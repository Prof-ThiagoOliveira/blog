[{"authors":null,"categories":null,"content":"I hold a PhD in Statistics from the University of S√£o Paulo, Brazil, and have at least eight years of experience in experimental statistics, statistical modelling, and concordance analysis. As a PhD candidate, I was a visiting Scholar at the National University of Ireland in 2016, working with statistical modelling for agricultural data. Besides, I was a lecturer in the Department of Exact Sciences at ESALQ/University of S√£o Paulo, Piracicaba, S√£o Paulo, Brazil from 2017 to 2019. I worked as a Researcher Biostatistician from 2019-2020 at Insight Centre for Data Analytics in partnership with Orreco, School of Mathematics, Statistics, and Applied Mathematics, and NUI Galway in the development of statistical methods applied to athlete performance, and predictive models for COVID-19. I developed statistical methods in longitudinal concordance correlation, multilevel model (hierarchical model), generalized linear mixed-effects model, state-space models, experimental design, longitudinal data. As an enthusiast of the usage of dashboard apps to create an interactive data visualization, I believe that interactive applications are an easier way to create visual representations of large scale data sets, allowing the user explore the complex reality of the database, or even handle multiple sets of data in a single visualization. Recently, I was awarded a Marie Sk≈Çodowska-Curie Individual Fellowship to work at The Roslin Institute - The University of Edinburgh, where I currently work on the development of statistical models applied to quantitative genetics and genomics of plant breeding in partnership with Limagrain. ","date":1906549200,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1906549200,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"https://prof-thiagooliveira.netlify.com/author/thiago-de-paula-oliveira/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/thiago-de-paula-oliveira/","section":"authors","summary":"I hold a PhD in Statistics from the University of S√£o Paulo, Brazil, and have at least eight years of experience in experimental statistics, statistical modelling, and concordance analysis. As a PhD candidate, I was a visiting Scholar at the National University of Ireland in 2016, working with statistical modelling for agricultural data.","tags":null,"title":"Thiago de Paula Oliveira","type":"authors"},{"authors":null,"categories":null,"content":"Summary of the number of courses and number of hours dedicated by category:\n    Programming Shiny Statistical Models Maching Learning Linear Algebra Inference and Probability Total     Number 5 2 13 1 4 4 29   Hours 21 8 196 4 56 55 340    ","date":1584090000,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":1535475600,"objectID":"5fc13f1f3abdb54ac237fb33bd7c538e","permalink":"https://prof-thiagooliveira.netlify.com/accomplishments/","publishdate":"2020-03-13T09:00:00Z","relpermalink":"/accomplishments/","section":"accomplishments","summary":"Summary of the number of courses and number of hours dedicated by category:\n    Programming Shiny Statistical Models Maching Learning Linear Algebra Inference and Probability Total     Number 5 2 13 1 4 4 29   Hours 21 8 196 4 56 55 340    ","tags":null,"title":"Courses","type":"docs"},{"authors":null,"categories":null,"content":"Planning observational studies, and experiment are one of the essential steps in scientific methodology. Unfortunately, in some cases, the statistical planning is neglected, leading to an analysis, sometimes, that does not answer properly the questions of researcher interest. When we are planning an experiment, we should account for non-biased samples, at same time that we consider the availability of experimental material. Moreover, we should to establish the experimental design with or without randomization restrictions.\n","date":1535360400,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":1535475600,"objectID":"59c3ce8e202293146a8a934d37a4070b","permalink":"https://prof-thiagooliveira.netlify.com/courses/example/","publishdate":"2018-08-27T09:00:00Z","relpermalink":"/courses/example/","section":"courses","summary":"I Workshop in introduction of experimental design","tags":null,"title":"Overview","type":"docs"},{"authors":null,"categories":null,"content":"Did you find this page helpful? Consider sharing it üôå ","date":1593216000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1593216000,"objectID":"246300c7e70a1142a658f22bdbb04f77","permalink":"https://prof-thiagooliveira.netlify.com/post/experimental_design/","publishdate":"2020-06-27T00:00:00Z","relpermalink":"/post/experimental_design/","section":"post","summary":"Did you find this page helpful? Consider sharing it üôå ","tags":null,"title":"Main elements and questions of a good experimental plan.","type":"post"},{"authors":null,"categories":null,"content":"  SAS day, Universidade de S√£o Paulo, USP, Brasil, 7h.\n  Matrizes. Universidade de S√£o Paulo, USP, Brasil, 25h.\n  C√°lculo Diferencial e Integral, Universidade de S√£o Paulo, USP, Brasil, 25h.\n  Modelos n√£o-lineares de efeitos mistos em R, Regi√£o Brasileira da Sociedade Internacional de Biometria, RBRAS, Brasil, 6h.\n  Uma revis√£o de modelos lineares generalizados, Universidade de S√£o Paulo, USP, Brasil, 4h.\n  No√ß√µes de Probabilidade, Universidade de S√£o Paulo, USP, Brasil, 25h.\n  Testes de Hip√≥teses, Universidade de S√£o Paulo, USP, Brasil, 24h.\n  M√©todos computacionais para infer√™ncia, Universidade de S√£o Paulo, USP, Brasil, 6h.\n  √Ålgebra intervalar na an√°lise de correspond√™ncia, Universidade de S√£o Paulo, USP, Brasil, 6h.\n  On longitudinal and incomplete data, Universidade de S√£o Paulo, USP, Brasil, 30h.\n  ","date":1577750400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1577750400,"objectID":"982d477653ba519326d766e2d5dd7df8","permalink":"https://prof-thiagooliveira.netlify.com/accomplishments/accomplishments2012/","publishdate":"2019-12-31T00:00:00Z","relpermalink":"/accomplishments/accomplishments2012/","section":"accomplishments","summary":"SAS day, Universidade de S√£o Paulo, USP, Brasil, 7h.\n  Matrizes. Universidade de S√£o Paulo, USP, Brasil, 25h.\n  C√°lculo Diferencial e Integral, Universidade de S√£o Paulo, USP, Brasil, 25h.","tags":null,"title":"2012","type":"docs"},{"authors":null,"categories":null,"content":" Generalized Additive Models with P-splines, Universidade de S√£o Paulo, USP, Brasil, 20h.  ","date":1577750400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1577750400,"objectID":"a9dcc0fd0069084d94c98701434432c3","permalink":"https://prof-thiagooliveira.netlify.com/accomplishments/accomplishments2014/","publishdate":"2019-12-31T00:00:00Z","relpermalink":"/accomplishments/accomplishments2014/","section":"accomplishments","summary":" Generalized Additive Models with P-splines, Universidade de S√£o Paulo, USP, Brasil, 20h.  ","tags":null,"title":"2014","type":"docs"},{"authors":null,"categories":null,"content":" Longitudinal and Incomplete Data, Escola superior de agricultura \u0026ldquo;Luiz de queiroz\u0026rdquo;, ESALQ, Brasil (30h).  ","date":1577750400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1577750400,"objectID":"e50eb563aacc6328a6bfdf5b26764071","permalink":"https://prof-thiagooliveira.netlify.com/accomplishments/accomplishments2016/","publishdate":"2019-12-31T00:00:00Z","relpermalink":"/accomplishments/accomplishments2016/","section":"accomplishments","summary":" Longitudinal and Incomplete Data, Escola superior de agricultura \u0026ldquo;Luiz de queiroz\u0026rdquo;, ESALQ, Brasil (30h).  ","tags":null,"title":"2016","type":"docs"},{"authors":null,"categories":null,"content":" Machine Learning with caret in R, DataCamp, 4h, certificate   **Description**: Machine learning is the study and application of algorithms that learn from and make predictions on data. From search results to self-driving cars, it has manifested itself in all areas of our lives and is one of the most exciting and fast growing fields of research in the world of data science. This course teaches the big ideas in machine learning: how to build and evaluate predictive models, how to tune them for optimal performance, how to preprocess data for better results, and much more. The popular caret R package, which provides a consistent interface to all of R's most powerful machine learning facilities, is used throughout the course.\n    ","date":1577750400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1577750400,"objectID":"207ad6af6c53717b4e8895059ec00777","permalink":"https://prof-thiagooliveira.netlify.com/accomplishments/accomplishments2018/","publishdate":"2019-12-31T00:00:00Z","relpermalink":"/accomplishments/accomplishments2018/","section":"accomplishments","summary":"Machine Learning with caret in R, DataCamp, 4h, certificate   **Description**: Machine learning is the study and application of algorithms that learn from and make predictions on data. From search results to self-driving cars, it has manifested itself in all areas of our lives and is one of the most exciting and fast growing fields of research in the world of data science.","tags":null,"title":"2018","type":"docs"},{"authors":null,"categories":null,"content":"  Intermediate R, DataCamp, 4h certificate\n  **Description**: Intermediate R is the next stop on your journey in mastering the R programming language. In this R training, you will learn about conditional statements, loops, and functions to power your own R scripts. Next, make your R code more efficient and readable using the apply functions. Finally, the utilities chapter gets you up to speed with regular expressions in R, data structure manipulations, and times and dates. This course will allow you to take the next step in advancing your overall knowledge and capabilities while programming in R.\n    Introduction to R, DataCamp, 4h, certificate\n  **Description**: In Introduction to R, you will master the basics of this widely used open source language, including factors, lists, and data frames. With the knowledge gained in this course, you will be ready to undertake your first very own data analysis. Oracle estimated over 2 million R users worldwide in 2012, cementing R as a leading programming language in statistics and data science. Every year, the number of R users grows by about 40%, and an increasing number of organizations are using it in their day-to-day activities. Begin your journey to learn R with us today!\n    Introduction to Python, DataCamp, 4h, certificate\n  **Description**: Python is a general-purpose programming language that is becoming ever more popular for data science. Companies worldwide are using Python to harvest insights from their data and gain a competitive edge. Unlike other Python tutorials, this course focuses on Python specifically for data science. In our Introduction to Python course, you‚Äôll learn about powerful ways to store and manipulate data, and helpful data science tools to begin conducting your own analyses. Start DataCamp‚Äôs online Python curriculum now.\n    Survival Analysis in R, DataCamp, 4h, certificate\n  **Description**: Do patients taking the new drug survive longer than others? How fast do people get a new job after getting unemployed? What can I do to make my friends stay on the dancefloor at my party? All these questions require the analysis of time-to-event data, for which we use special statistical methods. This course introduces basic concepts of time-to-event data analysis, also called survival analysis. Learn how to deal with time-to-event data and how to compute, visualize and interpret survivor curves as well as Weibull and Cox models.\n    Introduction to Statistical Modeling in R, DataCamp, 4h, certificate\n  **Description**: Introduction Statistical Modeling in R is a multi-part course designed to get you up to speed with the most important and powerful methodologies in statistical modeling in R.\n    Building Dashboards with shinydashboard, DataCamp, 4h, certificate\n  **Description**: Once you've started learning tools for building interactive web applications with shiny, this course will translate this knowledge into building dashboards. Dashboards, a common data science deliverable, are pages that collate information, often tracking metrics from a live-updating data source. You'll gain more expertise using shiny while learning to build and design these dynamic dashboards. In the process, you'll pick up tips to optimize performance as well as best practices to create a visually appealing product.\n    Case Studies: Building Web Applications with Shiny in R, DataCamp, 4h, certificate\n  **Description**: After learning the basics of using Shiny to build web applications, this course takes you to the next level by putting your newly acquired skills into practice. You'll get experience developing fun and realistic Shiny apps for different common use cases, such as using Shiny to explore a dataset, generate a customized plot, and even create a word cloud. With all this practice and new knowledge, you will be well-equipped to develop Shiny apps for your own use.\n    ","date":1577750400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1577750400,"objectID":"6c41ebb295d97a65c0de1ce88c31cc6b","permalink":"https://prof-thiagooliveira.netlify.com/accomplishments/accomplishments2019/","publishdate":"2019-12-31T00:00:00Z","relpermalink":"/accomplishments/accomplishments2019/","section":"accomplishments","summary":"Intermediate R, DataCamp, 4h certificate\n  **Description**: Intermediate R is the next stop on your journey in mastering the R programming language. In this R training, you will learn about conditional statements, loops, and functions to power your own R scripts.","tags":null,"title":"2019","type":"docs"},{"authors":null,"categories":null,"content":"  Mathematical Biostatistics BootCamp 1, 35h, Coursera\n  **Description**: This course puts forward key mathematical and statistical topicsto help students understand biostatistics at a deeper level.Successful students have a basic understanding of the goals,assumptions, benefits and negatives of probability modeling inthe medical sciences.\n    Statistics: Making Sense of Data, 376h, Coursera\n  **Description**: This introductory statistics course teaches the fundamentals ofstatistical investigations, including numerical and graphicalsummaries of data, probability, confidence intervals, hypothesistesting, and linear regression.\n    Introdu√ß√£o a An√°lise de Dados Categ√≥ricos, Universidade de S√£o Paulo, USP, Brasil, 15h.\n  Modelos de Equa√ß√µes Estruturais, Universidade de S√£o Paulo, USP, Brasil, 6h.\n  Alguns T√≥picos Importantes de Teoria Assint√≥tica, Universidade de S√£o Paulo, USP, Brasil, 6h.\n  ","date":1546214400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1546214400,"objectID":"f645bea5560ce548d823308a130165a2","permalink":"https://prof-thiagooliveira.netlify.com/accomplishments/accomplishments2013/","publishdate":"2018-12-31T00:00:00Z","relpermalink":"/accomplishments/accomplishments2013/","section":"accomplishments","summary":"Mathematical Biostatistics BootCamp 1, 35h, Coursera\n  **Description**: This course puts forward key mathematical and statistical topicsto help students understand biostatistics at a deeper level.Successful students have a basic understanding of the goals,assumptions, benefits and negatives of probability modeling inthe medical sciences.","tags":null,"title":"2013","type":"docs"},{"authors":null,"categories":null,"content":"  Regression Models, Coursera, 36h, certificate\n  **Description**: Linear models, as their name implies, relates an outcome to a set of predictors of interest using linear assumptions. Regression models, a subset of linear models, are the most important statistical analysis tool in a data scientist‚Äôs toolkit. This course covers regression analysis, least squares and inference using regression models. Special cases of the regression model, ANOVA and ANCOVA will be covered as well. Analysis of residuals and variability will be investigated. The course will cover modern thinking on model selection and novel uses of regression models including scatterplot smoothing.\n    Explorando interfaces gr√°ficas interativas no R, Regi√£o Brasileira da Sociedade Internacional de Biometria, RBRAS, Brazil, 2h.\n  Redu√ß√£o de dimensionalidade, Universidade de S√£o Paulo, USP, Brasil, 16h.\n  Modelos aditivos Generalizados con P-splines, Regi√£o Brasileira da Sociedade Internacional de Biometria, RBRAS, Brasil, 4h.\n  ","date":1546214400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1546214400,"objectID":"e85fbc9a52cb97231e3dc45e4137c6c9","permalink":"https://prof-thiagooliveira.netlify.com/accomplishments/accomplishments2015/","publishdate":"2018-12-31T00:00:00Z","relpermalink":"/accomplishments/accomplishments2015/","section":"accomplishments","summary":"Regression Models, Coursera, 36h, certificate\n  **Description**: Linear models, as their name implies, relates an outcome to a set of predictors of interest using linear assumptions. Regression models, a subset of linear models, are the most important statistical analysis tool in a data scientist‚Äôs toolkit.","tags":null,"title":"2015","type":"docs"},{"authors":null,"categories":null,"content":"Tip 1 Example of a completely randomized design.\n############################################################################ #################### Completely Randomized Design ########################## ############################################################################ # Type of Rootstock Trat \u0026lt;- gl(5,1,labels = c(\u0026quot;P1\u0026quot;, \u0026quot;P2\u0026quot;, \u0026quot;P3\u0026quot;, \u0026quot;P4\u0026quot;, \u0026quot;Controle\u0026quot;)) # Repetitions Rep \u0026lt;- 5 # Draw of treatments to plots DIC \u0026lt;- function(Trat,Rep){ Trat \u0026lt;- rep(Trat,Rep) N \u0026lt;- length(levels(Trat))*Rep # N√∫mero total de parcelas Plan\u0026lt;-as.data.frame( matrix( sample(Trat,N), ncol = length(levels(Trat)), nrow=Rep ) ) colnames(Plan)\u0026lt;-paste(\u0026quot;Coluna\u0026quot;, c(seq(1:length(levels(Trat))))) rownames(Plan)\u0026lt;-paste(\u0026quot;Linha\u0026quot;, c(seq(1:Rep))) return(Plan) } # Experiment Sketch DIC(Trat,Rep)  Tip 2 Example of a Randomized Block Design.\n############################################################################ ################### Randomized Block Design ################################ ############################################################################ # A researcher wishes to evaluate the color, odor and consistency of ruminal # juice samples from cattle of same breed, who are treated with 3 types of # feeds. As a restriction ofexperiment implementation, we can confine up to # 4 cattle per sector and the maximum number of sectors available is 5. # In addition, those animals were classified into three groups of carcasses: # i) light (226-228 kg), ii) medium (241-243 kg) and iii) higher (259-261 Kg). # Feed Trat \u0026lt;- gl(3,1,labels = c(\u0026quot;Ra√ß√£o 1\u0026quot;, \u0026quot;Ra√ß√£o 2\u0026quot;, \u0026quot;Ra√ß√£o 3\u0026quot;)) # Number of Blocks - carcass groups Bloco \u0026lt;- gl(5,1,labels = c(\u0026quot;Bloco I\u0026quot;, \u0026quot;Bloco II\u0026quot;, \u0026quot;Bloco III\u0026quot;, \u0026quot;Bloco IV\u0026quot;, \u0026quot;Bloco V\u0026quot;)) # Total number of plots N \u0026lt;- length(levels(Trat))*length(levels(Bloco)) # Draw of treatments to plots within blocks DCB \u0026lt;- function(Trat,Bloco){ Trat_Bloco \u0026lt;- list(NA) for(i in 1:length(levels(Bloco))){ Trat_Bloco[[i]]\u0026lt;-matrix( sample(Trat,length(levels(Trat)))) } Plan \u0026lt;- do.call(cbind.data.frame, Trat_Bloco) colnames(Plan) \u0026lt;- c(levels(Bloco)) rownames(Plan) \u0026lt;- paste(\u0026quot;Linha\u0026quot;, c(1:length(levels(Trat)))) return(Plan) } # Experiment Sketch DCB(Trat,Bloco)  Tip 3 Example of a completely randomized designs for factorial structure\n############################################################################ ################## Completely randomized designs ########################### ####################### Factorial structure ################################ ############################################################################ # Five soy cultivar Cultivar \u0026lt;- gl(5,1,labels=c(\u0026quot;BRS 1003IPro\u0026quot;, \u0026quot;BRS 1007IPro\u0026quot;, \u0026quot;BRS 1010IPro\u0026quot;, \u0026quot;BRS 1074IPro\u0026quot;, \u0026quot;BRS 706IPro\u0026quot;)) # Four nutrient solution with levels of 0.1.2, and 4 mg / liter of manganese. Solucao \u0026lt;- gl(4,1,labels = c(\u0026quot;0\u0026quot;, \u0026quot;1\u0026quot;, \u0026quot;2\u0026quot;, \u0026quot;4\u0026quot;)) # Treatments Trat \u0026lt;- expand.grid(Cultivar = Cultivar, Solu√ß√£o = Solucao) Trat$Tratamento \u0026lt;- as.factor(paste(Trat$Cultivar,Trat$Solu√ß√£o)) # Repetition Rep \u0026lt;- 10 # Draw of treatments to plots DIC \u0026lt;- function(Trat,Rep){ N \u0026lt;- length(levels(Trat))*Rep # Total number of plots Trat \u0026lt;- rep(Trat,Rep) Plan \u0026lt;- as.data.frame( matrix( sample(Trat,N), ncol = Rep, nrow=length(levels(Trat)) ) ) colnames(Plan) \u0026lt;- paste(\u0026quot;Coluna\u0026quot;, c(seq(1:Rep))) rownames(Plan) \u0026lt;- paste(\u0026quot;Linha\u0026quot;, c(seq(1:length(levels(Trat))))) return(Plan) } # Experiment Sketch DIC(Trat$Tratamento,Rep)  Tip 4 Example of a Latin Square Design\n############################################################################ ######################## Latin Square Design ############################### ############################################################################ L1 \u0026lt;- gl(4,1,labels = c(\u0026quot;A\u0026quot;,\u0026quot;B\u0026quot;,\u0026quot;C\u0026quot;,\u0026quot;D\u0026quot;)) L2 \u0026lt;- gl(4,1,labels = c(\u0026quot;B\u0026quot;,\u0026quot;C\u0026quot;,\u0026quot;D\u0026quot;,\u0026quot;A\u0026quot;)) L3 \u0026lt;- gl(4,1,labels = c(\u0026quot;C\u0026quot;,\u0026quot;D\u0026quot;,\u0026quot;A\u0026quot;,\u0026quot;B\u0026quot;)) L4 \u0026lt;- gl(4,1,labels = c(\u0026quot;D\u0026quot;,\u0026quot;A\u0026quot;,\u0026quot;B\u0026quot;,\u0026quot;C\u0026quot;)) Trat \u0026lt;- rbind(paste0(L1),paste0(L2),paste0(L3),paste0(L4)) QL \u0026lt;- function(Trat){ #Sorteando as linhas Linha \u0026lt;- Trat[sample(nrow(Trat),size=ncol(Trat)),] Coluna \u0026lt;- Linha[, sample(nrow(Linha),size=ncol(Linha))] return(Coluna) } QL(Trat)  ","date":1535360400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1535360400,"objectID":"74533bae41439377bd30f645c4677a27","permalink":"https://prof-thiagooliveira.netlify.com/courses/example/example1/","publishdate":"2018-08-27T09:00:00Z","relpermalink":"/courses/example/example1/","section":"courses","summary":"Tip 1 Example of a completely randomized design.\n############################################################################ #################### Completely Randomized Design ########################## ############################################################################ # Type of Rootstock Trat \u0026lt;- gl(5,1,labels = c(\u0026quot;P1\u0026quot;, \u0026quot;P2\u0026quot;, \u0026quot;P3\u0026quot;, \u0026quot;P4\u0026quot;, \u0026quot;Controle\u0026quot;)) # Repetitions Rep \u0026lt;- 5 # Draw of treatments to plots DIC \u0026lt;- function(Trat,Rep){ Trat \u0026lt;- rep(Trat,Rep) N \u0026lt;- length(levels(Trat))*Rep # N√∫mero total de parcelas Plan\u0026lt;-as.","tags":null,"title":"R Code","type":"docs"},{"authors":["Thiago de Paula Oliveira","Rafael de Andrade Moral"],"categories":null,"content":"Abstract:\nThe continuously growing number of COVID-19 cases pressures healthcare services worldwide. Accurate short-term forecasting is thus vital to support country-level policy making. The strategies adopted by countries to combat the pandemic vary, generating different uncertainty levels about the actual number of cases. Accounting for the hierarchical structure of the data and accommodating extra-variability is therefore fundamental. We introduce a new modelling framework to describe the course of the pandemic with great accuracy, and provide short-term daily forecasts for every country in the world. We show that our model generates highly accurate forecasts up to six days ahead, and use estimated model components to cluster countries based on recent events. We introduce statistical novelty in terms of modelling the autoregressive parameter as a function of time, increasing predictive power and flexibility to adapt to each country. Our model can also be used to forecast the number of deaths, study the effects of covariates (such as lockdown policies), and generate forecasts for smaller regions within countries. Consequently, it has strong implications for global planning and decision making. We constantly update forecasts and make all results freely available to any country in the world through an online Shiny dashboard.\n","date":1906549200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1906549200,"objectID":"4ea25c492c2034f8ee4a47d506a50759","permalink":"https://prof-thiagooliveira.netlify.com/talk/2020-usp/","publishdate":"2020-05-30T00:00:00Z","relpermalink":"/talk/2020-usp/","section":"talk","summary":"Accurate short-term forecasting is thus vital to support country-level policy making during COVID-19 outbreak","tags":["COVID-19","Outbreak","State-Space Model","Longitudinal Data"],"title":"Global Short-Term Forecasting of Covid-19 Cases","type":"talk"},{"authors":["Thiago de Paula Oliveira"],"categories":["C++","Computer Programs"],"content":" Introduction Expressions are combinations of operators, values (constants), and variables which are arranged according to the rules established througout the code. Thus, every expression is any part of a statement that returns a value, as in the follow example:\nThis statement creates a box to store the value of \\(x\\) and another to store the value of \\(y\\), which is equal to the expression \\(x\\) plus 13 (\\(y=23\\)). Now consider a more complex statement:\nThis statment consists of three expressions:  The results of the expression \\(3 - x\\) is stored in the variable \\(y\\) The expression \\(y = 3 - x\\) returns the value of \\(y\\), and it is stored in the variable \\(v\\) The results of the expression \\(y \\times \\left(\\frac{v}{5} + x\\right)\\) is stored in the variable \\(z\\)   Remember that multiplication and division occur before addition and subtraction. Ex.:\n1-3*4 = -11 2/3-4*2/3 = -2 2/3-4/4*2/3 = 0 The operator precedente dictates the order of evaluation of operators in an expression. In C, each operator has a fixed priority order to be executed or precedence in relation to other operators. As multiplication or division has higher precedence than addition and subtraction, in the expression \\(\\frac{2}{4}-3+ 4 \\times 6\\), firstly the subexpressions \\(\\frac{2}{4}\\) and \\(4 \\times 6\\) will be evaluated (Step 1 in the Figure 1), and then addition and subtraction (Step 2 in the Figure 1). Note that multiplication and division, or addition and subtraction have same precedente, then tey are evaluated from left to right due to its associativity.\n Figure 1: Precedence order  Associativity defines the order in which operators of the same precedence are evaluated in an expression, and it can be either from left to right or right to left (Figure 2). Generally, addition, subtraction, multiplication, and division operators are usually left-associative while assignment operators are typically right-associative. Besides, there are operators that have no defined behavior when used in sequence over an expression, and they are called as non-associative (Figure 2). Note that when we include parentheses, we can force an expression to be right-associative rather than left-associative as usual.\n Figure 2: Example of left-associative, right-associative, and non-associative   Using Parentheses () The operator () has the highest precedente order (see Table 1), as consequence, we can use parentheses to change the sequence of operators. Consider the following example:\n5 + 6 * 7 The * operator is evaluated firstly followed by the + operator, so the result is \\(5+6\\times 7 = 47\\). However, if we want to account for the addiction first and then the multiplication, we can rewrite the code as:\n(5 + 6) * 7 Then, the program will compute \\(\\left(5+6\\right)\\times 7=11\\times 7=77\\). Sometimes, the inclusion of parentheses should be important to makes your code easier to understand, and therefore easier to maintain.\n Modulus operator (%) Modulus operator evaluates to the remainder when dividing the first operand by the second one. Ex.: a % b is the remainder when \\(a\\) is divided by \\(b\\) (\\(a\\) modulus \\(b\\)). by \\(b\\) (\\(a\\) modulus \\(b\\)).\n Figure 3: Example of modulus   Dividing an integer by another one gives an integer.   Example: int x = 10; int y = 3; x/y = 10/3 = 3 (dividing two integers) x % y = 1 (modulus)   Short hand or syntatic sugar Short hand expressions provide a short way to write common patterns over the algorithm for initialized variables.\n  Short hand Meaning Prefix and Postfix    \\(x+=y\\) \\(x=x+y\\)   \\(x-=y\\) \\(x=x-y\\)   \\(x*=y\\) \\(x= x \\times y\\)   \\(x/=y\\) \\(x=x/y\\)   \\(x++\\) \\(x=x+1\\) Return the value of \\(x\\) first then increment it  \\(++x\\) \\(x=x+1\\) Increment first then return the value of \\(x\\)  \\(x--\\) \\(x=x-1\\) Return the value of \\(x\\) first then increment it  \\(--x\\) \\(x=x-1\\) Increment first then return the value of \\(x\\)    Example 1: Here you can see that y ++= x * z; is calculate as \\(y=y+x \\times z = 30 + 2 \\times 4 = 34\\).\n Example 2: In this example you can see that we used the postfix x++ to first initialize \\(y\\) (\\(y=8 \\times x = 8 \\times 7 = 56\\)) and then update \\(x\\) to x=x+1=8. On the other hand, we used the prefix --y to first update the variable \\(y\\) to y=y-1=55 and then calculate the variable z using the updated \\(y\\) \\(\\left(z = y/5 = 55/5 = 11 \\right)\\).\nNote that when we use x*= (y/z) % 2 the variable \\(x\\) multiply the entire expression after = symbol. This expression is equivalent to x = x * ((y/z) % 2));.\n  Operator precedence and associativity Table 1 shows a list of precedence (ordered) and associativity of C operators. This table was obtained from cppreference.com.\n   Table 1: Precedence and associativity of C operators  Precedence  Operator  Description  Associativity    1  ++ --  Suffix/postfix increment and decrement  Left-to-right    ()  Function call    []  Array subscripting    .  Structure and union member access    -\u0026gt;  Structure and union member access through pointer    (type){list}  Compound literal(C99)    2  ++ --  Prefix increment and decrement[note 1]  Right-to-left    + -  Unary plus and minus    ! ~  Logical NOT and bitwise NOT    (type)  Cast    *  Indirection (dereference)    \u0026amp;  Address-of    sizeof  Size-of[note 2]    _Alignof  Alignment requirement(C11)     3   * / %   Multiplication, division, and remainder  Left-to-right     4   + -   Addition and subtraction     5   \u0026lt;\u0026lt; \u0026gt;\u0026gt;   Bitwise left shift and right shift    6  \u0026lt; \u0026lt;=  For relational operators \u0026lt; and ‚â§ respectively    \u0026gt; \u0026gt;=  For relational operators \u0026gt; and ‚â• respectively     7   == !=   For relational = and ‚â† respectively     8   \u0026amp;   Bitwise AND     9   ^   Bitwise XOR (exclusive or)     10   |   Bitwise OR (inclusive or)     11   \u0026amp;\u0026amp;   Logical AND     12   ||   Logical OR     13   ?:   Ternary conditional[note 3]  Right-to-Left    14[note 4]  =  Simple assignment    += -=  Assignment by sum and difference    *= /= %=  Assignment by product, quotient, and remainder    \u0026lt;\u0026lt;= \u0026gt;\u0026gt;=  Assignment by bitwise left shift and right shift    \u0026amp;= ^= |=  Assignment by bitwise AND, XOR, and OR     15   ,   Comma   Left-to-right     ‚Üë The operand of prefix ++ and -- can‚Äôt be a type cast. This rule grammatically forbids some expressions that would be semantically invalid anyway. Some compilers ignore this rule and detect the invalidity semantically.  ‚Üë The operand of sizeof can‚Äôt be a type cast: the expression sizeof (int) * p is unambiguously interpreted as (sizeof(int)) * p, but not sizeof((int)*p).  ‚Üë The expression in the middle of the conditional operator (between ? and :) is parsed as if parenthesized: its precedence relative to ?: is ignored.  ‚Üë Assignment operators‚Äô left operands must be unary (level-2 non-cast) expressions. This rule grammatically forbids some expressions that would be semantically invalid anyway. Many compilers ignore this rule and detect the invalidity semantically. For example, e = a \u0026lt; d ? a++ : a = d is an expression that cannot be parsed because of this rule. However, many compilers ignore this rule and parse it as e = ( ((a \u0026lt; d) ? (a++) : a) = d ), and then give an error because it is semantically invalid.     References  C Operator Precedence - https://en.cppreference.com/w/c/language/operator_precedence#cite_note-1  Did you find this page helpful? Consider sharing it üôå\n ","date":1608076800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1608120954,"objectID":"505ea7ea3b3953f93ed1b36b33bb0f23","permalink":"https://prof-thiagooliveira.netlify.com/post/expressions/","publishdate":"2020-12-16T00:00:00Z","relpermalink":"/post/expressions/","section":"post","summary":"Introduction Expressions are combinations of operators, values (constants), and variables which are arranged according to the rules established througout the code. Thus, every expression is any part of a statement that returns a value, as in the follow example:","tags":["C++","Computer Science","Computer Programs"],"title":"Expressions","type":"post"},{"authors":["Rafael Moral","Thiago de Paula Oliveira","Andrew Parnell"],"categories":["COVID-19","Statistical Models","Forecast Models"],"content":" tl;dr  Many different variables affect how the pandemic progresses and it is extremely difficult to identify each one, and precisely measure them. The data we have is surely innacurate, but could be a good proxy for understanding the behaviour of the coronavirus outbreak We developed a statistical model to obtain short-term forecasts of the number of COVID-19 cases We constantly update forecasts and make all results freely available to any country in the world through a web app   How many people will get infected tomorrow? ‚ÄúHow many cases do you think we‚Äôre going to have today?‚Äù, my fianc√®e asked me just as I‚Äôm writing this post ‚Äì and quite frankly I‚Äôve asked that myself many times over the last several months. Wouldn‚Äôt it be great if we had a method to accurately predict the number of confirmed COVID-19 cases we‚Äôll have every single day for, say, the next month? If we could do that, we‚Äôd know whether our measures to contain the virus are working, whether we would be able to lift particular restrictions here and there, invest in intensive care units, or whether that wedding we had planned long ago would finally happen or have to be postponed‚Ä¶ again.\nIt is very hard, however, to pinpoint exactly every single factor that affects the number of reported COVID-19 cases, and most importantly, measure them all. Here we try and outline different techniques we could use to try and predict how the outbreak will behave in the future, and show a particular method we have developed to obtain short-term forecasts with a reasonable degree of accuracy. We have packaged the method into an app, which you can access here.\n What strategies can we use? There are many different strategies and mathematical/statistical tools we can use to attempt to predict the future. These can include what we call mechanistic, or compartment models, for example. These make assumptions based on empirical evidence of the biological system being studied and translate them into mathematical equations based on the flow of individuals to/from specific compartments. For COVID-19 the SEIR-type model has been widely used by many research groups to describe the behaviour of the outbreak (see our blog post on the use of SEIR models to predict when the pandemic will end). They are realistic in the sense that they reflect the epidemiological behaviour of the outbreak.\nThere are other alternatives that do not take into account the true biological nature of the phenomenon per se, but may use it as input in a different way. Many machine learning techniques could sometimes be seen as black-box methods, that would e.g.¬†take the reported number of past COVID-19 cases and other variables that we would believe could influence this number and spit out a prediction for tomorrow, or next week, next month, etc. There are cases where these methods are even more accurate than mechanistic models, however there is a trade-off to consider here in terms of prediction accuracy vs.¬†explainability, as discussed here. If a new event or variable comes into play, which could empirically be very important to dictate the future behaviour of the pandemic, it is very difficult to gauge its effects using a black-box method.\nWe could also simply assume that the number of reported COVID-19 cases today is purely a reflection of the reported number of cases yesterday, and the day before, and so on. So we pretty much assume all variables that influence this process can be summarised purely by the outcomes we have observed in the past, and this can in turn be used to forecast what future numbers will be. Of course, there are plenty of different ways to include other variables in these types of models, but the important thing is to notice that we place a very heavy assumption on an underlying process that is able to explain its own behaviour. We usually refer to these models as ‚Äútime series‚Äù or ‚Äústate-space‚Äù models.\n Why is it so difficult? There are many factors that influence our ability to predict the number of future COVID-19 cases. Imagine we have, for example, a fantastic SEIR-type model that can reproduce the dynamics of the disease almost perfectly up to today. To be able to predict with great accuracy what will happen tomorrow (or even further down the line), we must assume, among other things, that the assumptions that hold today will still hold tomorrow and so on. If any new variable comes into play, or if the variables that are involved change over time, our predictions can be completely off.\nThis is not the worst problem, however. There are in fact many variables that we‚Äôre simply not able to measure with good precision. This includes knowing, for example, where everybody in the country is at all times, who they talk to, for how long, where they will be, etc. This is why it is important to do contact tracing, although this matters mostly in a retrospective way, not necessarily to predict what will happen in the future.\nBut wait a minute now, we don‚Äôt even know whether the data we can actually measure is in fact accurate! Or to be more specific, we do know that our data is definitely not 100% accurate. Cases reported today could reflect infections that happened between a few days ago to several weeks. Tests are not 100% accurate either, so there is a pool of false positives in there, as well as false negatives not being included in the whole sum. Simply put, the data we have is pretty much a proxy of the real thing. Hence why it is so important to understand what these numbers could actually mean, and not imbue them with improper meaning.\n What about short-term forecasting? So long-term forecasting is very prone to built-up variation and error, as we all know. It‚Äôs just like predicting what time you‚Äôll wake up on your birthday 10 years from now. But there must be something we could do in the short-term, right? Well, it depends on how ‚Äúlong‚Äù this short-term is. And it also depends on how we want to use this information.\nWe developed a modelling framework in an attempt to predict the number of reported COVID-19 cases for up to 7 days in the future. We fitted our models to the data collected by the ECDC to generate the forecasts. See below for a validation study we carried out back in May/2020.\nThe panels are in the logarithmic scale, but in essence, the closer the points are to the identity line (dashed line), the closer our model was in predicting the number of COVID-19 cases up to 7 days ahead (panels in part A). In part B we see that the accuracy of the method is high for all 7 days ahead, but we begin to lose in terms of precision from day four onwards. (\\(r\\) represents Pearson‚Äôs linear correlation coefficient, the closest it is to 1 the better the method is; the same applies to the CCC - the concordance correlation coefficient.)\nThe idea behind this is not to be able to inform governments the exact numbers we‚Äôd expect tomorrow, but to give more perspective in terms of the types of trends we expect in the near future. This is useful to inform decision making related to the healthcare services. For instance, if a particular country‚Äôs healthcare system is currently at capacity, and we are predicting an upward trend in the number of infections, then this could guide policy in terms of resource allocation to accommodate the extra patients that are likely to seek health professionals in the upcoming weeks. This is why it is so important to look at overall trends (for example, the number of cases per 100,000 people over the last 14 days).\nOur model creates predictions based on two components. The first, called the autoregressive component, uses information on the past number of cases to predict future ones. The second is included to account for extra variability that could occur for a variety of different reasons. The autoregressive component is directly linked to the behaviour of the outbreak, so it is useful to detect waves of the pandemic. See, for example, our latest estimates for Ireland:\nWe can clearly see that towards the end of July this second wave was already starting to take shape, and now we are aiming at a new peak of cases.\n Grouping countries together Now that we have profiles for each country on how the pandemic is behaving in terms of number of cases, perhaps it would be a good idea to look at which countries present a similar behaviour over the last, say, 60 days. We created a dendrogram based on a cluster analysis performed using the values of the autoregressive parameter and produced the figure below ‚Äì\nHere we see that over looking at the past two months, the country that has presented the most similar behaviour to Ireland was Croatia. In our app you can play with different ways of presenting the dendrogram, as well as print names of different countries in bold to aid in finding them easily when looking at the picture. You can also change the number of clusters.\nPerhaps these comparisons would be useful in terms of comparing government policies on how to deal with the COVID-19 outbreak, and learn lessons from successful policies vs unsuccessful ones. Also, this type of modelling can help to detect a further wave of the outbreak sooner rather than when we are already in the middle of it!\n All models are wrong‚Ä¶ In the end of the day, there is no true, correct model we can apply. After all, it is impossible to know exactly what the data generating mechanism is. We can only attempt to understand it and reproduce its behaviour using mathematical/statistical tools. We hope, however, that our modelling approach can be useful. We could point a whole list of problems with it here, such as completely ignoring biological mechanisms and using just past behaviour to explain future behaviour without any additional context. But we believe it represents a reasonable attempt at forecasting the number of COVID-19 cases in the short-term.\nDid you find this page helpful? Consider sharing it üôå\n Citation For attribution, please cite this work as:  Moral, et al.¬†(2020, Sept.¬†29). Ireland‚Äôs COVID-19 Data Dive: How hard is it to predict COVID-19 cases?. Retrieved from https://www.hamilton.ie/covid19/posts/2020-10-01-how-hard-to-predict-cases/\n BibTeX citation  @misc{moral2020how, author = {Moral, Rafael and Oliveira, Thiago and Parnell, Andrew}, title = {Ireland\u0026#39;s COVID-19 Data Dive: How hard is it to predict COVID-19 cases?}, url = {https://www.hamilton.ie/covid19/posts/2020-10-01-how-hard-to-predict-cases/}, year = {2020} }  ","date":1608076800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1608121186,"objectID":"8a17a1381fc8f69cddde821d4df2bfcb","permalink":"https://prof-thiagooliveira.netlify.com/post/how-hard-is-it-to-predict-covid-19-cases/","publishdate":"2020-12-16T00:00:00Z","relpermalink":"/post/how-hard-is-it-to-predict-covid-19-cases/","section":"post","summary":"tl;dr  Many different variables affect how the pandemic progresses and it is extremely difficult to identify each one, and precisely measure them. The data we have is surely innacurate, but could be a good proxy for understanding the behaviour of the coronavirus outbreak We developed a statistical model to obtain short-term forecasts of the number of COVID-19 cases We constantly update forecasts and make all results freely available to any country in the world through a web app   How many people will get infected tomorrow?","tags":["Covid-19","Statistics","State-Space Model","Statistical Models","Statistical Methodology"],"title":"How hard is it to predict COVID-19 cases?","type":"post"},{"authors":["Thiago de Paula Oliveira"],"categories":["C++","Computer Programs"],"content":"  Introduction When we think about writing a program in C, the first step is understand how variables should be assigned. There are several variable‚Äôs type in C, and here we are introducing the type int, which is used for integer data types. Basically, we can define a variable as an integer in two ways:  Uninitialized variable: defined as int x;, where no value is assign to the variable \\(x\\) (Figure 1), which generally is not a good idea as it could lead to a bug in the algorithm if no value is assign over the code. Initialized variable: there are two ways to assign a value to a variable \\(x\\) (Figure 1):  in a single declaration - int x = 3; in a double step declaration - int x; and x = 3;      Figure 1: Declaring variables in C  Additionally, there are a large set of storage size-specific declarations for a integer, and here we will explain just an initial idea about it. Figure 2 showns the Integer representation of whole numbers or fixed-point numbers (fixed number of digits). Generally, computers use a fixed number of bits to represent them, where commonly used bit-lengths for integers are 8-bit, 16-bit (short), 32-bit (long) or 64-bit (long long). There are two representation schemes for integers called signed integer type (signed int) capable of containing the range of values from -32,767 to 32,767, and unsigned integer type (unsigned int) containing the range of values from 0 to 65,535 (\\(32767 \\times 2+1\\)). Therefore, unsigned qualifier should be used when we are working with only positive values.\n Figure 2: Integer Representation  Furthermore, there are three representation schemes for signed integers called Sign-Magnitude representation, 1‚Äôs Complement representation, and 2‚Äôs Complement representation. The 1‚Äôs and the 2‚Äôs complements of a binary number are important because they permit different representation for negative numbers. In all of these schemes, positive signed binary numbers starts with value 0 while negative ones starts with value 1 (Figure 3).\n Figure 3: Signed binary numbers  Consequently, the disadvantage of signed binary numbers is that there is 1 bit used to store the sign positive or negative while the remaning \\(n-1\\) bits are assign to the range of digits from \\(-2^{n-1}\\) to \\(2^{n-1}\\). If we have 8 bits to represent a signed binary number, we have to use 1 bit for the sign bit and 7 bits for the magnitude bits:\n Using Sign-Magnitude Representation: \\[-|2^{\\left(8-1\\right)}-1| \\mbox{ to } 2^{\\left(8-1\\right)}-1 = -127 \\mbox{ to } 127\\] Using 2‚Äôs Complement Representation: \\[-2^{\\left(8-1\\right)} \\mbox{ to } 2^{\\left(8-1\\right)}-1 = -128 \\mbox{ to } 127\\]   Thus, we can representing the numbers ranging from -128 to 127 using 2‚Äôs Complement Representation. Probably now you are asking why there is one extra number being accounted when using 2‚Äôs Complement Representation. The answer can be found in the Figure 4.\n Figure 4: Representation schemes of Sign-Magnitude Representation and 2‚Äôs Complement Representation   Examples Unsigned int Supose we are interested in representing a sequence of number \\(x\\) where \\(x \\in \\lbrace 0, 1, \\ldots, 15\\rbrace\\). We can assign these numbers as unsigned numbers of 4 bits. Consequently, we have 4 zero bits associated to describe this numbers because our variable belongs to the interval \\([0, 2^{4}‚àí1] \\in \\mathcal{N}_{0}\\).\n Table 1: Representation of numbers from 0 to 15 in 4 bits    bits  0000  0001  0010  0011  0100  0101  0110  0111  1000  1001  1010  1011  1100  1101  1110  1111    x  0  1  2  3  4  5  6  7  8  9  10  11  12  13  14  15      Signed int Supose now we are interested in representing a sequence of number \\(y\\) where \\(y \\in \\lbrace -7, -6, \\ldots,6, 7\\rbrace\\). We have to assign them as signed numbers using 4 bits because 1 bit will be used for sign bit and 3 bits for the magnitude bits to describe \\(y \\in \\left[-|2^3-1|,2^3-1\\right] \\in \\mathcal{Z}\\).\n Table 2: Sign-Magnitude Representation of numbers from -7 to 7 using 4 bits    bits  0111  0110  0101  0100  0011  0010  0001  0000  1000  1001  1010  1011  1100  1101  1110  1111    y  7  6  5  4  3  2  1  0  -0  -1  -2  -3  -4  -5  -6  -7      Table 3: 2‚Äôs Complement Representation of numbers from -8 to 7 using 4 bits    bits  1000  1001  1010  1011  1100  1101  1110  1111  0000  0001  0010  0011  0100  0101  0110  0111    y  -8  -7  -6  -5  -4  -3  -2  -1  0  1  2  3  4  5  6  7       References Barnett R.; O‚ÄôCull L.; Cox, S. Embedded C Programming and the Microship PIC. Delmar Learning, ed.¬†1, 2004.\nCadenhead, R.; Liberty, J. Sams Teach Yoirself C++. Pearson Education, ed.¬†6, 2017.\nC Data Types - https://en.wikipedia.org/wiki/C_data_types\nDid you find this page helpful? Consider sharing it üôå\n ","date":1608076800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1608120651,"objectID":"f9d843a0159600db57c80e48bbc780f6","permalink":"https://prof-thiagooliveira.netlify.com/post/signed-and-unsigned-binary-numbers/","publishdate":"2020-12-16T00:00:00Z","relpermalink":"/post/signed-and-unsigned-binary-numbers/","section":"post","summary":"Introduction When we think about writing a program in C, the first step is understand how variables should be assigned. There are several variable‚Äôs type in C, and here we are introducing the type int, which is used for integer data types.","tags":["C++","Computer Science","Computer Programs"],"title":"Signed and Unsigned Binary Numbers","type":"post"},{"authors":["Thiago de Paula Oliveira"],"categories":["C++","Computer Programs"],"content":" Overview of the Seven Steps The seven steps proposed by Hilton et al.¬†(2019) is very interesting strategy to start a new project that involves programming process, where a summary of the entire process is shown in the Figure 1. Here we will describe these steps based on thw work of Hilton et al.¬†(2019).\n Figure 1: The seven steps (modified from Hilton et al.¬†(2019))  All steps are then described in the sections below.\n Step 1 - Project definition using simple examples This is the moment where you spend time thinking about the project and how could you divide them into small tasks. Start your project drawing a diagram of it by hand, including the main subjects, how you could sorted out the problems, and how many main algorithms should you create to have your project done. Here you may include how the project could be sub-divided in smaller tasks, how this tasks are connected, and if there is an order to execute them (Figure 2). Consequently, this should reflect in the number of main algorithms to be build. Doing a good job during this stage will facilitate the remainder steps.\n Figure 2: Example of how divide the main project into small tasks  Example 1 Suppose we would want to write an algorithm in C++ to compute the total fat of a ice cream portion basis (\\(y\\)). Suppose also this response variable is a function of butyric fat \\(x_1\\) and vegetable fat \\(x_2\\). Let \\(E[y]\\) be the expected value of \\(y\\) defined as\n\\[E[y]=10-0.5x_1+0.6x_1^2-0.6x_2+0.2x_2^2+0.1x_1x_2\\] Thus, we can pick particular values for \\(x_1\\), and \\(x_2\\) to calculate the total fat \\(y\\) by hand. If \\(x_{1}=2\\), \\(x_{2}=1\\), then \\[y=10-0.5\\times2+0.6\\times 2^2-0.6\\times 1+0.2 \\times 1^2+0.1\\times 2 \\times 1 = 11.2.\\]\nNow, suppose the the second aim is the optimization of reduction in fat ice cream formulation from this fitted model. In this sense, we are looking for the global minimum through the response surface, consequently, we can divide our project into, e. g., two tasks:\nGeneralize the function for any \\(x_1\\) and \\(x_2\\); Calculate the global (or absolute) minimum point;   If you get stuck in one of these steps, probably this difficult is comming from a lack of domain knowledge of a particular field, e. g., a lack of domain in mathematics:\n How could I calculate the global minimum? How can I use partial derivatives?   Thus, during this step you have to identify all lack of domain knowledge and then overcome them before going to the next step. Sometimes, domain knowledge may come from particular fields of computer science, sports, agriculture, statistics, or engineering.\n  Step 2 - Write everything you did In this step you should take notes about what you did to solve the project or tasks within the project. Your notes describing all solutions by task should be precisely enough to anyone else reproduce them easily. Sometimes we may omit common sense steps such as multiply \\(x\\) by \\(y\\), or the order in which each task should be executed.\nExample 2 Suppose we are interested in computing \\(f(x,y)=x^y+3x\\) when \\(x=2\\) and \\(y=4\\), then we might write down a deatiled descriptions of all steps to compute \\(f(x,y)\\):\n Multiply 2 by 2 \\(\\rightarrow\\) you get 4 Multiply 4 by 2 \\(\\rightarrow\\) you get 8 Multiply 8 by 2 \\(\\rightarrow\\) you get 16 Sum 16 plus 3 multiplied by 2 \\(\\rightarrow\\) you get 22 22 is the answer.   The steps are precise as anyone who can perform basic math can follow these steps to get the same answer.\n  Step 3 - Generalize Our task now is generalize the last steps into an algorithm, finding patterns that allows us to solve the whole class rather than for a particular parameter values. Here is two common way to generalize those steps into algorithm:\n Look all details of your step 2 because, sometimes, you can find the generalization into it description. Look for repetition patterns - when the same step repeats several times   We can, e. g., generalize our Example 2 just looking the description into step 2, where we can replacing the occurence of 2 by \\(x\\):  Multiply 2 by \\(x\\) \\(\\rightarrow\\) you get 4 Multiply 4 by \\(x\\) \\(\\rightarrow\\) you get 8 Multiply 8 by \\(x\\) \\(\\rightarrow\\) you get 16 Sum 16 plus 3 multiplied by \\(x\\) \\(\\rightarrow\\) you get 22 22 is the answer.   Note that, in the first multiplication, we have to start with \\(x \\times x=2 \\times x = 4\\), thus the number of times that we should multiply 2 by \\(x\\) are \\(y-1\\). Thus, we would lead to the following generalized steps:\nAlgorithm sketch 1 start with x = 2 and y = 4 n[1] = x Count up from i in 1 to y-1 n[i+1] = n[i] * x z = n[y] + 3 * x z is the answer This process is referred to as writing ‚Äòpseudo-code‚Äô as an algorithm design with no particular target language.\n  Step 4 - Test Your Algorithm Testing your algorithm is a useful step to ensure steps 1-3 are actually right before we proceed to the step 5. Some examples about what you should do/think during this stage are described below:\n Test your algorithm choosing different values for parameters What happen if the value is positive, negative or equal to zero? Have you restricted parameter space? Ex.: \\(y\\geq 0\\). Use mathematical proofs There is always more than one right answer to a programming problem   Remember that parameter space is the space of possible parameter values that define a particular mathematical/statistical model, and they are generally a subset of finite-dimensional Euclidean space.\n Sometimes, we mis-generalizing our algorithm at step 3, and this mistake lead us again to the steps 1-2. Generally, mis-generalization happens when we did not consider all possible cases during step 3, or when we did not have mathematical proofs about what we are doing.\nA good example of algorithm mistake could be seen in the Example 2. What happens if \\(y=0\\), or \\(y\u0026lt;0\\)? We can see that our algorithm handles these cases incorrectly. If you calculate the algorithm steps by hand with \\(x=2\\) and \\(y=0\\) you will get \\(2^0=2\\) rather than \\(2^0=1\\) (correct answer). Additionally, for any value \\(y\\leq 0\\) the algorithm try to count from \\(1\\) to \\(y-1\u0026lt;0\\), of which are no Natural number, leading an error in the process. Thus, we can conclude that \\(|y| \\in \\mathcal{N}_{0}\\), where \\(\\mathcal{N}_{0}=\\mathcal{N} \\cup \\lbrace 0 \\rbrace\\) represents Natural numbers with zero. In this sense, we might attempt to generalize our algorithm to higher number of cases:\nAlgorithm sketch 2 y must be a integer number start with x = 2 and y = 4 if y=0 { n[1] = 1 i=0 } else{ Count up from i in 1 to |y|-1 if y\u0026lt;0 { n[1] = 1/x n[i+1] = n[i] * 1/x } else{ n[1] = x n[i+1] = n[i] * x } } z = n[i+1] + 3 * x z is the answer  Figure 3: Example of output using the algorithm 2  Question: How can we improve this algorithm? Think about the case where \\(x=y=0\\).\n For some problems, there are particular cases that require our attention. Every time we detect problem with our algorithm in this step, we have to choose one of this option: Return to steps 1-3 to get more information to generalize the algorithm to a higher number of cases. Skip the last steps and fix the algorithm directly in the step 4 (when we know easily how to fix the problem).   Example 3 The numbers in the Figure 4 were obtained from an algorithm that has one parameter \\(N \\in \\mathcal{N}_{0}\\) to be specified, where \\(\\mathcal{N}_{0}=\\mathcal{N} \\cup \\lbrace 0 \\rbrace\\) represents Natural numbers with zero, and a sequence of number as output values for each \\(N\\).\n Figure 4: Output of sequences of integers based on values of \\(N\\) from 0 to 4  Question: Determine the algorithm that was used to generate the numbers in this Figure. What is the result for \\(N=5\\)?\n   References [1] Hilton, AD; Lipp, GM; Rodger, SH, Translation from Problem to Code in Seven Steps, Comped 2019 Proceedings of the Acm Conference on Global Computing Education (2019), pp.¬†78-84.\n Answers Example 3 Algorithm sketch 3 N must be a Natural number with zero start with N = n, where n represents the value Minimum value = 4 * N Maximum value = 9 * N + 6 Increment of the sequence = 3 x[1] = Minimum value While x[i] is less than the Maximum value x[i] = x[i-1] + Increment of the sequence x is the answer # N = 6 N=5 seq \u0026lt;- seq(4*N, 9*N+6, 3) cat(\u0026quot;The answer is\u0026quot;, seq) ## The answer is 20 23 26 29 32 35 38 41 44 47 50 Did you find this page helpful? Consider sharing it üôå\n  ","date":1608076800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1608119583,"objectID":"2a434fb16cdef7db0fdaca23027b096c","permalink":"https://prof-thiagooliveira.netlify.com/post/the-seven-steps-of-a-programer/","publishdate":"2020-12-16T00:00:00Z","relpermalink":"/post/the-seven-steps-of-a-programer/","section":"post","summary":"Overview of the Seven Steps The seven steps proposed by Hilton et al.¬†(2019) is very interesting strategy to start a new project that involves programming process, where a summary of the entire process is shown in the Figure 1.","tags":["Algorithm","C++","Computer Science"],"title":"The seven steps of a programer","type":"post"},{"authors":["Thiago de Paula Oliveira","Georgie Bruinvels","Charles Pedlar","John Newell"],"categories":null,"content":"","date":1607558400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1607558400,"objectID":"019a1dece72ceaa27e7429675873733b","permalink":"https://prof-thiagooliveira.netlify.com/publication/2020-scireports/","publishdate":"2020-12-10T00:00:00Z","relpermalink":"/publication/2020-scireports/","section":"publication","summary":"Development of an appropriate parametric state-space formulation for the marginal distribution of standard menstrual cycles for female athletes","tags":["Menstrual cycle","Longitudinal data","State-Space Models","Athletes","Statistical Modelling","Hierarchical data"],"title":"Modelling menstrual cycle length in athletes using state-space models","type":"publication"},{"authors":["Thiago de Paula Oliveira","Rafael de Andrade Moral"],"categories":null,"content":"Abstract:\nThe continuously growing number of COVID-19 cases pressures healthcare services worldwide. Accurate short-term forecasting is thus vital to support country-level policy making. The strategies adopted by countries to combat the pandemic vary, generating different uncertainty levels about the actual number of cases. Accounting for the hierarchical structure of the data and accommodating extra-variability is therefore fundamental. We introduce a new modelling framework to describe the course of the pandemic with great accuracy, and provide short-term daily forecasts for every country in the world. We show that our model generates highly accurate forecasts up to six days ahead, and use estimated model components to cluster countries based on recent events. We introduce statistical novelty in terms of modelling the autoregressive parameter as a function of time, increasing predictive power and flexibility to adapt to each country. Our model can also be used to forecast the number of deaths, study the effects of covariates (such as lockdown policies), and generate forecasts for smaller regions within countries. Consequently, it has strong implications for global planning and decision making. We constantly update forecasts and make all results freely available to any country in the world through an online Shiny dashboard.\n","date":1605178800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1605178800,"objectID":"d21c73970b60035164ac402b09400a5c","permalink":"https://prof-thiagooliveira.netlify.com/talk/2020-young-isa/","publishdate":"2020-11-10T12:00:00Z","relpermalink":"/talk/2020-young-isa/","section":"talk","summary":"Accurate short-term forecasting is thus vital to support country-level policy making during COVID-19 outbreak","tags":["COVID-19","Outbreak","State-Space Model","Longitudinal Data"],"title":"Global Short-Term Forecasting of Covid-19 Cases","type":"talk"},{"authors":["Heloisa Thomazi Kleina1","Karla Kudlawiec","Mariana B. Esteves,","Marco A. Dalb√≥","Thiago de Paula Oliveira","Nathalie Maluta","Jo√£o R. S. Lopes","Louise L. May-De-Mio1"],"categories":null,"content":"","date":1597622400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1597622400,"objectID":"4d8941c87310fec1359b93fd5113237a","permalink":"https://prof-thiagooliveira.netlify.com/publication/2020-plant_pathology/","publishdate":"2020-08-17T00:00:00Z","relpermalink":"/publication/2020-plant_pathology/","section":"publication","summary":"We focused to investigate the host non preference and suitability for xylem-sap feeding among plum genotypes that differ in bacterial leaf scald intensity in the field.","tags":["Phytopathology","Statistical Modelling","Experimental design","Agriculture","Mixed-Effects Models","Generalized linear models","Hierarchical data"],"title":"Settling and feeding behavior of sharpshooter vectors on plum genotypes with different susceptibility levels to leaf scald disease (Xylella fastidiosa)","type":"publication"},{"authors":["Thiago de Paula Oliveira","Rafael de Andrade Moral","Silvio Sandoval Zocchi","Clarice G. B. Demetrio","John Hinde"],"categories":null,"content":"Supplementary notes were added here:\n lcc package  Github: https://github.com/Prof-ThiagoOliveira/lcc CRAN: https://CRAN.R-project.org/package=lcc    ","date":1597276800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1597276800,"objectID":"e82d87d3e10df07ca946d00c59174724","permalink":"https://prof-thiagooliveira.netlify.com/publication/2020-lccpeerj/","publishdate":"2020-08-13T00:00:00Z","relpermalink":"/publication/2020-lccpeerj/","section":"publication","summary":"Describes the statistical package lcc using three real examples.","tags":["R Package","Bootstrap Confidence Intervals","Statistical Methods","Longitudinal data","Concordance Correlation Coefficient","Accuracy","Precision","Mixed-Effects Model"],"title":"lcc: an R package to estimate the concordance correlation, Pearson correlation, and accuracy over time","type":"publication"},{"authors":["Thiago de Paula Oliveira","Rafael de Andrade Moral"],"categories":null,"content":"Supplementary notes were added here:\n  Github\n  Dashboard App\n  ","date":1590710400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1590710400,"objectID":"1d5f658795ef3d36ee6ca5bee4011ccb","permalink":"https://prof-thiagooliveira.netlify.com/publication/2020-covid/","publishdate":"2020-05-28T00:00:00Z","relpermalink":"/publication/2020-covid/","section":"publication","summary":"We showthat our model generates highly accurate forecasts up to six days ahead for covid-19 cases.","tags":["COVID-19","SARS-Cov-2","Pandemic","Statistical Methodology","Statistical Modelling","Longitudinal data","State-Space Models","Hierarchical data"],"title":"Global Short-Term Forecasting of Covid-19 Cases","type":"publication"},{"authors":["Thiago de Paula Oliveira","John Newell"],"categories":null,"content":"Abstract:\nIn basketball, the athlete performance evaluation are generally based on variants of plus-minus and PER statistics Optimizing Athlete Performance calculated through multiple regression, ridge, or lasso models using likelihood-based or Bayesian approach. We developed a novel methodology based on principal components analysis and multilevel model to create new indexes such as Oliveira-Newell Score that can be used to evaluate player performance during a match, relevance score used to rank players in a season, and the consistence score used to evaluate the player contribution for their team based on random effects.\n","date":1587463200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1587463200,"objectID":"439b54314b2e275dd39515978c06ba99","permalink":"https://prof-thiagooliveira.netlify.com/talk/2020-nuig/","publishdate":"2020-04-21T10:00:00Z","relpermalink":"/talk/2020-nuig/","section":"talk","summary":"Athlete performance evaluation based on novel methodology using principal components and multilevel models","tags":["Athlete Performance","Agreement Measures","Multilevel Model","Longitudinal Data"],"title":"Estimating NBA athlete performance using multilevel models","type":"talk"},{"authors":[],"categories":[],"content":"Summary Measuring color hue in \u0026lsquo;Sunrise Solo\u0026rsquo; papaya using a flatbed scanner\n Papaya Production   Global papaya producing (FAO, 2012):\n India: 38.61% (4,713,800) Brazil: 17.5% (1,871,300) Indonesia: 6.86% (695,214)    Brazil: $2^{\\circ}$ major papaya exporting (11.2% of global trade)\n  Papayas are classified according to size and color;\n   Colorimeter Methodology   Very efficient when the fruit has uniform coloration\n  It may be inefficient when the fruit does not have uniform coloration\n  Usually, samples are observed on the equatorial region of fruits\n   Colorimeter Methodology   The sample is observed from a very small area on the fruit\u0026rsquo;s peel\n  Problem:\n The sample cannot represents the equatorial region properly A sample on the equatorial region cannot represents the whole region     Digital Image Analysis   An alternative method proposed to evaluate the color of several fruits\n  Offers an objective measure for color and other physical factors\n  Most recent applications include:\n Fruit\u0026rsquo;s classification Postharvest quality evaluation Including meats, fruits, and seeds     Conclusions   Scanner can be used as a device to measure color components\n  Colorimeter and digital image analysis leads to defferents peel color measurements\n  Based on sample size we conclude:\n The usage of images analysis is preferable compared with colorimeter approach Digital images analysis should be used for fruits with non-uniform coloration    ","date":1583798400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1583798400,"objectID":"a9da0326489dc7c5c181f7e4edc100d7","permalink":"https://prof-thiagooliveira.netlify.com/slides/2017-papaya/","publishdate":"2020-03-10T00:00:00Z","relpermalink":"/slides/2017-papaya/","section":"slides","summary":"An introduction to using Academic's Slides feature.","tags":[],"title":"Slides","type":"slides"},{"authors":["Thiago de Paula Oliveira","John Newell"],"categories":null,"content":"Abstract:\nThe ability to predict menstrual cycle length to a high degree of precision enables female athletes to track their period and tailortheir training and nutrition correspondingly knowing when to push harder when to prioritise recovery and how to minimise theimpact of menstrual symptoms on performance. Such individualisation is possible if cycle length can be predicted to a highdegree of accuracy. To achieve this, a hybrid predictive model was built using data on 16,990 cycles collected from a sampleof 2,178 women (mean age 33.89 years, range 14.98 - 47.10, number of menstrual cycles ranging from 4 - 53). To capture thewithin-subject temporal correlation, a mixed-effect state-space model was fitted incorporating a Bayesian approach for processforecasting to predict the duration (in days) of the next menstrual cycle. The modelling procedure was split into three steps(i)a time trend component using a random walk with an overdispersion parameter, (ii) an autocorrelation component using anautoregressive moving-average (ARMA) model, and (iii) a linear predictor to account for covariates (e.g. injury, stomach cramps,training intensity). The inclusion of an overdispersion parameter suggested that26.81% [24.14%,29.58%]of cycles in the samplewere overdispersed where the random walk standard deviation under a non-overdispersed cycle is1.0530 [1.0060,1.0526]days whileunder an overdispersed cycle it increased to4.7386 [4.5379,4.9492]days. To assess the performance and prediction accuracy ofthe model, each woman‚Äôs last observation was used as test data. The Root Mean Square Error (RMSE), Concordance CorrelationCoefficient (CCC) and Pearson correlation coefficient (r) between the observed and predicted values were calculated. The modelhad an RMSE of 1.6126 days, a precision of 0.7501 and overall accuracy of 0.9855. In the absence of hormonal measurements,knowing how aspects of physiology and psychology are changing across the menstrual cycle has the potential to help femaleathletes personalise their training, nutrition and recovery tailored to their cycle to sustain peak performance at the highest leveland gain a competitive edge. In conclusion, the hybrid model presented here is a useful approach for predicting menstrual cyclelength which in turn can be used to support female athlete wellness to optimise performance ","date":1570179600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1570179600,"objectID":"14574e4e871fb3b9efd44ac2882f66ed","permalink":"https://prof-thiagooliveira.netlify.com/talk/2019-young-stats/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/talk/2019-young-stats/","section":"talk","summary":"Times are changing. At an elite level, female athletes and coaches across the globe are now starting to work with the menstrual cycle to gain a performance edge. By tracking the menstrual cycle, and knowing how, why and when hormone fluctuations affect female physiology, an athlete's training, nutrition and recovery can be tailored to their cycle to sustain peak performance\n","tags":["Bayesian Approach","State Space Models","Cycle Length","Performance","Autoregressive Models"],"title":"Modelling menstrual cycle length using state space models","type":"talk"},{"authors":["Gustavo V. Popin","Arthur K. B. Santos","Thiago de Paula Oliveira","Pl√≠nio B. de Camargo","Carlos E. P. Cerri","Marcos Siqueira-Neto"],"categories":null,"content":"Supplementary notes were added here, including figures.\n","date":1563235200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1563235200,"objectID":"5e8883e7dec03615d2d23522b2cb0e5a","permalink":"https://prof-thiagooliveira.netlify.com/publication/2019-soil/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/publication/2019-soil/","section":"publication","summary":"Evaluate the effects of global warming and straw removal on gas emissions","tags":["Global warming","Statistical Modelling","Gas emissions"],"title":"Sugarcane straw management for bioenergy: effects of global warming on greenhouse gas emissions and soil carbon storage","type":"publication"},{"authors":["Thiago de Paula Oliveira","Rafael de Andrade Moral","John Hinde","Silvio Sandoval Zocchi","Clarice Garcia Borges Demetrio"],"categories":null,"content":"Abstract:\nWe present the lcc package, available from the Comprehensive R Archive Network (CRAN). The package implements estimation procedures for the longitudinal concordance correlation (LCC), using fixed effects and variance components estimates from linear mixed models. The LCC is a quantity that measures the extent of agreement between two (or more) methods used to evaluate a response variable of interest and is frequently applied in medicine, pharmacology, and agronomy. The main features of the package are the estimation and inference of the extent of agreement using numerical and graphical summaries. Moreover, our approach presents flexibility in the sense that it accommodates both balanced and unbalanced experimental designs, allows for different within-group error structures, while also allowing for the inclusion of covariates in the linear predictor to control systematic variations in the response. We illustrate our methodology by comparing different methods used to measure the peel colour of fruit as an assessment of ripeness.\n","date":1559898000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1559898000,"objectID":"323893964181b4832931df0efac0dc46","permalink":"https://prof-thiagooliveira.netlify.com/talk/2019-iwsm/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/talk/2019-iwsm/","section":"talk","summary":"Abstract:\nWe present the lcc package, available from the Comprehensive R Archive Network (CRAN). The package implements estimation procedures for the longitudinal concordance correlation (LCC), using fixed effects and variance components estimates from linear mixed models.","tags":["R Package","Agreement Measures","Mixed-Effects Model","Longitudinal Data"],"title":"The longitudinal concordance correlation","type":"talk"},{"authors":["Thiago de Paula Oliveira","Rafael de Andrade Moral","Silvio S. Zocchi","Clarice G. B. Demetrio","John Hinde"],"categories":null,"content":"","date":1542326400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1542326400,"objectID":"45351a12a748374de8bdd61a5c271dc4","permalink":"https://prof-thiagooliveira.netlify.com/publication/2019-lcc-package/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/publication/2019-lcc-package/","section":"publication","summary":"We proposed an R package to estimate the longitudinal concordance correlation (LCC)","tags":["R Package","Bootstrap Confidence Intervals","Statistical Methods","Longitudinal data","Concordance Correlation Coefficient","Accuracy","Precision","Mixed-Effects Model"],"title":"lcc: Longitudinal Concordance Correlation","type":"publication"},{"authors":["Mariana B. Esteves","Heloisa T. Kleina","Tiago de Melo Sales","Thiago de Paula Oliveira","Idemauro A.R. Lara","Rodrigo P.P. Almeida","Helvecio D. Coletta-Filho","Jo√£o R.S. Lopes"],"categories":null,"content":"","date":1541808000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1541808000,"objectID":"6af98efad9f8f156e5616058ca2fbfe4","permalink":"https://prof-thiagooliveira.netlify.com/publication/2019-phitopatology/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/publication/2019-phitopatology/","section":"publication","summary":"Adapt and validate an in vitro acquisition system for X. fastidiosa by sharpshooters.","tags":["Phytopathology","Statistical Modelling","Experimental design","Agriculture","Mixed-Effects Models","Generalized linear models"],"title":"Transmission efficiency of xylella fastidiosa subsp. Pauca sequence types by sharpshooter vectors after in vitro acquisition","type":"publication"},{"authors":["Thiago de Paula Oliveira","Silvio S. Zocchi","John Hinde"],"categories":null,"content":"Supplementary notes were added here, including code and data.\n","date":1521676800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1521676800,"objectID":"f1a5a0e3d674f9b95525b671e1f8a5a5","permalink":"https://prof-thiagooliveira.netlify.com/publication/2018-lcc/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/publication/2018-lcc/","section":"publication","summary":"We proposed a longitudinal concordance correlation (LCC) to estimate agreement over time among methods","tags":["Longitudinal data","Concordance Correlation Coefficient","Accuracy","Precision","Statistical Modelling","Statistical Methods","R Package","Bootstrap Confidence Intervals","Mixed-Effects Model"],"title":"Longitudinal concordance correlation function based on variance components: an application in fruit color analysis","type":"publication"},{"authors":null,"categories":null,"content":"","date":1514764800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1514764800,"objectID":"4cd459fb2711ceefd52c827ba1c5dd33","permalink":"https://prof-thiagooliveira.netlify.com/project/sport-project/","publishdate":"2018-01-01T00:00:00Z","relpermalink":"/project/sport-project/","section":"project","summary":"Uniquely blending Data Science and Sports Science to generate customized strategies by athlete","tags":["Statistical modelling","Athlete performance","Biostatistics","Shiny App","Sports"],"title":"The use of biostatistics for optimizing athletes performance","type":"project"},{"authors":["Thiago de Paula Oliveira","Silvio S. Zocchi","Angelo P. M. Jacomino"],"categories":null,"content":"","date":1483228800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1483228800,"objectID":"0352785b21d368da5202302fd9ba162c","permalink":"https://prof-thiagooliveira.netlify.com/publication/2017-papaya/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/publication/2017-papaya/","section":"publication","summary":"It is recommended the usage of digital image analysis to access the fruit peel color when it has non-uniform coloration.","tags":["Fruit","Postharvest","Colour","Statistics"],"title":"Measuring color hue in 'Sunrise Solo' papaya using a flatbed scanner","type":"publication"},{"authors":null,"categories":null,"content":"","date":1461715200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1461715200,"objectID":"8c594946bd84a73e02ff7c1a2aefd944","permalink":"https://prof-thiagooliveira.netlify.com/project/color-project/","publishdate":"2016-04-27T00:00:00Z","relpermalink":"/project/color-project/","section":"project","summary":"Promote the usage of image analysis as well as development of statistical methodologies for that purpose.","tags":["Image Analysis","Digital Images","Circular Statistics","Agriculture"],"title":"Measuring color using image analyis","type":"project"},{"authors":null,"categories":null,"content":"","date":1461715200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1461715200,"objectID":"c6477ef5e689a66792634a2bc67116b5","permalink":"https://prof-thiagooliveira.netlify.com/project/concordance-project/","publishdate":"2016-04-27T00:00:00Z","relpermalink":"/project/concordance-project/","section":"project","summary":"Estimating longitudinal concordance correlation function","tags":["Agreement","Precision","Accuracy","R packages"],"title":"The lcc Package","type":"project"},{"authors":null,"categories":null,"content":"          ","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"665288c8761d48eb3366c37954243edc","permalink":"https://prof-thiagooliveira.netlify.com/gallery/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/gallery/","section":"","summary":"          ","tags":null,"title":"Photos","type":"page"}]