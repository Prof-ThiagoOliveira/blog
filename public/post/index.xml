<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Posts | Thiago Oliveira</title>
    <link>https://prof-thiagooliveira.netlify.com/post/</link>
      <atom:link href="https://prof-thiagooliveira.netlify.com/post/index.xml" rel="self" type="application/rss+xml" />
    <description>Posts</description>
    <generator>Wowchemy (https://wowchemy.com)</generator><language>en-us</language><copyright>¬© 2021 Thiago Oliviera</copyright><lastBuildDate>Fri, 19 Jan 2024 00:00:00 +0000</lastBuildDate>
    <image>
      <url>https://prof-thiagooliveira.netlify.com/media/icon_hucac388deec264b13c6395804f04d3e9e_484996_512x512_fill_lanczos_center_3.png</url>
      <title>Posts</title>
      <link>https://prof-thiagooliveira.netlify.com/post/</link>
    </image>
    
    <item>
      <title>Main elements and questions of a good experimental plan.</title>
      <link>https://prof-thiagooliveira.netlify.com/post/experimental_design/</link>
      <pubDate>Sat, 27 Jun 2020 00:00:00 +0000</pubDate>
      <guid>https://prof-thiagooliveira.netlify.com/post/experimental_design/</guid>
      <description>&lt;h3 id=&#34;did-you-find-this-page-helpful-consider-sharing-it-&#34;&gt;Did you find this page helpful? Consider sharing it üôå&lt;/h3&gt;
</description>
    </item>
    
    <item>
      <title>Exploring Polynomial, Fractional Polynomial, and Spline Models</title>
      <link>https://prof-thiagooliveira.netlify.com/post/statistics/</link>
      <pubDate>Fri, 19 Jan 2024 00:00:00 +0000</pubDate>
      <guid>https://prof-thiagooliveira.netlify.com/post/statistics/</guid>
      <description>&lt;p align=&#34;justify&#34;&gt;
The ability to accurately model and interpret complex data sets is paramount. This technical exploration delves into three sophisticated modelling techniques:
&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Polynomial Models&lt;/strong&gt;,&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Fractional Polynomials&lt;/strong&gt;, and&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Spline Models&lt;/strong&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;p align=&#34;justify&#34;&gt;
Each of these models serves as a fundamental tool in the statistical toolkit, enabling us to capture and understand the intricacies of linear and non-linear relationships inherent in real-world data.
&lt;/p&gt;
&lt;p align=&#34;justify&#34;&gt;
As a bio-statistician entrenched in the technical aspects of data analysis, I recognize the critical importance of these models. We will commence with an examination of Polynomial Models, discussing their mathematical underpinnings and practical applications in capturing curvilinear trends. Next, we will navigate through the Fractional Polynomials, a more flexible extension of traditional polynomials, adept at modelling asymmetric patterns. Lastly, we will explore Spline Models, one of the most flexible approach in data fitting, capable of adapting to complex and segmented patterns in data.
&lt;/p&gt;
&lt;p align=&#34;justify&#34;&gt;
This post is designed not just to inform but to provide a technical understanding of these models with examples, illustrating their relevance and application in contemporary data analysis. Whether you are a data scientist, a statistician, or a researcher grappling with complex data sets, this exploration aims to enhance the modelling arsenal, offering insights into when and how to apply these models effectively.
&lt;/p&gt;
&lt;h1 id=&#34;polynomial-models&#34;&gt;Polynomial Models&lt;/h1&gt;
&lt;p align=&#34;justify&#34;&gt;
[Polynomial Models](https://en.wikipedia.org/wiki/Polynomial), represented by functions of the form $$y = a_n x^n + a_{n-1} x^{n-1} + \ldots + a_1 x + a_0,$$ are foundational in modelling curvilinear relationships. In this formulation, each $a_i$ (where $i = 0, 1, \ldots, n$) denotes the coefficient corresponding to the $i$-th term of the polynomial, and $x$ is the independent or exploratory variable. The degree $n$ of the polynomial determines the model&#39;s complexity, with higher degrees allowing for more intricate curve shapes.
&lt;/p&gt;
&lt;p align=&#34;justify&#34;&gt;
These models are particularly useful in capturing the non-linear dynamics often observed in real-world data. For instance, a quadratic model (where $n = 2$) can describe simple parabolic trends, while higher-degree models, such as cubic ($n = 3$) or quartic ($n = 4$), enable the representation of more complex and varied behaviours (Figure 1).
&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-{r,echo=FALSE,fig.cap=&amp;quot;Comparative&#34;&gt;knitr::include_graphics(&#39;polynomial.png&#39;)
&lt;/code&gt;&lt;/pre&gt;
&lt;p align=&#34;justify&#34;&gt;
However, increasing the degree $n$ also increases the risk of overfitting, a phenomenon where the model adapts too closely to the specificities of the training data, including noise, at the expense of generalizability to new data (Figure 2). Overfitting leads to models that perform poorly in predictive scenarios, failing to capture the true underlying trend.
&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-{r,echo=FALSE,fig.cap=&amp;quot;Visualizing&#34;&gt;knitr::include_graphics(&#39;poly_overfit.png&#39;)
&lt;/code&gt;&lt;/pre&gt;
&lt;p align=&#34;justify&#34;&gt;
Polynomial models are extensively applied across various disciplines. In physics, they are instrumental in [modelling motion](https://aapm.onlinelibrary.wiley.com/doi/abs/10.1118/1.2739811) under uniform acceleration, among other phenomena. In economics, [polynomial trends are fitted to time series data](https://www.sciencedirect.com/science/article/abs/pii/S0378475405000418) to understand market dynamics. In biological sciences, these models aid in [interpreting growth rates](https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1574-0862.2010.00450.x) and [simple gene expression patterns](https://bmcgenomics.biomedcentral.com/articles/10.1186/s12864-017-4304-3). The interpretation of the coefficients $a_i$ can provide significant insights; for instance, in the quadratic model $y = ax^2 + bx + c$, the sign of $a$ determines the direction in which the parabola opens, offering crucial information about the nature of the relationship being modelled (Figure 3).
&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-{r,echo=FALSE,fig.cap=&amp;quot;Parabola&#34;&gt;knitr::include_graphics(&#39;parabola.png&#39;)
&lt;/code&gt;&lt;/pre&gt;
&lt;p align=&#34;justify&#34;&gt;
In practical applications, the selection of the polynomial degree $n$ is critical. It is a balance between capturing the complexity of the data and avoiding overfitting (Figure 2). Techniques such as cross-validation, where the data is divided into training and testing sets, can be used to determine the optimal degree of the polynomial. Additionally, statistical measures like the Akaike Information Criterion (AIC) or the Bayesian Information Criterion (BIC) are often employed to select the most appropriate model by balancing model fit and complexity.
&lt;/p&gt;
&lt;p align=&#34;justify&#34;&gt;
In summary, Polynomial Models are a versatile and powerful tool in statistical modelling. Their ability to approximate complex functions with a relatively straightforward mathematical formulation makes them a fundamental component in various fields of data analysis.
&lt;/p&gt;
&lt;p align=&#34;justify&#34;&gt;
While traditional polynomial models are highly effective, they sometimes lack the flexibility required for certain types of data, particularly those exhibiting asymmetric trends. This limitation led to the development of fractional polynomial models, which extend the concept of polynomial models by allowing for fractional exponents. This advancement provides a greater ability to fit a wider range of curves and is especially useful in cases where the relationship between variables is not adequately captured by integer exponents.
&lt;/p&gt;
&lt;h1 id=&#34;fractional-polynomial-models&#34;&gt;Fractional Polynomial Models&lt;/h1&gt;
&lt;p align=&#34;justify&#34;&gt;
[Fractional Polynomials](https://academic.oup.com/jrsssc/article-abstract/43/3/429/6990357) represent an advanced evolution of traditional polynomial models, marked by their use of non-integer, real-number exponents in the independent variable. Mathematically, they are expressed as $$y = \beta_0 + \beta_1 x^{p_1} + \beta_2 x^{p_2} + \ldots + \beta_n x^{p_n},$$ where $x$ is the independent variable, $\beta_i$ are coefficients, and $p_i$ are the variable powers. These powers, unlike the integer-only powers in traditional polynomials, can include any real number like $0.5$, $-1$, or $2.3$. This flexibility significantly broadens the modeling capability of polynomials, allowing for more precise fitting to complex and asymmetric data patterns. Terms such as $x^{-1}$ and $x^{0.5}$, representing the reciprocal and square root of $x$ respectively, enable the modeling of relationships that exhibit dramatic changes over different ranges of $x$, a task challenging for standard polynomial models with integer exponents.
&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-{r,echo=FALSE,fig.cap=&amp;quot;Comparative&#34;&gt;knitr::include_graphics(&#39;frac_poly.png&#39;)
&lt;/code&gt;&lt;/pre&gt;
&lt;p align=&#34;justify&#34;&gt;
The utility of fractional polynomials extends to various fields, notably in medical statistics and biological data analysis, where data patterns often defy symmetry. They are particularly adept in modeling phenomena like dose-response curves in pharmacokinetics and progression rates of diseases, where the response changes in a non-linear fashion. Such flexibility makes them invaluable in scenarios where data exhibit complex, non-standard behaviors.
&lt;/p&gt;
&lt;p align=&#34;justify&#34;&gt;
However, the complexity of fractional polynomials can pose interpretational challenges, and like their traditional counterparts, they are susceptible to overfitting. This risk is heightened with the inclusion of multiple fractional terms or higher degrees, necessitating careful model selection and validation processes. Methods such as cross-validation or the use of information criteria like AIC or BIC are often employed to balance model fit against the risk of overfitting.
&lt;/p&gt;
&lt;h2 id=&#34;finding-optimal-power-values-in-fractional-polynomials&#34;&gt;Finding Optimal Power Values in Fractional Polynomials&lt;/h2&gt;
&lt;p align=&#34;justify&#34;&gt;
The process of finding the best values for $p_1, p_2, \ldots, p_n$ is inherently iterative and may require a combination of statistical testing, validation techniques, and expert judgement. The goal is to have a balance between a model that fits the data well, is not overly complex, and is robust to variations in model parameters.
&lt;/p&gt;
&lt;p align=&#34;justify&#34;&gt;
In Figure 5, I exemplify this process by fitting various fractional polynomial models to the dataset. Through the application of the Bayesian Information Criterion (BIC), I identified the most parsimonious model, which is succinctly expressed mathematically as $$y = \beta_0 + \beta_1 x^{1.13},$$ and the corresponding BIC value for this model is denoted as $‚àí144.34$.
&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-{r,echo=FALSE,fig.cap=&amp;quot;Comparative&#34;&gt;knitr::include_graphics(&#39;fractional_polynomial_fit_with_bic.gif&#39;)
&lt;/code&gt;&lt;/pre&gt;
&lt;p align=&#34;justify&#34;&gt;
Below I have described some possible approaches to achieve this objective:
&lt;/p&gt;
&lt;p align=&#34;justify&#34;&gt;
**Initial Power Selection**: Start with a set of candidate powers, often including a mix of positive, negative, and fractional values. Common choices are \(-2, -1, -0.5, 0, 0.5, 1, 2, 3\). The selection of these initial powers is guided by prior knowledge about the data, theoretical considerations, or exploratory analysis.
&lt;/p&gt;
&lt;p align=&#34;justify&#34;&gt;
**Model Fitting and Comparison**: Fit fractional polynomial models using different combinations of these candidate powers. This fitting can be done using least squares regression or other suitable methods depending on the nature of the data. For each model, compute a goodness-of-fit statistic, such as the residual sum of squares (RSS) or the Akaike Information Criterion (AIC).
&lt;/p&gt;
&lt;p align=&#34;justify&#34;&gt;
**Iterative Testing**: Employ an iterative approach to test various combinations of powers. This might involve starting with a simple model and gradually adding complexity (increasing the number of terms) while monitoring the improvement in the fit. 
&lt;/p&gt;
&lt;p align=&#34;justify&#34;&gt;
**Cross-Validation**: To guard against overfitting, especially in models with higher degrees or more terms, use cross-validation. Divide your data into training and testing sets. Fit the model to the training set and evaluate its performance on the testing set. This step helps in assessing the model&#39;s predictive accuracy.
&lt;/p&gt;
&lt;p align=&#34;justify&#34;&gt;
**Statistical Significance**: Assess the statistical significance of the coefficients associated with each term in the model. Non-significant terms might suggest that certain powers do not contribute meaningfully to the model and could be excluded.
&lt;/p&gt;
&lt;p align=&#34;justify&#34;&gt;
**Model Selection Criteria**: Use model selection criteria like AIC or BIC to compare models with different combinations of powers. These criteria balance the goodness of fit with the complexity of the model, helping to choose a model that is both accurate and parsimonious.
&lt;/p&gt;
&lt;p align=&#34;justify&#34;&gt;
**Sensitivity Analysis**: Conduct sensitivity analyses by varying the powers slightly to see how robust the model is to changes in these parameters. This step is crucial to understand the stability and reliability of the model.
&lt;/p&gt;
&lt;p align=&#34;justify&#34;&gt;
While fractional polynomials offer enhanced modelling flexibility over traditional polynomials, they sometimes fall short in handling data with distinct behavioural changes across different segments. This limitation summed to the difficulty in determine $p_i$ are where spline models come into play. Spline models, constructed as piecewise polynomials, provide localized fitting capabilities, adapting seamlessly to variations within different data segments. Such adaptability is particularly useful in datasets with distinct phases or regimes. Thus, spline models emerge as a natural progression when fractional polynomials alone are insufficient to model the intricate patterns present in the data
&lt;/p&gt;
&lt;h1 id=&#34;spline-models&#34;&gt;Spline Models&lt;/h1&gt;
&lt;p align=&#34;justify&#34;&gt;
[Splines](https://www.taylorfrancis.com/chapters/edit/10.1201/9780203738535-7/generalized-additive-models-trevor-hastie) are a class of mathematical functions used in statistical modeling, defined as piecewise polynomials that are joined at specific points called knots. Mathematically, if we denote a spline function by $S(x)$, it can be represented as:
$$S(x) = \begin{cases} 
P_1(x) &amp; \text{for } x \leq k_1, \\
P_2(x) &amp; \text{for } k_1 &lt; x \leq k_2, \\
\vdots \\
P_n(x) &amp; \text{for } x &gt; k_{n-1},
\end{cases}$$
where $P_i(x)$ are polynomial functions of degree $d$, typically represented as $$P_i(x) = a_{i0} + a_{i1}x + a_{i2}x^2 + \ldots + a_{id}x^d$$ for each piece of the spline, with $a_{i0}, a_{i1}, \ldots, a_{id}$ being the coefficients that vary from one segment of the spline to another. The knots $k_1, k_2, \ldots, k_{n-1}$ are specific values in the domain of $x$ where these polynomial pieces meet. Splines ensure continuity and smoothness at these knots by enforcing that both the function and its derivatives up to degree $d-1$ are continuous across the knots. This mathematical formulation allows splines to flexibly model a wide range of functions by varying the number and position of the knots as well as the degree of the polynomial pieces.
&lt;/p&gt;
&lt;p align=&#34;justify&#34;&gt;
Splines, with their diverse forms, can have a variety of applications, each type distinguished by its unique features and mathematical formulation. Linear splines represent the most basic form, where each segment $P_i(x)$ is a linear function, typically $P_i(x) = a_{i0} + a_{i1}x$. These are straightforward to compute and are used in applications requiring simple, piecewise linear approximations.
&lt;/p&gt;
&lt;p align=&#34;justify&#34;&gt;
Cubic splines elevate the complexity and smoothness, with each $P_i(x)$ being a third-degree polynomial: $$P_i(x) = a_{i0} + a_{i1}x + a_{i2}x^2 + a_{i3}x^3$$. Their widespread adoption is attributed to their ability to model smooth, continuous curves, making them highly suitable for applications in curve fitting, computer-aided design, and modelling non-linear relationships in data.
&lt;/p&gt;
&lt;p align=&#34;justify&#34;&gt;
[B-splines](https://link.springer.com/content/pdf/10.1007/978-0-387-84858-7_5.pdf), or basis splines, while they can also be cubic, offer a more general and flexible approach. They are defined not by the splines themselves, but by a set of basis functions, which are piecewise polynomials of a specified degree. The key advantage of B-splines is their local control; adjustments in one part of the spline affect only a limited region around that part. This is due to their basis functions having minimal support, which means each function is non-zero only over a small interval. 
&lt;/p&gt;
&lt;p align=&#34;justify&#34;&gt;
For B-splines, the mathematical representation shifts from individual polynomial pieces to a sum of basis functions, each weighted by a coefficient. These basis functions are defined over the knots and have local support. The B-spline representation can be expressed as:
&lt;/p&gt;
&lt;p&gt;$$S(x) = \sum_{i=0}^{n+d} B_{i,d}(x) \cdot c_i$$&lt;/p&gt;
&lt;p align=&#34;justify&#34;&gt;
Here, $B_{i,d}(x)$ are the B-spline basis functions of degree $d$, and $c_i$ are the coefficients. The basis functions $B_{i,d}(x)$ are defined recursively, starting with degree 0 (piecewise constant functions) and building up to the desired degree. The recursive definition for a B-spline basis function of degree $d$ is given by:
&lt;/p&gt;
&lt;p&gt;$$ B_{i,0}(x) = \begin{cases} 
1 &amp;amp; \text{if } k_i \leq x &amp;lt; k_{i+1}, \
0 &amp;amp; \text{otherwise},
\end{cases} $$&lt;/p&gt;
&lt;p&gt;$$ B_{i,d}(x) = \frac{x - k_i}{k_{i+d} - k_i} B_{i,d-1}(x) + \frac{k_{i+d+1} - x}{k_{i+d+1} - k_{i+1}} B_{i+1,d-1}(x) $$&lt;/p&gt;
&lt;p align=&#34;justify&#34;&gt;
The knots $k_0, k_1, \ldots, k_{n+d}$ in the case of B-splines extend beyond the range of the data to ensure that the spline is well-defined at the boundaries. This expansion of the knot sequence provides a framework for the B-spline basis functions to cover the entire domain of the data. Unlike traditional splines, where each polynomial piece is defined explicitly, B-splines construct the spline function as a linear combination of these basis functions, providing a high degree of flexibility and local control over the shape of the spline. This formulation allows for efficient computation and adjustments in a localized manner, making B-splines a powerful tool for modelling complex data in various applications.&lt;/p&gt;
&lt;/p&gt;
&lt;h2 id=&#34;example&#34;&gt;Example&lt;/h2&gt;
&lt;p align=&#34;justify&#34;&gt;
Figure 6 visualizes the fitting of four distinct statistical models to a dataset: 
&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;a cubic polynomial,&lt;/li&gt;
&lt;li&gt;a fractional polynomial,&lt;/li&gt;
&lt;li&gt;a cubic spline, and&lt;/li&gt;
&lt;li&gt;a B-spline.&lt;/li&gt;
&lt;/ul&gt;
&lt;p align=&#34;justify&#34;&gt;
The explanatory variable is shown along the x-axis, while the response variable is on the y-axis.
&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-{r,echo=FALSE,fig.cap=&amp;quot;Comparison&#34;&gt;knitr::include_graphics(&#39;splines.png&#39;)
&lt;/code&gt;&lt;/pre&gt;
&lt;p align=&#34;justify&#34;&gt;
The plot provides a comparative visualization of four distinct statistical models applied to the same data set, with the cubic polynomial model (solid red line) demonstrating a poor fit. It captures the global tendency but lacks the intricacy to model local data variations, likely due to its restrictive assumption of a single global function without &#39;breaks&#39;. In contrast, the fractional polynomial (dotted blue line) incorporates power transformations of the explanatory variable, allowing for a more flexible functional form and better accommodation of non-linear relationships within the data. Nevertheless, it continues to apply a global approach to the data, which is evidently insufficient for modelling the localized fluctuations observed in the dataset. Both models underperform, suggesting that their global fitting strategies are inadequate for datasets. A more complex polynomial might offer an enhanced fit, but at the risk of overfitting, which must be judiciously managed.
&lt;/p&gt;
&lt;p align=&#34;justify&#34;&gt;
More nuanced fits are achieved with the spline-based models. The cubic spline (dashed green line) employs piecewise third-degree polynomials, joining at the knots‚Äîstrategically placed along the domain of the explanatory variable‚Äîto enhance model flexibility. This allows the cubic spline to conform more closely to the data&#39;s local variations and structural shifts. The B-spline model (long-dashed purple line), with its basis function approach, offers a superior level of smoothness and local control, manifesting in its ability to trace the dataset&#39;s oscillatory pattern with considerable precision.
&lt;/p&gt;
&lt;p align=&#34;justify&#34;&gt;
The visual assessment thus underscores the critical role of model selection in statistical analysis, emphasizing that the appropriateness of a model is contingent upon its alignment with the data&#39;s inherent patterns and the analysis objectives. The choice of model has profound implications for the accuracy of predictions and the robustness of inferences drawn from the data.
&lt;/p&gt;
&lt;h2 id=&#34;challenges&#34;&gt;Challenges&lt;/h2&gt;
&lt;p align=&#34;justify&#34;&gt;
The primary challenge in using spline models lies in the selection of knots. The number and location of knots significantly influence the model&#39;s complexity and its ability to capture underlying patterns in data. Too few knots can lead to underfitting, while too many can cause overfitting. There is no universal method for optimal knot placement, often requiring a combination of data-driven techniques and expert judgement. Additionally, spline models can become computationally intensive with an increasing number of knots.
&lt;/p&gt;
&lt;p align=&#34;justify&#34;&gt;
Splines are implemented through specialized algorithms that construct the piecewise polynomial functions and determine the appropriate knot positions, like in the `R` package `splines`. These algorithms often utilize basis functions, such as B-spline basis functions, which provide a stable and efficient way to represent spline curves. Computational techniques, like penalized least squares for smoothing splines, are employed to balance model fit and smoothness. Most statistical software packages offer built-in functions for spline modelling, simplifying their application in practical scenarios.
&lt;/p&gt;
&lt;h2 id=&#34;selection-process-for-spline-models&#34;&gt;Selection Process for Spline Models&lt;/h2&gt;
&lt;p align=&#34;justify&#34;&gt;
The selection process for spline models involves determining the optimal type and number of splines, along with the placement of knots, to best fit the data while avoiding overfitting. This process is a critical step in spline modelling and typically involves a blend of statistical techniques and domain expertise.
&lt;p align=&#34;justify&#34;&gt;
**Type Selection**: The first step is choosing the type of spline (e.g., linear, cubic, B-spline, smoothing spline). The choice depends on the nature of the data and the smoothness required in the model. For instance, cubic splines are often chosen for their balance between flexibility and smoothness.
&lt;/p&gt;
&lt;p align=&#34;justify&#34;&gt;
**Number of Knots**: Deciding on the number of knots is crucial as it controls the flexibility of the spline model. As explained previously, fewer knots result in a smoother, but potentially underfit model, while more knots can capture finer details but risk overfitting. Methods like cross-validation can be used to determine an optimal number of knots (`caret` package in `R`). In cross-validation, the data is divided into subsets; the model is trained on some subsets and validated on others, with the goal of minimizing prediction error.
&lt;/p&gt;
&lt;p align=&#34;justify&#34;&gt;
**Knot Placement**: The location of knots is equally important. Knots can be placed at quantiles of the independent variable, which is a common strategy for evenly distributing them across the range of data. Alternatively, adaptive methods can be used where knot placement is data-driven, focusing on regions where the function appears to change rapidly.
&lt;/p&gt;
&lt;p align=&#34;justify&#34;&gt;
**Model Complexity and Regularization**: For smoothing splines, the degree of smoothness is controlled by a smoothing parameter. Techniques like the Akaike Information Criterion (AIC), Bayesian Information Criterion (BIC), or [generalized cross-validation (GCV)](https://www.sciencedirect.com/science/article/abs/pii/S0005109817306416)
 are used to select this parameter. These methods aim to find a balance between the goodness of fit and the complexity of the model.
&lt;/p&gt;
&lt;p align=&#34;justify&#34;&gt;
**Model Validation**: After selecting the spline model, it is validated using unseen data or through resampling methods like bootstrapping. This step is crucial to ensure that the model generalizes well and does not merely capture the idiosyncrasies of the training data.
&lt;/p&gt;
&lt;h1 id=&#34;citation&#34;&gt;Citation&lt;/h1&gt;
&lt;ol&gt;
&lt;li&gt;For attribution, please cite this work as:&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;::: div-1
Oliveira T.P. (2024, Jan. 25). Exploring the Technicalities of Data Fitting - Polynomial, Fractional Polynomial, and Spline Models
:::&lt;/p&gt;
&lt;ol start=&#34;2&#34;&gt;
&lt;li&gt;BibTeX citation&lt;/li&gt;
&lt;/ol&gt;
&lt;pre&gt;&lt;code&gt;@misc{oliveira2024polynomials,
  author = {Oliveira, Thiago},
  title = {Exploring the Technicalities of Data Fitting - Polynomial, Fractional Polynomial, and Spline Models},
  url = {https://prof-thiagooliveira.netlify.app/post/exploring-the-technicalities-of-data-fitting-polynomial-fractional-polynomial-and-spline-models/},
  year = {2024}
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;Did you find this page helpful? Consider sharing it üôå&lt;/strong&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Precision &amp; Accuracy - The Role of Concordance Correlation in Research</title>
      <link>https://prof-thiagooliveira.netlify.com/post/statistics/</link>
      <pubDate>Wed, 17 Jan 2024 00:00:00 +0000</pubDate>
      <guid>https://prof-thiagooliveira.netlify.com/post/statistics/</guid>
      <description>


&lt;p align=&#34;justify&#34;&gt;
The Concordance Correlation Coefficient (CCC) is a statistical measure designed to evaluate the agreement between two sets of measurements, such as those represented by two random variables, &lt;span class=&#34;math inline&#34;&gt;\(X\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(Y\)&lt;/span&gt;. Mathematically, the CCC is defined as:
&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\rho_c = \frac{2\sigma_{x,y}}{\sigma_x^2 + \sigma_y^2 + (\mu_x - \mu_y)^2} = \frac{2\rho\sigma_x\sigma_y}{\sigma_x^2 + \sigma_y^2 + (\mu_x - \mu_y)^2} = \rho \times C_b.\]&lt;/span&gt;&lt;/p&gt;
&lt;p align=&#34;justify&#34;&gt;
In this formula, &lt;span class=&#34;math inline&#34;&gt;\(\sigma_x\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\sigma_y\)&lt;/span&gt; are the standard deviations of &lt;span class=&#34;math inline&#34;&gt;\(X\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(Y\)&lt;/span&gt;, respectively, showing the variability within each set of measurements. The means, &lt;span class=&#34;math inline&#34;&gt;\(\mu_x\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\mu_y\)&lt;/span&gt;, represent the central tendency of each dataset. The term &lt;span class=&#34;math inline&#34;&gt;\(\rho\)&lt;/span&gt; is Pearson‚Äôs correlation coefficient, expressing the linear association between &lt;span class=&#34;math inline&#34;&gt;\(X\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(Y\)&lt;/span&gt;, while &lt;span class=&#34;math inline&#34;&gt;\(C_b\)&lt;/span&gt;, the bias correction factor, quantifies the deviation of the best-fit line from the 45-degree line through the origin‚Äîthe line of perfect agreement. A &lt;span class=&#34;math inline&#34;&gt;\(C_b\)&lt;/span&gt; of 1 indicates no bias, and values close to 1 signify an accurate agreement.
&lt;/p&gt;
&lt;p align=&#34;justify&#34;&gt;
Understanding the concepts of precision and accuracy is crucial for grasping the essence of CCC (Concordance Correlation Coefficient). Let‚Äôs break down these components:
&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;p align=&#34;justify&#34;&gt;
&lt;strong&gt;Precision&lt;/strong&gt;: This aspect refers to the consistency or repeatability of measurements (Figure 1). Imagine a target with a bullseye:
&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p align=&#34;justify&#34;&gt;
If you shoot a series of arrows, and they all land very close to each other but not necessarily near the bullseye, this demonstrates high precision. The arrows are consistently hitting the same spot, showing that your measurements (in this case, arrow shots) are repeatable and reliable.
&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p align=&#34;justify&#34;&gt;
However, high precision does not guarantee that you are hitting the target accurately. Your consistent shots might be clustered in a corner of the target, far from the bullseye.
&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;p align=&#34;justify&#34;&gt;
&lt;strong&gt;Accuracy&lt;/strong&gt;: This term refers to how close the measurements are to the ‚Äòtrue‚Äô or accepted value (Figure 1). Continuing with the target analogy:
&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p align=&#34;justify&#34;&gt;
If your arrows hit or are very close to the bullseye, this indicates high accuracy. You are hitting the correct or intended spot.
&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p align=&#34;justify&#34;&gt;
It‚Äôs possible to be accurate without being precise if your arrows are scattered all around the bullseye, each hitting close but not in a consistent pattern.
&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;div class=&#34;figure&#34; style=&#34;text-align: center&#34;&gt;&lt;span style=&#34;display:block;&#34; id=&#34;fig:unnamed-chunk-1&#34;&gt;&lt;/span&gt;
&lt;img src=&#34;dartboard_precision_accuracy.gif&#34; alt=&#34;Example of precision and accuracy concept. The red dot in the center represents the bullseye.&#34; width=&#34;500px&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;
Figure 1: Example of precision and accuracy concept. The red dot in the center represents the bullseye.
&lt;/p&gt;
&lt;/div&gt;
&lt;p align=&#34;justify&#34;&gt;
Now, applying these concepts to CCC. The &lt;strong&gt;CCC measures both the precision and accuracy of a set of measurements&lt;/strong&gt;. It assesses the strength of the relationship between two variables (precision) and how closely these measurements agree with the ‚Äòtrue‚Äô or accepted values (accuracy). A high CCC indicates that not only are the measurements consistent with each other (precision), but they also closely match the true values (accuracy). In our analogy, this would be like consistently hitting the bullseye with every arrow.
&lt;/p&gt;
&lt;p align=&#34;justify&#34;&gt;
Furthermore, in the context of CCC, the concept of a ‚Äútrue‚Äù value is central. One variable is considered the standard or ‚Äútrue‚Äù measurement against which the other is compared. This distinction is vital because CCC is not merely a correlation but a measure of agreement. The notion of a ‚Äútrue‚Äù value in scientific research is intricate, often defined by theoretical constructs or consensus standards, and the assumption of truth can be challenged or refined with advancing knowledge and technology. Thus, CCC offers a way to quantitatively assess how well our measurements reflect what we accept as true, acknowledging that our understanding of ‚Äútrue‚Äù can evolve.
&lt;/p&gt;
&lt;p align=&#34;justify&#34;&gt;
To illustrate, in Scenario 1, even with a Pearson correlation near 1, the CCC‚Äôs modest value signals a discrepancy from the true value, reflecting either a systematic bias or scale differences between the measurements. The dashed red line represents the line of perfect agreement, where the true values would ideally lie. This scenario underscores the necessity of considering both precision and accuracy‚Äîwhere precision alone can mislead, and accuracy is pivotal for measurements to be meaningful and trustworthy.
&lt;/p&gt;
&lt;div class=&#34;figure&#34; style=&#34;text-align: center&#34;&gt;&lt;span style=&#34;display:block;&#34; id=&#34;fig:unnamed-chunk-2&#34;&gt;&lt;/span&gt;
&lt;img src=&#34;scenario1.png&#34; alt=&#34;Scenario 1 - High Pearson correlation with modest CCC indicating possible systematic bias or scale differences. The dashed line represents perfect agreement&#34; width=&#34;500px&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;
Figure 2: Scenario 1 - High Pearson correlation with modest CCC indicating possible systematic bias or scale differences. The dashed line represents perfect agreement
&lt;/p&gt;
&lt;/div&gt;
&lt;p align=&#34;justify&#34;&gt;
Scenario 2 presents a contrasting picture with a CCC value of 0.95, indicating not only a strong linear relationship but also a high degree of concordance. In this instance, the measurements not only follow a consistent pattern (precision) but also align closely with the line of perfect agreement (accuracy), suggesting that one set of measurements can be reliably used as a surrogate for the true values.
&lt;/p&gt;
&lt;div class=&#34;figure&#34; style=&#34;text-align: center&#34;&gt;&lt;span style=&#34;display:block;&#34; id=&#34;fig:unnamed-chunk-3&#34;&gt;&lt;/span&gt;
&lt;img src=&#34;scenario2.png&#34; alt=&#34;Scenario 2 - Strong linear relationship and high concordance with CCC at 0.95. The dashed line indicates the line of perfect agreement&#34; width=&#34;500px&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;
Figure 3: Scenario 2 - Strong linear relationship and high concordance with CCC at 0.95. The dashed line indicates the line of perfect agreement
&lt;/p&gt;
&lt;/div&gt;
&lt;p align=&#34;justify&#34;&gt;
In Scenario 3, we explore a scenario characterized by a negative Pearson correlation coefficient of approximately -0.44 and a Concordance Correlation Coefficient (CCC) of -0.43. This specific case demands a tailored approach to understanding concordance within inverse relationships. Instead of using the &lt;span class=&#34;math inline&#34;&gt;\(Y = X\)&lt;/span&gt; line commonly associated with positive correlations, we introduce a new reference line represented by &lt;span class=&#34;math inline&#34;&gt;\(Y = 100 - X\)&lt;/span&gt; (depicted as the black dashed line in the plot). This reference line possesses a slope of -1 and serves as the benchmark for perfect inverse agreement.
&lt;/p&gt;
&lt;div class=&#34;figure&#34; style=&#34;text-align: center&#34;&gt;&lt;span style=&#34;display:block;&#34; id=&#34;fig:unnamed-chunk-4&#34;&gt;&lt;/span&gt;
&lt;img src=&#34;scenario3.png&#34; alt=&#34;Scenario 3: Inverse relationship with both Pearson correlation and CCC around -0.44. The red dashed line represents $Y = X$, the black dashed line is the $Y = 100 - X$, and the blue solid line is the best fit line&#34; width=&#34;500px&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;
Figure 4: Scenario 3: Inverse relationship with both Pearson correlation and CCC around -0.44. The red dashed line represents &lt;span class=&#34;math inline&#34;&gt;\(Y = X\)&lt;/span&gt;, the black dashed line is the &lt;span class=&#34;math inline&#34;&gt;\(Y = 100 - X\)&lt;/span&gt;, and the blue solid line is the best fit line
&lt;/p&gt;
&lt;/div&gt;
&lt;p align=&#34;justify&#34;&gt;
The noteworthy aspect of this scenario lies in the high &lt;span class=&#34;math inline&#34;&gt;\(C_b\)&lt;/span&gt; value, which is approximately 0.98 (&lt;span class=&#34;math inline&#34;&gt;\(C_b = \frac{\rho_c}{\rho} = \frac{-0.43}{-0.44}\)&lt;/span&gt;). This value is calculated as the ratio of CCC to the Pearson correlation coefficient. While the negative Pearson correlation may not indicate a high precision, the elevated &lt;span class=&#34;math inline&#34;&gt;\(C_b\)&lt;/span&gt; value implies that &lt;span class=&#34;math inline&#34;&gt;\(Y\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(X\)&lt;/span&gt; are almost perfectly accurate.
&lt;/p&gt;
&lt;p align=&#34;justify&#34;&gt;
Now, let‚Äôs take a closer look at an intriguing scenario. If we push the Pearson correlation to the extreme, reaching -1, we witness a perfect inverse agreement. In this scenario, every data point converges precisely onto the black dashed line, forming an impeccable alignment. Notably, even the best fit line mirrors this black dashed line in perfect harmony, showcasing the unparalleled concordance in this exceptional case.
&lt;/p&gt;
&lt;div class=&#34;figure&#34; style=&#34;text-align: center&#34;&gt;&lt;span style=&#34;display:block;&#34; id=&#34;fig:unnamed-chunk-5&#34;&gt;&lt;/span&gt;
&lt;img src=&#34;scenario4_gif.gif&#34; alt=&#34;Scenario 4: Inverse relationship with both Pearson correlation varying from -0.43 to -1. The red dashed line represents $Y = X$, the black dashed line is the $Y = 100 - X$, and the blue solid line is the best fit line&#34; width=&#34;600px&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;
Figure 5: Scenario 4: Inverse relationship with both Pearson correlation varying from -0.43 to -1. The red dashed line represents &lt;span class=&#34;math inline&#34;&gt;\(Y = X\)&lt;/span&gt;, the black dashed line is the &lt;span class=&#34;math inline&#34;&gt;\(Y = 100 - X\)&lt;/span&gt;, and the blue solid line is the best fit line
&lt;/p&gt;
&lt;/div&gt;
&lt;p align=&#34;justify&#34;&gt;
In Scenario 5, the CCC value of 0 denotes absolute non-concordance, indicating that the variability between the measurements does not correspond to the variability expected by chance alone. This suggests that the measurements lack any systematic agreement and cannot be used interchangeably or as reliable estimates of one another. The complete absence of concordance highlights the importance of accuracy in measurement, underscoring that precision without accuracy does not yield valid or useful data in reflecting the assumed ‚Äútrue‚Äù values.
&lt;/p&gt;
&lt;div class=&#34;figure&#34; style=&#34;text-align: center&#34;&gt;&lt;span style=&#34;display:block;&#34; id=&#34;fig:unnamed-chunk-6&#34;&gt;&lt;/span&gt;
&lt;img src=&#34;scenario4.png&#34; alt=&#34;Scenario 5 - No agreement with CCC at 0&#34; width=&#34;500px&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;
Figure 6: Scenario 5 - No agreement with CCC at 0
&lt;/p&gt;
&lt;/div&gt;
&lt;p align=&#34;justify&#34;&gt;
These scenarios vividly demonstrate the nuanced interplay between precision and accuracy within the framework of CCC. They bring to light the importance of accuracy in scientific measurement and the limitations of relying solely on correlation coefficients for assessing the validity and reliability of data.
&lt;/p&gt;
&lt;p align=&#34;justify&#34;&gt;
To further strengthen the discussion, we must consider the assumptions and limitations of CCC. It assumes that the data scales are continuous and that the relationship between the measures is linear. The presence of outliers can unduly influence the CCC, and it may not be suitable for all data types. Additionally, the CCC does not account for random error, which can affect measurements variably.
&lt;/p&gt;
&lt;p align=&#34;justify&#34;&gt;
When considering alternative measures, such as Bland-Altman plots, we can address scenarios where CCC is less suitable, like non-normal data or comparisons of more than two measurement sets.
&lt;/p&gt;
&lt;p align=&#34;justify&#34;&gt;
In practical terms, CCC can be used to validate new measurement methods against established gold standards, underscoring its application in method comparison studies. Real-world examples where CCC has been pivotal could include its use in clinical settings for comparing measurement techniques, methods of colour measurements in agriculture, and model diagnostic in statistics.
&lt;/p&gt;
&lt;p align=&#34;justify&#34;&gt;
For computational purposes, the statistical environment &lt;code&gt;R&lt;/code&gt; has functions and libraries dedicated to calculating CCC, making it accessible for researchers and practitioners to apply this measure to their data. The &lt;code&gt;epiR&lt;/code&gt; package in &lt;code&gt;R&lt;/code&gt;, for instance, provides a function &lt;code&gt;epi.ccc&lt;/code&gt; specifically for calculating Lin‚Äôs CCC.
&lt;/p&gt;
&lt;p align=&#34;justify&#34;&gt;
If one prefers to write a custom function in &lt;code&gt;R&lt;/code&gt; for educational or analytical purposes, the following function can be used to compute a point estimate for Lin‚Äôs Concordance Correlation Coefficient (CCC):
&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#&amp;#39; Calculate Lin&amp;#39;s Concordance Correlation Coefficient (CCC)
#&amp;#39;
#&amp;#39; This function computes Lin&amp;#39;s Concordance Correlation Coefficient to evaluate the agreement
#&amp;#39; between two sets of measurements. It returns the CCC which combines measures of precision
#&amp;#39; and accuracy to determine how well the data from the two sets conform to the line of
#&amp;#39; perfect concordance.
#&amp;#39;
#&amp;#39; @param x A numeric vector of measurements.
#&amp;#39; @param y A numeric vector of measurements, where each element corresponds to the element in `x`.
#&amp;#39;
#&amp;#39; @return The Concordance Correlation Coefficient as a numeric value.
#&amp;#39;
#&amp;#39; @examples
#&amp;#39; x &amp;lt;- c(1, 2, 3, 4, 5)
#&amp;#39; y &amp;lt;- c(1.1, 1.9, 3.1, 4.2, 4.8)
#&amp;#39; ccc(x, y)
#&amp;#39;
#&amp;#39; @export
ccc &amp;lt;- function(x, y) {
  # Check if inputs are numeric vectors
  stopifnot(is.numeric(x), is.numeric(y))

  # Calculate Pearson&amp;#39;s correlation coefficient
  rho &amp;lt;- cor(x, y)

  # Calculate means of x and y
  mean_x &amp;lt;- mean(x)
  mean_y &amp;lt;- mean(y)

  # Calculate variances of x and y
  var_x &amp;lt;- var(x)
  var_y &amp;lt;- var(y)

  # Calculate CCC based on the formula
  ccc_value &amp;lt;- (2 * rho * sqrt(var_x) * sqrt(var_y)) / 
               (var_x + var_y + (mean_x - mean_y)^2)

  return(ccc_value)
}&lt;/code&gt;&lt;/pre&gt;
&lt;p align=&#34;justify&#34;&gt;
This function begins by calculating Pearson‚Äôs correlation coefficient (&lt;span class=&#34;math inline&#34;&gt;\(rho\)&lt;/span&gt;) for the input vectors &lt;span class=&#34;math inline&#34;&gt;\(x\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt;. It then computes the means (&lt;span class=&#34;math inline&#34;&gt;\(mean_x\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(mean_y\)&lt;/span&gt;) and variances (&lt;span class=&#34;math inline&#34;&gt;\(var_x\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(var_y\)&lt;/span&gt;) of the two sets of measurements. The CCC is calculated by combining these values according to the formula, thereby quantifying the agreement between the two measurements in terms of both precision and accuracy.
&lt;/p&gt;
&lt;p align=&#34;justify&#34;&gt;
Using the custom &lt;code&gt;ccc&lt;/code&gt; function provides a straightforward computation of Lin‚Äôs Concordance Correlation Coefficient (CCC) for research applications, particularly when a simple estimate of concordance is required. However, for a more comprehensive analysis, the &lt;code&gt;epi.ccc&lt;/code&gt; function from the &lt;a href=&#34;https://cran.r-project.org/web/packages/epiR/index.html&#34;&gt;&lt;code&gt;epiR&lt;/code&gt; package&lt;/a&gt; is advantageous as it not only computes CCC but also provides confidence intervals for the CCC value, offering a statistical range within which the true concordance lies with a certain probability. This is crucial for making inferences about the precision of the agreement between measurements in research.
&lt;/p&gt;
&lt;p align=&#34;justify&#34;&gt;
For those looking to apply CCC specifically to Lin‚Äôs method, both the &lt;a href=&#34;https://cran.r-project.org/web/packages/epiR/index.html&#34;&gt;&lt;code&gt;epiR&lt;/code&gt; package&lt;/a&gt; and the &lt;a href=&#34;https://cran.r-project.org/web/packages/DescTools/index.html&#34;&gt;&lt;code&gt;DescTools&lt;/code&gt; package&lt;/a&gt; on CRAN offer robust tools. The &lt;code&gt;DescTools&lt;/code&gt; package provides a comprehensive collection of statistical functions, including methods for calculating CCC.
&lt;/p&gt;
&lt;p align=&#34;justify&#34;&gt;
For studies involving repeated measures, where the same subjects are measured under different conditions or at different times, the &lt;a href=&#34;https://cloud.r-project.org/web/packages/lcc/index.html&#34;&gt;&lt;code&gt;lcc&lt;/code&gt; package&lt;/a&gt; offers functions for calculating CCC for longitudinal data, taking into account the within-subject correlation.
&lt;/p&gt;
&lt;p align=&#34;justify&#34;&gt;
Additionally, the &lt;a href=&#34;https://cran.r-project.org/web/packages/cccrm/index.html&#34;&gt;&lt;code&gt;cccrm&lt;/code&gt; package&lt;/a&gt; provides functions for calculating the CCC for repeated (and non-repeated) measures, catering to a wide range of research designs and ensuring that the variability inherent in repeated measures is appropriately accounted for.
&lt;/p&gt;
&lt;p align=&#34;justify&#34;&gt;
These packages are valuable additions to the toolkit of researchers, statisticians, and data analysts, enhancing the reliability and interpretability of concordance assessments in scientific studies.
&lt;/p&gt;
&lt;div id=&#34;r-code-used-to-produce-the-data-and-plots&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;R code used to produce the data and plots&lt;/h1&gt;
&lt;pre&gt;&lt;code&gt;# Load necessary libraries
library(MASS)
library(ggplot2)

# Function to calculate Concordance Correlation Coefficient (CCC)
ccc &amp;lt;- function(x, y) {
  # Check if inputs are numeric vectors
  stopifnot(is.numeric(x), is.numeric(y))

  # Calculate Pearson&amp;#39;s correlation coefficient
  rho &amp;lt;- cor(x, y)

  # Calculate means of x and y
  mean_x &amp;lt;- mean(x)
  mean_y &amp;lt;- mean(y)

  # Calculate variances of x and y
  var_x &amp;lt;- var(x)
  var_y &amp;lt;- var(y)

  # Calculate CCC based on the formula
  ccc_value &amp;lt;- (2 * rho * sqrt(var_x) * sqrt(var_y)) / 
               (var_x + var_y + (mean_x - mean_y)^2)

  return(ccc_value)
}

# Set seed for reproducibility
set.seed(123)

# Function to generate and plot data for each scenario
data_plot &amp;lt;- function(mean, cov, scenario_number) {
  data &amp;lt;- mvrnorm(100, mu = mean, Sigma = cov)
  df &amp;lt;- data.frame(x = data[,1], y = data[,2])
  
  title &amp;lt;- ifelse(scenario_number == 3 || scenario_number == 4,
                  paste(&amp;quot;Scenario&amp;quot;, scenario_number, &amp;quot;: Pearson =&amp;quot;, round(cor(df$x, df$y), 2), 
                        &amp;quot;CCC =&amp;quot;, round(ccc(df$x, df$y), 2)),
                  paste(&amp;quot;Scenario&amp;quot;, scenario_number, &amp;quot;: CCC =&amp;quot;, round(ccc(df$x, df$y), 2)))
  
  p &amp;lt;- ggplot(df, aes(x = x, y = y)) + 
    geom_point(color = &amp;quot;blue&amp;quot;, alpha = 0.6, size = 3) +
    ggtitle(title) +
    xlab(&amp;quot;X values&amp;quot;) +
    ylab(&amp;quot;Y values&amp;quot;) +
    theme_minimal() +
    theme(plot.title = element_text(hjust = 0.5, face = &amp;quot;bold&amp;quot;, size = 14),
          axis.title.x = element_text(face = &amp;quot;bold&amp;quot;, size = 12),
          axis.title.y = element_text(face = &amp;quot;bold&amp;quot;, size = 12),
          axis.text.x = element_text(size = 10),
          axis.text.y = element_text(size = 10))
  
  if (scenario_number == 3 || scenario_number == 4) {
    p &amp;lt;- p + geom_smooth(method = &amp;quot;lm&amp;quot;, color = &amp;quot;blue&amp;quot;, se = FALSE) +
      geom_abline(slope = -1, intercept = 100, linetype = &amp;quot;dashed&amp;quot;, color = &amp;quot;black&amp;quot;) +
      geom_abline(slope = 1, intercept = 0, linetype = &amp;quot;dashed&amp;quot;, color = &amp;quot;red&amp;quot;)
  } else {
    p &amp;lt;- p + geom_abline(slope = 1, intercept = 0, linetype = &amp;quot;dashed&amp;quot;, color = &amp;quot;red&amp;quot;)
  }
  
  print(p)
}

# Scenario 1: High Pearson correlation, modest CCC
data_plot(c(50, 70), matrix(c(100, 0.99 * sqrt(100) * sqrt(150), 0.99 * sqrt(100) * sqrt(150), 150), 2), 1)

# Scenario 2: High CCC
data_plot(c(50, 50), matrix(c(100, 0.95 * sqrt(100) * sqrt(100), 0.95 * sqrt(100) * sqrt(100), 100), 2), 2)

# Scenario 3: Negative Pearson and CCC
data_plot(c(50, 50), matrix(c(100, -0.3 * sqrt(100) * sqrt(150), -0.3 * sqrt(100) * sqrt(150), 150), 2), 3)

# Scenario 4 (previously 5): Perfect inverse agreement
data_plot(c(50, 50), matrix(c(100, -1 * sqrt(100) * sqrt(100), -1 * sqrt(100) * sqrt(100), 100), 2), 4)

# Scenario 5 (previously 4): No correlation (CCC = 0)
data_plot(c(50, 50), matrix(c(100, 0, 0, 150), 2), 5)&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;references&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;References&lt;/h1&gt;
&lt;p align=&#34;justify&#34;&gt;
Carrasco, J. L., King, T. S., &amp;amp; Chinchilli, V. M. (2009). The Concordance Correlation Coefficient for Repeated Measures Estimated by Variance Components. &lt;em&gt;Journal of Biopharmaceutical Statistics, 19&lt;/em&gt;, 90-105. DOI: 10.1080/10543400802527890
&lt;/p&gt;
&lt;p align=&#34;justify&#34;&gt;
Oliveira, T. de P., Hinde, J., &amp;amp; Zocchi, S. S. (2018). Longitudinal Concordance Correlation Function Based on Variance Components: An Application in Fruit Color Analysis. &lt;em&gt;Journal of Agricultural, Biological, and Environmental Statistics, 23&lt;/em&gt;(2), 233-254. DOI: 10.1007/s13253-018-0321-1
&lt;/p&gt;
&lt;p align=&#34;justify&#34;&gt;
Rathnayake, L. N., &amp;amp; Choudhary, P. K. (2017). Semiparametric Modeling and Analysis of Longitudinal Method Comparison Data. &lt;em&gt;Statistics in Medicine, 36&lt;/em&gt;, 2003-2015. DOI: 10.1002/sim.7261
&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;citation&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Citation&lt;/h1&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;For attribution, please cite this work as:&lt;/li&gt;
&lt;/ol&gt;
&lt;div class=&#34;div-1&#34;&gt;
&lt;p&gt;Oliveira T.P. (2024, Jan.¬†10). Precision &amp;amp; Accuracy - The Role of Concordance Correlation in Research&lt;/p&gt;
&lt;/div&gt;
&lt;ol start=&#34;2&#34; style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;BibTeX citation&lt;/li&gt;
&lt;/ol&gt;
&lt;pre&gt;&lt;code&gt;@misc{oliveira2024concordance,
  author = {Oliveira, Thiago},
  title = {Precision &amp;amp; Accuracy - The Role of Concordance Correlation in Research},
  url = {https://prof-thiagooliveira.netlify.app/post/precision-and-accuracy-the-role-of-concordance-correlation-in-research/},
  year = {2024}
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;Did you find this page helpful? Consider sharing it üôå&lt;/strong&gt;&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>R Programming with Efficient Snippets</title>
      <link>https://prof-thiagooliveira.netlify.com/post/r-programming/</link>
      <pubDate>Sat, 06 Jan 2024 00:00:00 +0000</pubDate>
      <guid>https://prof-thiagooliveira.netlify.com/post/r-programming/</guid>
      <description>


&lt;div id=&#34;introduction&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Introduction&lt;/h1&gt;
&lt;p align=&#34;justify&#34;&gt;
In &lt;code&gt;R&lt;/code&gt; programming, efficiency is key. Snippets, small reusable blocks of code, are a cornerstone in achieving this. This post delves into the world of snippets, offering both novice and seasoned &lt;code&gt;R&lt;/code&gt; programmers insights into their power and versatility.
&lt;/p&gt;
&lt;div id=&#34;what-are-snippets&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;What are Snippets?&lt;/h2&gt;
&lt;p align=&#34;justify&#34;&gt;
In &lt;code&gt;R&lt;/code&gt; programming, snippets are more than just pre-written bits of code; they are dynamic templates designed to streamline code writing and editing. Snippets in R can contain placeholders, which are special fields that can be easily tabbed through and filled in by the programmer. This feature allows for rapid customization of the snippet to fit specific coding needs. They can encapsulate complex coding patterns, data structures, and algorithms, making them particularly useful for tasks that require adherence to specific coding standards or methodologies.
&lt;/p&gt;
&lt;p align=&#34;justify&#34;&gt;
Snippets can be simple, such as a line to import a commonly used library, or complex, containing entire functions or control structures. They support variable interpolation, enabling the inclusion of dynamic content like dates, user names, or contextual code. Advanced snippets may even include scriptable transformations of the inserted text, allowing for sophisticated code generation based on the user‚Äôs input.
&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;advantages-of-using-snippets&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Advantages of Using Snippets&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p align=&#34;justify&#34;&gt;
&lt;strong&gt;Enhanced Productivity&lt;/strong&gt;: Snippets go beyond automating repetitive code insertion. They serve as a framework for implementing best practices and methodologies, significantly reducing the cognitive load on the programmer. By providing ready-to-use code templates, they allow programmers to focus on the unique aspects of their work, rather than the boilerplate code.
&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p align=&#34;justify&#34;&gt;
&lt;strong&gt;Error Reduction&lt;/strong&gt;: The use of snippets minimizes syntax and logical errors not just through standardization, but also by embedding proven and tested code patterns. This is especially beneficial in complex programming tasks where the risk of introducing errors is high. It ensures that the fundamental building blocks of the code are sound, allowing programmers to concentrate on higher-level logic and functionality.
&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p align=&#34;justify&#34;&gt;
&lt;strong&gt;Code Consistency&lt;/strong&gt;: In collaborative projects, maintaining a consistent coding style and structure is vital for readability and maintainability. Snippets enforce a uniform coding convention, which is crucial when working in teams or when codebases are passed between different developers. They help in aligning the code with organizational or community standards, making the code more accessible and understandable to all team members.
&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p align=&#34;justify&#34;&gt;
&lt;strong&gt;Rapid Prototyping and Experimentation&lt;/strong&gt;: Snippets enable quick assembly of code constructs, facilitating rapid prototyping and experimentation. This is particularly valuable in data science and statistical analysis, where various approaches and methods are often tested in quick succession.
&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p align=&#34;justify&#34;&gt;
&lt;strong&gt;Educational Tool&lt;/strong&gt;: For learners of R programming, snippets act as an educational tool, demonstrating best practices and exposing them to different coding styles and patterns. It accelerates the learning curve by providing examples of well-structured code.
&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;div id=&#34;potential-drawbacks-of-using-snippets&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Potential Drawbacks of Using Snippets&lt;/h3&gt;
&lt;p align=&#34;justify&#34;&gt;
While snippets offer numerous advantages, there are some considerations to keep in mind:
&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p align=&#34;justify&#34;&gt;
&lt;strong&gt;Inflexibility in Complex Scenarios&lt;/strong&gt;: Snippets are excellent for routine tasks, but they may not always suit more complex, unique programming challenges. Overusing snippets in such scenarios can lead to inefficient or convoluted code, especially if the snippet doesn‚Äôt align perfectly with the specific requirements of the task.
&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p align=&#34;justify&#34;&gt;
&lt;strong&gt;Maintenance Challenges&lt;/strong&gt;: Snippets, like any other code, require maintenance. As the &lt;code&gt;R&lt;/code&gt; language and associated packages evolve, snippets might become outdated, leading to compatibility issues or deprecated practices. Keeping a library of snippets up-to-date can be a task in itself.
&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p align=&#34;justify&#34;&gt;
&lt;strong&gt;Standardization vs.¬†Creativity&lt;/strong&gt;: While standardization is an advantage, it can sometimes stifle creativity and innovation in coding. Relying heavily on snippets may discourage developers from exploring new or unconventional solutions to programming problems.
&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p align=&#34;justify&#34;&gt;
Thus, while snippets are a powerful tool in &lt;code&gt;R&lt;/code&gt; programming, understanding and mitigating these potential drawbacks is crucial for effective and efficient use. It‚Äôs important to balance the convenience of snippets with the need for deep understanding, creativity, and code efficiency.
&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;integrating-snippets-into-r&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Integrating Snippets into &lt;code&gt;R&lt;/code&gt;&lt;/h2&gt;
&lt;p align=&#34;justify&#34;&gt;
Most &lt;code&gt;R&lt;/code&gt; Integrated Development Environments (IDEs), such as RStudio, have built-in support for snippets. They allow for easy creation, modification, and insertion of snippets into your code.
&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;example-of-snippets-for-r-programming&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Example of Snippets for R Programming&lt;/h2&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Function Declaration (&lt;code&gt;advFun&lt;/code&gt;)&lt;/strong&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;snippet advFun
    ${1:function_name} &amp;lt;- function(${2:args}, ${3:optional_args = default_values}) {
        tryCatch({
            ${4:body}
            return(${5:result})
        }, error = function(e) {
            stop(&amp;quot;Error in ${1:function_name}: &amp;quot;, e)
        })
    }&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Conditional Execution (&lt;code&gt;three_statements&lt;/code&gt;)&lt;/strong&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;snippet three_statements
    if (${1:primary_condition}) {
        ${2:primary_action}
    } else if (${3:secondary_condition}) {
        ${4:secondary_action}
    } else {
        ${5:alternative_action}
    }&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;For Loop&lt;/strong&gt; (&lt;code&gt;ForLoop&lt;/code&gt;)&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;snippet ForLoop
    for (${1:var} in ${2:sequence}) {
        if (${3:break_condition}) {
            break
        } else if (${4:continue_condition}) {
            next
        }
        ${5:loop_body}
    }&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;While Loop with Counter&lt;/strong&gt; (&lt;code&gt;whileLoopCounter&lt;/code&gt;)&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;snippet whileLoopCounter
    ${1:counter} &amp;lt;- ${2:initial_value}
    while (${3:condition}) {
        ${4:body}
        ${1:counter} &amp;lt;- ${1:counter} + 1
        if (${1:counter} &amp;gt; ${5:max_iterations}) break
    }&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Join and Transform Data with dplyr&lt;/strong&gt; (&lt;code&gt;dplyrJoinTransform&lt;/code&gt;)&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;snippet dplyrJoinTransform
    ${1:result} &amp;lt;- ${2:dataset1} %&amp;gt;%
        inner_join(${3:dataset2}, by = &amp;quot;${4:key}&amp;quot;) %&amp;gt;%
        dplyr::mutate(${5:new_column} = ${6:transformation}) %&amp;gt;%
        arrange(${7:order_column})&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Robust Exception Handling&lt;/strong&gt; (&lt;code&gt;robustTryCatch&lt;/code&gt;)&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;snippet robustTryCatch
    tryCatch({
        ${1:expr}
    }, warning = function(w) {
        warning(&amp;quot;Warning in ${1:expr}: &amp;quot;, w)
    }, error = function(e) {
        stop(&amp;quot;Error in ${1:expr}: &amp;quot;, e)
    }, finally = {
        message(&amp;quot;Executed ${1:expr}&amp;quot;)
    })&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Plotting with ggplot2&lt;/strong&gt; (&lt;code&gt;ggplot_wrap&lt;/code&gt;)&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;snippet ggplot_wrap
    ggplot(${1:data}, aes(${2:aes_params})) +
        ${3:geom_layer} +
        facet_wrap(~ ${4:facet_var}) +
        theme_minimal() +
        theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
        labs(title = &amp;quot;${5:plot_title}&amp;quot;, x = &amp;quot;${6:x_label}&amp;quot;, y = &amp;quot;${7:y_label}&amp;quot;)&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Data Reading&lt;/strong&gt; (&lt;code&gt;readData&lt;/code&gt;)&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;snippet readData
    ${1:dataset} &amp;lt;- read.csv(&amp;quot;${2:file_path}&amp;quot;, header = ${3:TRUE}, na.strings = &amp;quot;${4:NA}&amp;quot;, stringsAsFactors = ${5:FALSE})&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p align=&#34;justify&#34;&gt;
These snippets are formatted to be directly added to your &lt;code&gt;R&lt;/code&gt; snippet library, making them easily accessible and usable within your &lt;code&gt;R&lt;/code&gt; programming environment.
&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;evaluating-code-performance-with-snippet&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Evaluating Code Performance with Snippet&lt;/h2&gt;
&lt;p align=&#34;justify&#34;&gt;
In addition to the various functional and structural snippets, a key aspect of efficient programming is performance optimization. The &lt;code&gt;measureCodeBottleneck&lt;/code&gt; snippet is an example of code for identifying performance bottlenecks in your &lt;code&gt;R&lt;/code&gt; code. It helps you measure both execution time and memory usage, offering insights into how your code can be optimized for better performance.
&lt;/p&gt;
&lt;div id=&#34;the-measurecodebottleneck-snippet&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;The &lt;code&gt;measureCodeBottleneck&lt;/code&gt; Snippet&lt;/h3&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;snippet measureCodeBottleneck
    library(microbenchmark)
    library(pryr)

    # Memory and Time Measurement Function
    measureBottleneck &amp;lt;- function(expr) {
        # Measure execution time
        time_result &amp;lt;- microbenchmark(expr, times = ${1:100})
        print(summary(time_result))

        # Measure memory usage
        mem_usage &amp;lt;- object_size(expr)
        print(paste(&amp;quot;Memory Usage: &amp;quot;, mem_usage))
    }

    # Example Usage
    # measureBottleneck({
    #    # Place your code here
    # })&lt;/code&gt;&lt;/pre&gt;
&lt;p align=&#34;justify&#34;&gt;
This snippet is particularly useful when working with large datasets or complex algorithms, where understanding and minimizing resource consumption is crucial.
&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;conclusion&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Conclusion&lt;/h2&gt;
&lt;p align=&#34;justify&#34;&gt;
Snippets stand as a powerful asset in the toolkit of any &lt;code&gt;R&lt;/code&gt; programmer, driving efficiency, reducing errors, and ensuring consistency across coding projects. Their integration into your daily workflow can be a game changer, significantly elevating both productivity and the quality of your code. However, it‚Äôs crucial to use snippets judiciously.
&lt;/p&gt;
&lt;p align=&#34;justify&#34;&gt;
While snippets are designed to save time and resources, their indiscriminate or inappropriate use can, paradoxically, lead to the opposite - a waste of time and a drain on resources. As you incorporate these snippets into your work, be mindful of their relevance and applicability to the task at hand. Choose and customize snippets that align closely with your specific coding needs and avoid the temptation to use a snippet when a more straightforward or tailored piece of code would be more efficient. This balanced approach to using snippets will ensure that you truly harness their potential to make your &lt;code&gt;R&lt;/code&gt; programming more effective and streamlined.
&lt;/p&gt;
&lt;p align=&#34;justify&#34;&gt;
Remember, the goal is not just to code faster, but to code smarter. Snippets, when used thoughtfully, are a robust lever in achieving this goal.
&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;citation&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Citation&lt;/h1&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;For attribution, please cite this work as:&lt;/li&gt;
&lt;/ol&gt;
&lt;div class=&#34;div-1&#34;&gt;
&lt;p&gt;Oliveira T.P. (2024, Jan.¬†06). R Programming with Efficient Snippets&lt;/p&gt;
&lt;/div&gt;
&lt;ol start=&#34;2&#34; style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;BibTeX citation&lt;/li&gt;
&lt;/ol&gt;
&lt;pre&gt;&lt;code&gt;@misc{oliveira2024snippets,
  author = {Oliveira, Thiago},
  title = {R Programming with Efficient Snippets},
  url = {https://prof-thiagooliveira.netlify.app/post/r-programming-with-efficient-snippets/},
  year = {2024}
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;Did you find this page helpful? Consider sharing it üôå&lt;/strong&gt;&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Navigating the Shiny Universe with Golem</title>
      <link>https://prof-thiagooliveira.netlify.com/post/golem-package/</link>
      <pubDate>Mon, 02 Oct 2023 00:00:00 +0000</pubDate>
      <guid>https://prof-thiagooliveira.netlify.com/post/golem-package/</guid>
      <description>


&lt;div id=&#34;the-golem-package&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;The &lt;code&gt;golem&lt;/code&gt; package&lt;/h1&gt;
&lt;p align=&#34;justify&#34;&gt;
In the world of &lt;code&gt;R&lt;/code&gt; programming, Shiny applications let us make interactive web apps using R code. The &lt;code&gt;golem&lt;/code&gt; package (Fay et al.¬†2021) makes it easier to develop these apps. It brings new tools and methods to this area, helping developers handle complex tasks more simply.
&lt;/p&gt;
&lt;div id=&#34;making-things-with-structure&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Making Things with Structure&lt;/h2&gt;
&lt;p align=&#34;justify&#34;&gt;
Think of making a sculpture out of clay. At first, the big lump of clay can be hard to handle. &lt;code&gt;golem&lt;/code&gt; helps developers, like sculptors, by giving them a clear framework. This means instead of dealing with a big, confusing bunch of code, developers have an organized way to work. It is like having lines drawn on the clay, showing where to shape and smooth it.
&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;modular-component&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Modular Component&lt;/h2&gt;
&lt;p align=&#34;justify&#34;&gt;
When I first stumbled upon the &lt;code&gt;golem&lt;/code&gt; package for R‚Äôs Shiny applications, it was like discovering a secret garden in the world of coding. The stand-out feature for me? Its emphasis on modular coding. Let me break down why this is such a big deal.
&lt;/p&gt;
&lt;p align=&#34;justify&#34;&gt;
Think of building a Shiny app like crafting a beautiful mosaic. Each piece (or module) is unique and serves a specific purpose. When you put them all together, they create a stunning picture - your final application. This modular approach is not just about aesthetics; it is about making your coding life a whole lot easier.
&lt;/p&gt;
&lt;div id=&#34;why-modules-make-all-the-difference&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Why Modules Make All the Difference&lt;/h3&gt;
&lt;p align=&#34;justify&#34;&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;strong&gt;Organization&lt;/strong&gt;: Breaking down the app into modules is like having a well-organized toolbox. Everything has its place, and you know exactly where to find it. It is incredibly satisfying and efficient.&lt;/li&gt;
&lt;/ol&gt;
&lt;/p&gt;
&lt;p align=&#34;justify&#34;&gt;
&lt;ol start=&#34;2&#34; style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;strong&gt;Teamwork Made Simple&lt;/strong&gt;: If you are working in a team, modules are a lifesaver. Imagine each team member painting their part of a large canvas. With modules, you can work independently on different features without stepping on each other‚Äôs toes.&lt;/li&gt;
&lt;/ol&gt;
&lt;/p&gt;
&lt;p align=&#34;justify&#34;&gt;
&lt;ol start=&#34;3&#34; style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;strong&gt;Debugging&lt;/strong&gt;: We have all been there - something is broken, and we have no idea where to start looking. With modular coding, it is like having a map with a big ‚ÄúX‚Äù marking the spot of the problem. A big simplication!&lt;/li&gt;
&lt;/ol&gt;
&lt;/p&gt;
&lt;p align=&#34;justify&#34;&gt;
&lt;ol start=&#34;4&#34; style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;strong&gt;Reuse and Recycle&lt;/strong&gt;: I love this part. Created a nifty user authentication module? You can plug it into your next project without reinventing the wheel. It is like having a secret recipe you can use over and over with minor adaptations when needed.&lt;/li&gt;
&lt;/ol&gt;
&lt;/p&gt;
&lt;p align=&#34;justify&#34;&gt;
&lt;ol start=&#34;5&#34; style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;strong&gt;Growth Made Easy&lt;/strong&gt;: As your app grows, you can just add new modules. It is like adding new rooms to a house. This scalability is one of most helpful feature for any developer.&lt;/li&gt;
&lt;/ol&gt;
&lt;/p&gt;
&lt;p align=&#34;justify&#34;&gt;
&lt;ol start=&#34;6&#34; style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;strong&gt;Testing&lt;/strong&gt;: Testing each module separately means you can be super confident that every part of your app works perfectly before you put it all together.&lt;/li&gt;
&lt;/ol&gt;
&lt;/p&gt;
&lt;p align=&#34;justify&#34;&gt;
&lt;ol start=&#34;7&#34; style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;strong&gt;Newbie-Friendly&lt;/strong&gt;: If someone new joins your project, it is much easier for them to get up to speed with a modular structure. It is like giving them a well-detailed map instead of a single, overwhelming blueprint.&lt;/li&gt;
&lt;/ol&gt;
&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;a-developers-toolbox&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;A Developer‚Äôs Toolbox&lt;/h2&gt;
&lt;p align=&#34;justify&#34;&gt;
&lt;code&gt;golem&lt;/code&gt; is not just about keeping things tidy. It is like a multi-tool for Shiny developers. It helps with JavaScript and CSS, makes app settings simpler, and improves how you work. &lt;code&gt;golem&lt;/code&gt; also manages updates in &lt;code&gt;R&lt;/code&gt;, making sure your app stays stable even when other parts of &lt;code&gt;R&lt;/code&gt; change.
&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;deployment-and-documentation&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Deployment and Documentation&lt;/h2&gt;
&lt;p align=&#34;justify&#34;&gt;
Deploying a Shiny app should feel like a victory lap, not a hurdle race. &lt;code&gt;golem&lt;/code&gt; ensures this by packaging Shiny apps in a deployment-ready format. Be it RStudio Connect, Shinyapps.io, or the containerized world of Docker, your app is prepared and primed to go live.
&lt;/p&gt;
&lt;p align=&#34;justify&#34;&gt;
Now, let‚Äôs talk about something that does not always get the spotlight but is super crucial: documentation. &lt;code&gt;golem&lt;/code&gt; knows how important this is. It is not just about coding; it is about leaving a trail of breadcrumbs for those who will follow in your footsteps. &lt;code&gt;golem&lt;/code&gt; encourages you to document your work thoroughly. Think of it as creating a treasure map for future developers and collaborators who will join your project. Moreover, &lt;code&gt;golem&lt;/code&gt; aligns seamlessly with the &lt;code&gt;roxygen2&lt;/code&gt; style of documentation, familiar to many R developers. This integration means that while you are crafting your Shiny app, you can simultaneously create comprehensive, easy-to-understand documentation. It is like having a dual toolkit - one for building your app and another for creating a clear, helpful guide for any future developer or user who ventures into your code. This approach not only saves time but also ensures that your documentation is as robust and user-friendly as the app you are building.
&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;conclusion&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Conclusion&lt;/h2&gt;
&lt;p align=&#34;justify&#34;&gt;
&lt;code&gt;golem&lt;/code&gt; truly revolutionizes the way we handle R and Shiny applications. It is like having a GPS for the often complex journey of app development, guiding you with a structured, modular approach. This not only simplifies the process but also injects a sense of fun and creativity, much like piecing together a Lego masterpiece.
&lt;/p&gt;
&lt;p align=&#34;justify&#34;&gt;
Beyond just coding, &lt;code&gt;golem&lt;/code&gt; makes deploying apps feel like a victory lap and turns documentation into an integral, rewarding part of the development cycle. With the added bonus of a supportive community, &lt;code&gt;golem&lt;/code&gt; is more than just a tool - it is a companion for any developer venturing into the exciting world of Shiny applications. üöÄüåü
&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;references&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;References&lt;/h1&gt;
&lt;p&gt;Fay, Colin, Vincent Guyader, S√©bastien Rochette, and Cervan Girard. 2021. Golem: A Framework for Robust Shiny Applications. &lt;a href=&#34;https://github.com/ThinkR-open/golem&#34; class=&#34;uri&#34;&gt;https://github.com/ThinkR-open/golem&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;additional-material&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Additional Material&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://engineering-shiny.org/golem.html&#34;&gt;Engineering Production-Grade Shiny Apps&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://rstudio.github.io/cheatsheets/golem.pdf&#34;&gt;golem: A Framework for Building Robust Shiny Apps&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://cran.r-project.org/web/packages/golem/index.html&#34;&gt;golem R package&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;citation&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Citation&lt;/h1&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;For attribution, please cite this work as:&lt;/li&gt;
&lt;/ol&gt;
&lt;div class=&#34;div-1&#34;&gt;
&lt;p&gt;Oliveira T.P. (2023, Oct.¬†02). Navigating the Shiny Universe with Golem&lt;/p&gt;
&lt;/div&gt;
&lt;ol start=&#34;2&#34; style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;BibTeX citation&lt;/li&gt;
&lt;/ol&gt;
&lt;pre&gt;&lt;code&gt;@misc{oliveira2020golem,
  author = {Oliveira, Thiago},
  title = {Navigating the Shiny Universe with Golem},
  url = {https://prof-thiagooliveira.netlify.app/post/golem-package/},
  year = {2023}
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;Did you find this page helpful? Consider sharing it üôå&lt;/strong&gt;&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Expressions in C&#43;&#43;</title>
      <link>https://prof-thiagooliveira.netlify.com/post/expressions/</link>
      <pubDate>Wed, 16 Dec 2020 00:00:00 +0000</pubDate>
      <guid>https://prof-thiagooliveira.netlify.com/post/expressions/</guid>
      <description>&lt;h1 id=&#34;introduction&#34;&gt;Introduction&lt;/h1&gt;
&lt;p&gt;Expressions in C++ are fundamental constructs made up of operators, constants, and variables, following the language&amp;rsquo;s syntactical rules. Every expression is a segment of a code that returns a value. For instance:&lt;/p&gt;
&lt;img src=&#34;exp1.png&#34; width=&#34;320px&#34; style=&#34;display: block; margin: auto;&#34; /&gt;
&lt;p&gt;This example demonstrates the creation of variables to store values: a box for $x$ and another for $y$, where $y$ equals the expression $x + 13$ (thus, $y = 23$). Now, let&amp;rsquo;s delve into a more complex example:&lt;/p&gt;
&lt;img src=&#34;exp2.png&#34; width=&#34;500px&#34; style=&#34;display: block; margin: auto;&#34; /&gt;
&lt;p&gt;This statement encompasses three expressions:&lt;/p&gt;
&lt;div class=&#34;div-1&#34;&gt;
* The results of the expression $3 - x$ is stored in the variable $y$
* The expression $y = 3 - x$ returns the value of $y$, and it is stored in the variable $v$
* The results of the expression $y \times \left(\frac{v}{5} + x\right)$ is stored in the variable $z$
&lt;/div&gt;
&lt;p&gt;It&amp;rsquo;s essential to remember the precedence of operations: multiplication and division are executed before addition and subtraction. For example:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;1-3*4 = -11
2/3-4*2/3 = -2
2/3-4/4*2/3 = 0
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;Operator precedence&lt;/strong&gt; in &lt;code&gt;C++&lt;/code&gt; determines the sequence of operations in an expression. Operators have a specific order of execution relative to others. For instance, in the expression $\frac{2}{4} - 3 + 4 \times 6$, the subexpressions $\frac{2}{4}$&lt;code&gt;and&lt;/code&gt;$4 \times 6$ are calculated first, followed by the addition and subtraction. When operators have the same precedence, their associativity dictates the order - either left-to-right or right-to-left.&lt;/p&gt;
&lt;div class=&#34;figure&#34; style=&#34;text-align: center&#34;&gt;
&lt;img src=&#34;exp3.png&#34; alt=&#34;Precedence order&#34; width=&#34;300px&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;Precedence order&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;Associativity&lt;/strong&gt; specifies the order of operations for operators with the same precedence level. It can be left-to-right or right-to-left. Typically, addition, subtraction, multiplication, and division are left-associative, while assignment operators are right-associative. Some operators are non-associative, meaning their behaviour is undefined if used sequentially in an expression. Parentheses can alter the default associativity, enforcing a specific order.&lt;/p&gt;
&lt;div class=&#34;figure&#34; style=&#34;text-align: center&#34;&gt;
&lt;img src=&#34;exp4.png&#34; alt=&#34;Example of left-associative, right-associative, and non-associative&#34; width=&#34;800px&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;Example of left-associative, right-associative, and non-associative&lt;/p&gt;
&lt;/div&gt;
&lt;h1 id=&#34;using-parentheses-&#34;&gt;Using Parentheses &lt;code&gt;()&lt;/code&gt;&lt;/h1&gt;
&lt;p&gt;The operator &lt;code&gt;()&lt;/code&gt; has the highest precedente order (see &lt;a href=&#34;#table1&#34;&gt;Table 1&lt;/a&gt;), as consequence, we can use parentheses to change the sequence of operators. 
Consider the following example:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;5 + 6 * 7
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The &lt;code&gt;*&lt;/code&gt; operator is evaluated firstly, followed by the &lt;code&gt;+&lt;/code&gt; operator, so the result is $5+6\times 7 = 47$. However, if we want to account for the addiction first and then the multiplication, we can rewrite the code as:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;(5 + 6) * 7
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Then, the program will compute $\left(5+6\right)\times 7=11\times 7=77$. Sometimes, parentheses&#39; inclusion should be important to make your code easier to understand, and therefore easier to maintain.&lt;/p&gt;
&lt;h1 id=&#34;modulus-operator-&#34;&gt;Modulus operator (%)&lt;/h1&gt;
&lt;p&gt;The modulus operator evaluates the remainder when dividing the first operand by the second one. Ex.: &lt;code&gt;a % b&lt;/code&gt; is the remainder when $a$ is divided&lt;table class=&#34;wikitable&#34;&gt;&lt;/p&gt;
&lt;p&gt;by $b$ ($a$ modulus $b$).&lt;table class=&#34;wikitable&#34;&gt; by $b$ ($a$ modulus $b$).&lt;/p&gt;
&lt;div class=&#34;figure&#34; style=&#34;text-align: center&#34;&gt;
&lt;img src=&#34;exp5.png&#34; alt=&#34;Example of modulus&#34; width=&#34;300px&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;Example of modulus&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;div-1&#34;&gt;
* Dividing an integer by another one gives an integer.
&lt;/div&gt;
&lt;h2 id=&#34;example&#34;&gt;Example:&lt;/h2&gt;
&lt;pre&gt;&lt;code&gt;int x = 10;
int y = 3;

x/y = 10/3 = 3 (dividing two integers)

x % y = 1 (modulus)
&lt;/code&gt;&lt;/pre&gt;
&lt;h1 id=&#34;short-hand-or-syntatic-sugar&#34;&gt;Short hand or syntatic sugar&lt;/h1&gt;
&lt;p&gt;Short hand expressions provide a straightforward way to write common patterns over the algorithm for initialized variables.&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Short hand&lt;/th&gt;
&lt;th&gt;Meaning&lt;/th&gt;
&lt;th&gt;Prefix and Postfix&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;$x+=y$&lt;/td&gt;
&lt;td&gt;$x=x+y$&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;$x-=y$&lt;/td&gt;
&lt;td&gt;$x=x-y$&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;$x*=y$&lt;/td&gt;
&lt;td&gt;$x= x \times y$&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;$x/=y$&lt;/td&gt;
&lt;td&gt;$x=x/y$&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;$x++$&lt;/td&gt;
&lt;td&gt;$x=x+1$&lt;/td&gt;
&lt;td&gt;Return the value of $x$ first then increment it&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;$++x$&lt;/td&gt;
&lt;td&gt;$x=x+1$&lt;/td&gt;
&lt;td&gt;Increment first then return the value of $x$&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;$x&amp;ndash;$&lt;/td&gt;
&lt;td&gt;$x=x-1$&lt;/td&gt;
&lt;td&gt;Return the value of $x$ first then increment it&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;$&amp;ndash;x$&lt;/td&gt;
&lt;td&gt;$x=x-1$&lt;/td&gt;
&lt;td&gt;Increment first then return the value of $x$&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h2 id=&#34;example-1&#34;&gt;Example 1:&lt;/h2&gt;
&lt;p&gt;Here you can see that &lt;code&gt;y ++= x * z;&lt;/code&gt; is calculate as $y=y+x \times z = 30 + 2 \times 4 = 38$.&lt;/p&gt;
&lt;img src=&#34;example1.png&#34; width=&#34;350px&#34; style=&#34;display: block; margin: auto;&#34; /&gt;
&lt;h2 id=&#34;example-2&#34;&gt;Example 2:&lt;/h2&gt;
&lt;p&gt;In this example you can see that we used the postfix &lt;code&gt;x++&lt;/code&gt; to first initialize $y$ ($y=8 \times x = 8 \times 7 = 56$) and then update $x$ to &lt;code&gt;x=x+1=8&lt;/code&gt;. On the other hand, we used the prefix &lt;code&gt;--y&lt;/code&gt; to first update the variable $y$ to &lt;code&gt;y=y-1=55&lt;/code&gt; and then calculate the variable z using the updated $y$ $\left(z = y/5 = 55/5 = 11 \right)$.&lt;/p&gt;
&lt;img src=&#34;example2.png&#34; width=&#34;500px&#34; style=&#34;display: block; margin: auto;&#34; /&gt;
&lt;p&gt;Note that when we use &lt;code&gt;x*= (y/z) % 2&lt;/code&gt; the variable $x$ multiply the entire expression after &lt;code&gt;=&lt;/code&gt; symbol. This expression is equivalent to &lt;code&gt;x = x * ((y/z) % 2));&lt;/code&gt;.&lt;/p&gt;
&lt;h1 id=&#34;operator-precedence-and-associativity&#34;&gt;Operator precedence and associativity&lt;/h1&gt;
&lt;p&gt;&lt;a href=&#34;#table1&#34;&gt;Table 1&lt;/a&gt; shows a list of precedence (ordered) and associativity of C operators. This table was obtained from 
&lt;a href=&#34;https://en.cppreference.com/w/c/language/operator_precedence#cite_note-1&#34;&gt;cppreference.com&lt;/a&gt;.&lt;/p&gt;
&lt;div&gt;
&lt;table class=&#34;wikitable&#34;&gt;
&lt;tbody&gt;&lt;tr&gt;
&lt;a name=&#34;table1&#34;&gt; Table 1: Precedence and associativity of C operators &lt;/a&gt;
&lt;th style=&#34;text-align: left&#34;&gt; Precedence
&lt;/th&gt;
&lt;th style=&#34;text-align: left&#34;&gt; Operator
&lt;/th&gt;
&lt;th style=&#34;text-align: left&#34;&gt; Description
&lt;/th&gt;
&lt;th style=&#34;text-align: left&#34;&gt; Associativity
&lt;/th&gt;&lt;/tr&gt;
&lt;tr&gt;
&lt;th rowspan=&#34;6&#34;&gt; 1
&lt;/th&gt;
&lt;td style=&#34;border-bottom-style: none&#34;&gt; &lt;code&gt;++&lt;/code&gt; &lt;code&gt;\-\-&lt;/code&gt;
&lt;/td&gt;
&lt;td style=&#34;border-bottom-style: none&#34;&gt; Suffix/postfix increment and decrement
&lt;/td&gt;
&lt;td style=&#34;vertical-align: top&#34; rowspan=&#34;6&#34;&gt; Left-to-right
&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;border-bottom-style: none; border-top-style: none&#34;&gt; &lt;code&gt;()&lt;/code&gt;
&lt;/td&gt;
&lt;td style=&#34;border-bottom-style: none; border-top-style: none&#34;&gt; Function call
&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;border-bottom-style: none; border-top-style: none&#34;&gt; &lt;code&gt;[]&lt;/code&gt;
&lt;/td&gt;
&lt;td style=&#34;border-bottom-style: none; border-top-style: none&#34;&gt; Array subscripting
&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;border-bottom-style: none; border-top-style: none&#34;&gt; &lt;code&gt;.&lt;/code&gt;
&lt;/td&gt;
&lt;td style=&#34;border-bottom-style: none; border-top-style: none&#34;&gt; Structure and union member access
&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;border-bottom-style: none; border-top-style: none&#34;&gt; &lt;code&gt;-&amp;gt;&lt;/code&gt;
&lt;/td&gt;
&lt;td style=&#34;border-bottom-style: none; border-top-style: none&#34;&gt; Structure and union member access through pointer
&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;border-bottom-style: none; border-top-style: none&#34;&gt; &lt;code&gt;(&lt;i&gt;type&lt;/i&gt;){&lt;i&gt;list&lt;/i&gt;}&lt;/code&gt;
&lt;/td&gt;
&lt;td style=&#34;border-bottom-style: none; border-top-style: none&#34;&gt; Compound literal&lt;span class=&#34;t-mark-rev t-since-c99&#34;&gt;(C99)&lt;/span&gt;
&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;
&lt;th rowspan=&#34;8&#34;&gt; 2
&lt;/th&gt;
&lt;td style=&#34;border-bottom-style: none&#34;&gt; &lt;code&gt;++&lt;/code&gt; &lt;code&gt;\-\-&lt;/code&gt;
&lt;/td&gt;
&lt;td style=&#34;border-bottom-style: none&#34;&gt; Prefix increment and decrement&lt;sup id=&#34;cite_ref-1&#34; class=&#34;reference&#34;&gt;&lt;a href=&#34;#cite_note-1&#34;&gt;[note 1]&lt;/a&gt;&lt;/sup&gt;
&lt;/td&gt;
&lt;td style=&#34;vertical-align: top&#34; rowspan=&#34;8&#34;&gt; Right-to-left
&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;border-bottom-style: none; border-top-style: none&#34;&gt; &lt;code&gt;+&lt;/code&gt; &lt;code&gt;-&lt;/code&gt;
&lt;/td&gt;
&lt;td style=&#34;border-bottom-style: none; border-top-style: none&#34;&gt; Unary plus and minus
&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;border-bottom-style: none; border-top-style: none&#34;&gt; &lt;code&gt;!&lt;/code&gt; &lt;code&gt;~&lt;/code&gt;
&lt;/td&gt;
&lt;td style=&#34;border-bottom-style: none; border-top-style: none&#34;&gt; Logical NOT and bitwise NOT
&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;border-bottom-style: none; border-top-style: none&#34;&gt; &lt;code&gt;(&lt;i&gt;type&lt;/i&gt;)&lt;/code&gt;
&lt;/td&gt;
&lt;td style=&#34;border-bottom-style: none; border-top-style: none&#34;&gt; Cast
&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;border-bottom-style: none; border-top-style: none&#34;&gt; &lt;code&gt;*&lt;/code&gt;
&lt;/td&gt;
&lt;td style=&#34;border-bottom-style: none; border-top-style: none&#34;&gt; Indirection (dereference)
&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;border-bottom-style: none; border-top-style: none&#34;&gt; &lt;code&gt;&amp;amp;&lt;/code&gt;
&lt;/td&gt;
&lt;td style=&#34;border-bottom-style: none; border-top-style: none&#34;&gt; Address-of
&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;border-bottom-style: none; border-top-style: none&#34;&gt; &lt;code&gt;sizeof&lt;/code&gt;
&lt;/td&gt;
&lt;td style=&#34;border-bottom-style: none; border-top-style: none&#34;&gt; Size-of&lt;sup id=&#34;cite_ref-2&#34; class=&#34;reference&#34;&gt;&lt;a href=&#34;#cite_note-2&#34;&gt;[note 2]&lt;/a&gt;&lt;/sup&gt;
&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;border-bottom-style: none; border-top-style: none&#34;&gt; &lt;code&gt;_Alignof&lt;/code&gt;
&lt;/td&gt;
&lt;td style=&#34;border-bottom-style: none; border-top-style: none&#34;&gt; Alignment requirement&lt;span class=&#34;t-mark-rev t-since-c11&#34;&gt;(C11)&lt;/span&gt;
&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;
&lt;th&gt; 3
&lt;/th&gt;
&lt;td&gt; &lt;code&gt;*&lt;/code&gt; &lt;code&gt;/&lt;/code&gt; &lt;code&gt;%&lt;/code&gt;
&lt;/td&gt;
&lt;td&gt; Multiplication, division, and remainder
&lt;/td&gt;
&lt;td style=&#34;vertical-align: top&#34; rowspan=&#34;11&#34;&gt; Left-to-right
&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;
&lt;th&gt; 4
&lt;/th&gt;
&lt;td&gt; &lt;code&gt;+&lt;/code&gt; &lt;code&gt;-&lt;/code&gt;
&lt;/td&gt;
&lt;td&gt; Addition and subtraction
&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;
&lt;th&gt; 5
&lt;/th&gt;
&lt;td&gt; &lt;code&gt;&amp;lt;&amp;lt;&lt;/code&gt; &lt;code&gt;&amp;gt;&amp;gt;&lt;/code&gt;
&lt;/td&gt;
&lt;td&gt; Bitwise left shift and right shift
&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;
&lt;th rowspan=&#34;2&#34;&gt; 6
&lt;/th&gt;
&lt;td style=&#34;border-bottom-style: none&#34;&gt; &lt;code&gt;&amp;lt;&lt;/code&gt; &lt;code&gt;&amp;lt;=&lt;/code&gt;
&lt;/td&gt;
&lt;td style=&#34;border-bottom-style: none&#34;&gt; For relational operators &amp;lt; and ‚â§ respectively
&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;border-top-style: none&#34;&gt; &lt;code&gt;&amp;gt;&lt;/code&gt; &lt;code&gt;&amp;gt;=&lt;/code&gt;
&lt;/td&gt;
&lt;td style=&#34;border-top-style: none&#34;&gt; For relational operators &amp;gt; and ‚â• respectively
&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;
&lt;th&gt; 7
&lt;/th&gt;
&lt;td&gt; &lt;code&gt;==&lt;/code&gt; &lt;code&gt;!=&lt;/code&gt;
&lt;/td&gt;
&lt;td&gt; For relational = and ‚â† respectively
&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;
&lt;th&gt; 8
&lt;/th&gt;
&lt;td&gt; &lt;code&gt;&amp;amp;&lt;/code&gt;
&lt;/td&gt;
&lt;td&gt; Bitwise AND
&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;
&lt;th&gt; 9
&lt;/th&gt;
&lt;td&gt; &lt;code&gt;^&lt;/code&gt;
&lt;/td&gt;
&lt;td&gt; Bitwise XOR (exclusive or)
&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;
&lt;th&gt; 10
&lt;/th&gt;
&lt;td&gt; &lt;code&gt;|&lt;/code&gt;
&lt;/td&gt;
&lt;td&gt; Bitwise OR (inclusive or)
&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;
&lt;th&gt; 11
&lt;/th&gt;
&lt;td&gt; &lt;code&gt;&amp;amp;&amp;amp;&lt;/code&gt;
&lt;/td&gt;
&lt;td&gt; Logical AND
&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;
&lt;th&gt; 12
&lt;/th&gt;
&lt;td&gt; &lt;code&gt;||&lt;/code&gt;
&lt;/td&gt;
&lt;td&gt; Logical OR
&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;
&lt;th&gt; 13
&lt;/th&gt;
&lt;td&gt; &lt;code&gt;?:&lt;/code&gt;
&lt;/td&gt;
&lt;td&gt; Ternary conditional&lt;sup id=&#34;cite_ref-3&#34; class=&#34;reference&#34;&gt;&lt;a href=&#34;#cite_note-3&#34;&gt;[note 3]&lt;/a&gt;&lt;/sup&gt;
&lt;/td&gt;
&lt;td style=&#34;vertical-align: top&#34; rowspan=&#34;6&#34;&gt; Right-to-Left
&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;
&lt;th rowspan=&#34;5&#34;&gt; 14&lt;sup id=&#34;cite_ref-4&#34; class=&#34;reference&#34;&gt;&lt;a href=&#34;#cite_note-4&#34;&gt;[note 4]&lt;/a&gt;&lt;/sup&gt;
&lt;/th&gt;
&lt;td style=&#34;border-bottom-style: none&#34;&gt; &lt;code&gt;=&lt;/code&gt;
&lt;/td&gt;
&lt;td style=&#34;border-bottom-style: none&#34;&gt; Simple assignment
&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;border-bottom-style: none; border-top-style: none&#34;&gt; &lt;code&gt;+=&lt;/code&gt; &lt;code&gt;-=&lt;/code&gt;
&lt;/td&gt;
&lt;td style=&#34;border-bottom-style: none; border-top-style: none&#34;&gt; Assignment by sum and difference
&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;border-bottom-style: none; border-top-style: none&#34;&gt; &lt;code&gt;*=&lt;/code&gt; &lt;code&gt;/=&lt;/code&gt; &lt;code&gt;%=&lt;/code&gt;
&lt;/td&gt;
&lt;td style=&#34;border-bottom-style: none; border-top-style: none&#34;&gt; Assignment by product, quotient, and remainder
&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;border-bottom-style: none; border-top-style: none&#34;&gt; &lt;code&gt;&amp;lt;&amp;lt;=&lt;/code&gt; &lt;code&gt;&amp;gt;&amp;gt;=&lt;/code&gt;
&lt;/td&gt;
&lt;td style=&#34;border-bottom-style: none; border-top-style: none&#34;&gt; Assignment by bitwise left shift and right shift
&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;border-top-style: none&#34;&gt; &lt;code&gt;&amp;amp;=&lt;/code&gt; &lt;code&gt;^=&lt;/code&gt; &lt;code&gt;|=&lt;/code&gt;
&lt;/td&gt;
&lt;td style=&#34;border-top-style: none&#34;&gt; Assignment by bitwise AND, XOR, and OR
&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;
&lt;th&gt; 15
&lt;/th&gt;
&lt;td&gt; &lt;code&gt;,&lt;/code&gt;
&lt;/td&gt;
&lt;td&gt; Comma
&lt;/td&gt;
&lt;td&gt; Left-to-right
&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;
&lt;ol class=&#34;references&#34;&gt;
&lt;li id=&#34;cite_note-1&#34;&gt;&lt;span class=&#34;mw-cite-backlink&#34;&gt;&lt;a href=&#34;#cite_ref-1&#34;&gt;‚Üë&lt;/a&gt;&lt;/span&gt; &lt;span class=&#34;reference-text&#34;&gt;The operand of prefix &lt;code&gt;++&lt;/code&gt; and &lt;code&gt;\-\-&lt;/code&gt; can&#39;t be a type cast. This rule grammatically forbids some expressions that would be semantically invalid anyway. Some compilers ignore this rule and detect the invalidity semantically.&lt;/span&gt;
&lt;/li&gt;
&lt;li id=&#34;cite_note-2&#34;&gt;&lt;span class=&#34;mw-cite-backlink&#34;&gt;&lt;a href=&#34;#cite_ref-2&#34;&gt;‚Üë&lt;/a&gt;&lt;/span&gt; &lt;span class=&#34;reference-text&#34;&gt;The operand of &lt;code&gt;sizeof&lt;/code&gt; can&#39;t be a type cast: the expression &lt;code&gt;sizeof (int) * p&lt;/code&gt; is unambiguously interpreted as &lt;code&gt;(sizeof(int)) * p&lt;/code&gt;, but not &lt;code&gt;sizeof((int)*p)&lt;/code&gt;.&lt;/span&gt;
&lt;/li&gt;
&lt;li id=&#34;cite_note-3&#34;&gt;&lt;span class=&#34;mw-cite-backlink&#34;&gt;&lt;a href=&#34;#cite_ref-3&#34;&gt;‚Üë&lt;/a&gt;&lt;/span&gt; &lt;span class=&#34;reference-text&#34;&gt;The expression in the middle of the conditional operator (between &lt;code&gt;&lt;b&gt;?&lt;/b&gt;&lt;/code&gt; and &lt;code&gt;&lt;b&gt;:&lt;/b&gt;&lt;/code&gt;) is parsed as if parenthesized: its precedence relative to &lt;code&gt;?:&lt;/code&gt; is ignored.&lt;/span&gt;
&lt;/li&gt;
&lt;li id=&#34;cite_note-4&#34;&gt;&lt;span class=&#34;mw-cite-backlink&#34;&gt;&lt;a href=&#34;#cite_ref-4&#34;&gt;‚Üë&lt;/a&gt;&lt;/span&gt; &lt;span class=&#34;reference-text&#34;&gt;Assignment operators&#39; left operands must be unary (level-2 non-cast) expressions. This rule grammatically forbids some expressions that would be semantically invalid anyway. Many compilers ignore this rule and detect the invalidity semantically. For example, &lt;span class=&#34;t-c&#34;&gt;&lt;span class=&#34;mw-geshi c source-c&#34;&gt;e &lt;span class=&#34;sy1&#34;&gt;=&lt;/span&gt; a &lt;span class=&#34;sy1&#34;&gt;&amp;lt;&lt;/span&gt; d &lt;span class=&#34;sy4&#34;&gt;?&lt;/span&gt; a&lt;span class=&#34;sy2&#34;&gt;++&lt;/span&gt; &lt;span class=&#34;sy4&#34;&gt;:&lt;/span&gt; a &lt;span class=&#34;sy1&#34;&gt;=&lt;/span&gt; d&lt;/span&gt;&lt;/span&gt; is an expression that cannot be parsed because of this rule. However, many compilers ignore this rule and parse it as &lt;span class=&#34;t-c&#34;&gt;&lt;span class=&#34;mw-geshi c source-c&#34;&gt;e &lt;span class=&#34;sy1&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;br0&#34;&gt;(&lt;/span&gt; &lt;span class=&#34;br0&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;br0&#34;&gt;(&lt;/span&gt;a &lt;span class=&#34;sy1&#34;&gt;&amp;lt;&lt;/span&gt; d&lt;span class=&#34;br0&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;sy4&#34;&gt;?&lt;/span&gt; &lt;span class=&#34;br0&#34;&gt;(&lt;/span&gt;a&lt;span class=&#34;sy2&#34;&gt;++&lt;/span&gt;&lt;span class=&#34;br0&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;sy4&#34;&gt;:&lt;/span&gt; a&lt;span class=&#34;br0&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;sy1&#34;&gt;=&lt;/span&gt; d &lt;span class=&#34;br0&#34;&gt;)&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;, and then give an error because it is semantically invalid.&lt;/span&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;h2 id=&#34;impact-of-data-types-on-expressions&#34;&gt;Impact of Data Types on Expressions&lt;/h2&gt;
&lt;p&gt;In &lt;code&gt;C++&lt;/code&gt;, the data type of the variables involved in an expression significantly impacts the result. For instance, dividing two integers results in an integer, while using at least one floating-point number yields a floating-point result. Understanding how data types interact within expressions is crucial for accurate calculations and avoiding common pitfalls like integer truncation.&lt;/p&gt;
&lt;p&gt;Here are some key points about integer truncation and other common pitfalls in C++:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Integer Truncation&lt;/strong&gt;: This occurs when the result of a division or other operation between integers is a floating-point number, but the data type is an integer. For example, &lt;code&gt;int result = 5 / 2;&lt;/code&gt; will store &lt;code&gt;2&lt;/code&gt; in &lt;code&gt;result&lt;/code&gt;, not &lt;code&gt;2.5&lt;/code&gt;, as the fractional part is truncated.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Implicit Type Conversions&lt;/strong&gt;: &lt;code&gt;C++&lt;/code&gt; automatically converts types in certain situations, which can lead to unexpected results. For instance, mixing signed and unsigned integers in expressions can cause unexpected behaviours due to implicit type conversions.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Overflow and Underflow&lt;/strong&gt;: This happens when a variable is assigned a value outside its range. For example, storing a value larger than the maximum value that an &lt;code&gt;int&lt;/code&gt; can hold will result in overflow, leading to unexpected values.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Precision Loss in Floating-Point Numbers&lt;/strong&gt;: Floating-point variables can lose precision, especially when dealing with very large or very small numbers. This can result in rounding errors in calculations.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Division by Zero&lt;/strong&gt;: This can occur if a program inadvertently divides a number by zero. It&amp;rsquo;s a critical error in &lt;code&gt;C++&lt;/code&gt; and can cause a program to crash or behave unpredictably.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Uninitialized Variables&lt;/strong&gt;: Using variables before initializing them can lead to unpredictable results, as they may contain random data.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Pointer Errors&lt;/strong&gt;: Common mistakes with pointers include dereferencing a null or uninitialized pointer, pointer arithmetic errors, and memory leaks.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Operator Precedence Mistakes&lt;/strong&gt;: Misunderstanding the order in which operations are performed can lead to bugs. For example, assuming that &lt;code&gt;a + b * c&lt;/code&gt; adds &lt;code&gt;a&lt;/code&gt; and &lt;code&gt;b&lt;/code&gt; before multiplying by &lt;code&gt;c&lt;/code&gt; (it doesn&amp;rsquo;t; multiplication is done first).&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Assuming Size of Data Types is Constant&lt;/strong&gt;: The size of data types like &lt;code&gt;int&lt;/code&gt; can vary depending on the system. Assuming a constant size can lead to errors, particularly when performing operations like bit manipulation or working with binary file formats.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Not Checking the Return Value of Functions&lt;/strong&gt;: When functions return values to indicate success or failure, not checking these can lead to the program continuing as if nothing went wrong, even when errors have occurred.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;role-of-type-casting-in-expressions&#34;&gt;Role of Type Casting in Expressions&lt;/h2&gt;
&lt;p&gt;Type casting in expressions can be used to explicitly convert data from one type to another. This technique is particularly useful in situations where operations between different data types are necessary. For example, casting an integer to a float in a division operation to obtain a floating-point result. However, it&amp;rsquo;s important to use type casting judiciously to maintain the precision and integrity of data.&lt;/p&gt;
&lt;h2 id=&#34;the-significance-of-expression-evaluation-order&#34;&gt;The Significance of Expression Evaluation Order&lt;/h2&gt;
&lt;p&gt;While operator precedence and associativity rules dictate the order of operations in an expression, the sequence in which expressions are evaluated can also be influenced by function calls, side effects, and sequence points. Understanding how &lt;code&gt;C++&lt;/code&gt; evaluates expressions, especially in complex statements, is essential for debugging and writing predictable code.&lt;/p&gt;
&lt;h2 id=&#34;compiler-optimizations-and-expressions&#34;&gt;Compiler Optimizations and Expressions&lt;/h2&gt;
&lt;p&gt;Modern &lt;code&gt;C++&lt;/code&gt; compilers often optimize expressions to enhance performance. These optimizations might include reordering operations (while respecting the language rules), eliminating redundant calculations, or simplifying expressions at compile time. Being aware of these potential optimizations can help in writing more efficient code and understanding any discrepancies between the written code and its execution behaviour.&lt;/p&gt;
&lt;h2 id=&#34;best-practices-for-writing-expressions&#34;&gt;Best Practices for Writing Expressions&lt;/h2&gt;
&lt;p&gt;To maintain readability and reduce errors in &lt;code&gt;C++&lt;/code&gt;, it&amp;rsquo;s advisable to write clear and simple expressions. Avoid overly complex expressions, use parentheses to clarify order of operations, and follow coding standards and guidelines. Readable expressions are easier to debug, maintain, and understand, especially in collaborative environments.&lt;/p&gt;
&lt;p&gt;Adding these paragraphs can provide a more comprehensive and nuanced understanding of expressions in &lt;code&gt;C++&lt;/code&gt;, catering to both beginners and experienced programmers.&lt;/p&gt;
&lt;h1 id=&#34;references&#34;&gt;References&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;C Operator Precedence - &lt;a href=&#34;https://en.cppreference.com/w/c/language/operator_precedence#cite_note-1&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://en.cppreference.com/w/c/language/operator_precedence#cite_note-1&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&#34;citation&#34;&gt;Citation&lt;/h1&gt;
&lt;ol&gt;
&lt;li&gt;For attribution, please cite this work as:&lt;/li&gt;
&lt;/ol&gt;
&lt;div class=&#34;div-1&#34;&gt;
Oliveira T.P. (2020, Dec. 16). Expressions in C++
&lt;/div&gt;
&lt;ol start=&#34;2&#34;&gt;
&lt;li&gt;BibTeX citation&lt;/li&gt;
&lt;/ol&gt;
&lt;pre&gt;&lt;code&gt;@misc{oliveira2020expression,
  author = {Oliveira, Thiago},
  title = {Expressions in C++},
  url = {https://prof-thiagooliveira.netlify.app/post/expressions/},
  year = {2020}
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;Did you find this page helpful? Consider sharing it üôå&lt;/strong&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>How hard is it to predict COVID-19 cases?</title>
      <link>https://prof-thiagooliveira.netlify.com/post/how-hard-is-it-to-predict-covid-19-cases/</link>
      <pubDate>Wed, 16 Dec 2020 00:00:00 +0000</pubDate>
      <guid>https://prof-thiagooliveira.netlify.com/post/how-hard-is-it-to-predict-covid-19-cases/</guid>
      <description>


&lt;div id=&#34;tldr&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;tl;dr&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;Many different variables affect how the pandemic progresses and it is extremely difficult to identify each one, and precisely measure them.&lt;/li&gt;
&lt;li&gt;The data we have is surely innacurate, but could be a good proxy for understanding the behaviour of the coronavirus outbreak&lt;/li&gt;
&lt;li&gt;We developed a statistical model to obtain short-term forecasts of the number of COVID-19 cases&lt;/li&gt;
&lt;li&gt;We constantly update forecasts and make all results freely available to any country in the world through a web &lt;a href=&#34;link&#34;&gt;app&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;how-many-people-will-get-infected-tomorrow&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;How many people will get infected tomorrow?&lt;/h1&gt;
&lt;p&gt;‚ÄúHow many cases do you think we‚Äôre going to have today?‚Äù, my fianc√®e asked me just as I‚Äôm writing this post ‚Äì and quite frankly I‚Äôve asked that myself many times over the last several months. Wouldn‚Äôt it be great if we had a method to accurately predict the number of confirmed COVID-19 cases we‚Äôll have every single day for, say, the next month? If we could do that, we‚Äôd know whether our measures to contain the virus are working, whether we would be able to lift particular restrictions here and there, invest in intensive care units, or whether that wedding we had planned long ago would finally happen or have to be postponed‚Ä¶ again.&lt;/p&gt;
&lt;p&gt;It is very hard, however, to pinpoint exactly every single factor that affects the number of reported COVID-19 cases, and most importantly, measure them all. Here we try and outline different techniques we could use to try and predict how the outbreak will behave in the future, and show a particular method we have developed to obtain short-term forecasts with a reasonable degree of accuracy. We have packaged the method into an app, which you can access &lt;a href=&#34;link&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;what-strategies-can-we-use&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;What strategies can we use?&lt;/h1&gt;
&lt;p&gt;There are many different strategies and mathematical/statistical tools we can use to attempt to predict the future. These can include what we call mechanistic, or compartment models, for example. These make assumptions based on empirical evidence of the biological system being studied and translate them into mathematical equations based on the flow of individuals to/from specific compartments. For COVID-19 the SEIR-type model has been widely used by many research groups to describe the behaviour of the outbreak (see our &lt;a href=&#34;https://www.hamilton.ie/covid19/posts/2020-09-11-how-long-will-covid-19-last-in-ireland/&#34;&gt;blog post&lt;/a&gt; on the use of SEIR models to predict when the pandemic will end). They are realistic in the sense that they reflect the epidemiological behaviour of the outbreak.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;SEIR.png&#34; width=&#34;700px&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;There are other alternatives that do not take into account the true biological nature of the phenomenon per se, but may use it as input in a different way. Many &lt;a href=&#34;https://en.wikipedia.org/wiki/Machine_learning&#34;&gt;machine learning&lt;/a&gt; techniques could sometimes be seen as black-box methods, that would e.g.¬†take the reported number of past COVID-19 cases and other variables that we would believe could influence this number and spit out a prediction for tomorrow, or next week, next month, etc. There are cases where these methods are even more accurate than mechanistic models, however there is a trade-off to consider here in terms of prediction accuracy vs.¬†explainability, as &lt;a href=&#34;https://royalsocietypublishing.org/doi/10.1098/rsbl.2017.0660&#34;&gt;discussed here&lt;/a&gt;. If a new event or variable comes into play, which could empirically be very important to dictate the future behaviour of the pandemic, it is very difficult to gauge its effects using a black-box method.&lt;/p&gt;
&lt;p&gt;We could also simply assume that the number of reported COVID-19 cases today is purely a reflection of the reported number of cases yesterday, and the day before, and so on. So we pretty much assume all variables that influence this process can be summarised purely by the outcomes we have observed in the past, and this can in turn be used to forecast what future numbers will be. Of course, there are plenty of different ways to include other variables in these types of models, but the important thing is to notice that we place a very heavy assumption on an underlying process that is able to explain its own behaviour. We usually refer to these models as &lt;a href=&#34;https://en.wikipedia.org/wiki/Time_series&#34;&gt;‚Äútime series‚Äù&lt;/a&gt; or ‚Äústate-space‚Äù models.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;why-is-it-so-difficult&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Why is it so difficult?&lt;/h1&gt;
&lt;p&gt;There are many factors that influence our ability to predict the number of future COVID-19 cases. Imagine we have, for example, a fantastic SEIR-type model that can reproduce the dynamics of the disease almost perfectly up to today. To be able to predict with great accuracy what will happen tomorrow (or even further down the line), we must assume, among other things, that the assumptions that hold today will still hold tomorrow and so on. If any new variable comes into play, or if the variables that are involved change over time, our predictions can be completely off.&lt;/p&gt;
&lt;p&gt;This is not the worst problem, however. There are in fact many variables that we‚Äôre simply not able to measure with good precision. This includes knowing, for example, where everybody in the country is at all times, who they talk to, for how long, where they will be, etc. This is why it is important to do &lt;a href=&#34;https://www2.hse.ie/conditions/coronavirus/close-contact-and-casual-contact.html&#34;&gt;contact tracing&lt;/a&gt;, although this matters mostly in a retrospective way, not necessarily to predict what will happen in the future.&lt;/p&gt;
&lt;p&gt;But wait a minute now, we don‚Äôt even know whether the data we can actually measure is in fact accurate! Or to be more specific, we do know that our data is definitely &lt;em&gt;not&lt;/em&gt; 100% accurate. Cases reported today could reflect infections that happened between a few days ago to several weeks. Tests are not 100% accurate either, so there is a pool of false positives in there, as well as false negatives not being included in the whole sum. Simply put, the data we have is pretty much a proxy of the real thing. Hence why it is so important to understand what these numbers could actually mean, and not &lt;a href=&#34;https://www.newscientist.com/article/mg24732954-000-david-spiegelhalter-how-to-be-a-coronavirus-statistics-sleuth/&#34;&gt;imbue them with improper meaning&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;what-about-short-term-forecasting&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;What about short-term forecasting?&lt;/h1&gt;
&lt;p&gt;So long-term forecasting is very prone to built-up variation and error, as we all know. It‚Äôs just like predicting what time you‚Äôll wake up on your birthday 10 years from now. But there must be something we could do in the short-term, right? Well, it depends on how ‚Äúlong‚Äù this short-term is. And it also depends on how we want to use this information.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://arxiv.org/abs/2006.00111&#34;&gt;We developed a modelling framework&lt;/a&gt; in an attempt to predict the number of reported COVID-19 cases for up to 7 days in the future. We fitted our models to the data collected by the &lt;a href=&#34;https://www.ecdc.europa.eu/en&#34;&gt;ECDC&lt;/a&gt; to generate the forecasts. See below for a validation study we carried out back in May/2020.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;forecast.png&#34; width=&#34;800px&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;The panels are in the logarithmic scale, but in essence, the closer the points are to the identity line (dashed line), the closer our model was in predicting the number of COVID-19 cases up to 7 days ahead (panels in part &lt;em&gt;A&lt;/em&gt;). In part &lt;em&gt;B&lt;/em&gt; we see that the accuracy of the method is high for all 7 days ahead, but we begin to lose in terms of precision from day four onwards. (&lt;span class=&#34;math inline&#34;&gt;\(r\)&lt;/span&gt; represents &lt;a href=&#34;https://en.wikipedia.org/wiki/Pearson_correlation_coefficient&#34;&gt;Pearson‚Äôs linear correlation coefficient&lt;/a&gt;, the closest it is to 1 the better the method is; the same applies to the CCC - the &lt;a href=&#34;https://en.wikipedia.org/wiki/Concordance_correlation_coefficient&#34;&gt;concordance correlation coefficient&lt;/a&gt;.)&lt;/p&gt;
&lt;p&gt;The idea behind this is not to be able to inform governments the exact numbers we‚Äôd expect tomorrow, but to give more perspective in terms of the types of trends we expect in the near future. This is useful to inform decision making related to the healthcare services. For instance, if a particular country‚Äôs healthcare system is currently at capacity, and we are predicting an upward trend in the number of infections, then this could guide policy in terms of resource allocation to accommodate the extra patients that are likely to seek health professionals in the upcoming weeks. This is why it is so important to look at overall trends (for example, the number of cases per 100,000 people over the last 14 days).&lt;/p&gt;
&lt;p&gt;Our model creates predictions based on two components. The first, called the autoregressive component, uses information on the past number of cases to predict future ones. The second is included to account for extra variability that could occur for a variety of different reasons. The autoregressive component is directly linked to the behaviour of the outbreak, so it is useful to detect waves of the pandemic. See, for example, our latest estimates for Ireland:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;Ireland.png&#34; width=&#34;500px&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;We can clearly see that towards the end of July this second wave was already starting to take shape, and now we are aiming at a new peak of cases.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;grouping-countries-together&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Grouping countries together&lt;/h1&gt;
&lt;p&gt;Now that we have profiles for each country on how the pandemic is behaving in terms of number of cases, perhaps it would be a good idea to look at which countries present a similar behaviour over the last, say, 60 days. We created a dendrogram based on a cluster analysis performed using the values of the autoregressive parameter and produced the figure below ‚Äì&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;dendrogram.png&#34; width=&#34;1000px&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Here we see that over looking at the past two months, the country that has presented the most similar behaviour to Ireland was Croatia. In our &lt;a href=&#34;link&#34;&gt;app&lt;/a&gt; you can play with different ways of presenting the dendrogram, as well as print names of different countries in bold to aid in finding them easily when looking at the picture. You can also change the number of clusters.&lt;/p&gt;
&lt;p&gt;Perhaps these comparisons would be useful in terms of comparing government policies on how to deal with the COVID-19 outbreak, and learn lessons from successful policies vs unsuccessful ones. Also, this type of modelling can help to detect a further wave of the outbreak sooner rather than when we are already in the middle of it!&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;all-models-are-wrong&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;All models are wrong‚Ä¶&lt;/h1&gt;
&lt;p&gt;In the end of the day, there is no true, correct model we can apply. After all, it is impossible to know exactly what the data generating mechanism is. We can only attempt to understand it and reproduce its behaviour using mathematical/statistical tools. We hope, however, that our modelling approach can be useful. We could point a whole list of problems with it here, such as completely ignoring biological mechanisms and using just past behaviour to explain future behaviour without any additional context. But we believe it represents a reasonable attempt at forecasting the number of COVID-19 cases in the short-term.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Did you find this page helpful? Consider sharing it üôå&lt;/strong&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;citation&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Citation&lt;/h1&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;For attribution, please cite this work as:&lt;/li&gt;
&lt;/ol&gt;
&lt;div class=&#34;div-1&#34;&gt;
&lt;p&gt;Moral, et al.¬†(2020, Sept.¬†29). Ireland‚Äôs COVID-19 Data Dive: How hard is it to predict COVID-19 cases?. Retrieved from &lt;a href=&#34;https://www.hamilton.ie/covid19/posts/2020-10-01-how-hard-to-predict-cases/&#34; class=&#34;uri&#34;&gt;https://www.hamilton.ie/covid19/posts/2020-10-01-how-hard-to-predict-cases/&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;ol start=&#34;2&#34; style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;BibTeX citation&lt;/li&gt;
&lt;/ol&gt;
&lt;pre&gt;&lt;code&gt;@misc{moral2020how,
  author = {Moral, Rafael and Oliveira, Thiago and Parnell, Andrew},
  title = {Ireland&amp;#39;s COVID-19 Data Dive: How hard is it to predict COVID-19 cases?},
  url = {https://www.hamilton.ie/covid19/posts/2020-10-01-how-hard-to-predict-cases/},
  year = {2020}
}&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Signed and Unsigned Binary Numbers</title>
      <link>https://prof-thiagooliveira.netlify.com/post/signed-and-unsigned-binary-numbers/</link>
      <pubDate>Wed, 16 Dec 2020 00:00:00 +0000</pubDate>
      <guid>https://prof-thiagooliveira.netlify.com/post/signed-and-unsigned-binary-numbers/</guid>
      <description>&lt;h1 id=&#34;introduction&#34;&gt;Introduction&lt;/h1&gt;
&lt;p&gt;When we think about writing a program in C, the first step is understand how variables should be assigned. There are several variable&amp;rsquo;s type in C, and here we are introducing the type &lt;code&gt;int&lt;/code&gt;, which is used for integer data types. Basically, we can define a variable as an integer in two ways:&lt;/p&gt;
&lt;div class=&#34;div-1&#34;&gt;
* Uninitialized variable: defined as `int x;`, where no value is assign to the variable $x$ (Figure 1), which generally is not a good idea as it could lead to a bug in the algorithm if no value is assign over the code. 
* Initialized variable: there are two ways to assign a value to a variable $x$ (Figure 1):
  &lt;div class = &#34;div-2&#34;&gt;
    * in a single declaration -  `int x = 3;`
    * in a double step declaration - `int x;` and `x = 3;`
  &lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;figure&#34; style=&#34;text-align: center&#34;&gt;
&lt;img src=&#34;var_and_exp.png&#34; alt=&#34;Declaring variables in C&#34; width=&#34;550px&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;Declaring variables in C&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;Additionally, there are a large set of storage size-specific declarations for a integer, and here we will explain just an initial idea about it. Figure 2 showns the Integer representation of whole numbers or fixed-point numbers (fixed number of digits). Generally, computers use a fixed number of bits to represent them, where commonly used bit-lengths for integers are 8-bit, 16-bit (&lt;code&gt;short&lt;/code&gt;), 32-bit (&lt;code&gt;long&lt;/code&gt;) or 64-bit (&lt;code&gt;long long&lt;/code&gt;). There are two representation schemes for integers called signed integer type (&lt;code&gt;signed int&lt;/code&gt;) capable of containing the range of values from -32,767 to 32,767, and unsigned integer type (&lt;code&gt;unsigned int&lt;/code&gt;) containing the range of values from 0 to 65,535 ($32767 \times 2+1$). Therefore, &lt;code&gt;unsigned&lt;/code&gt; qualifier should be used when we are working with only positive values.&lt;/p&gt;
&lt;div class=&#34;figure&#34; style=&#34;text-align: center&#34;&gt;
&lt;img src=&#34;binary_number.png&#34; alt=&#34;Integer Representation&#34; width=&#34;500px&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;Integer Representation&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;Furthermore, there are three representation schemes for signed integers called &lt;em&gt;Sign-Magnitude representation&lt;/em&gt;, &lt;em&gt;1&amp;rsquo;s Complement representation&lt;/em&gt;, and &lt;em&gt;2&amp;rsquo;s Complement representation&lt;/em&gt;. The 1‚Äôs and the 2‚Äôs complements of a binary number are important because they permit different representation for negative numbers. In all of these schemes, positive signed binary numbers starts with value 0 while negative ones starts with value 1 (Figure 3).&lt;/p&gt;
&lt;div class=&#34;figure&#34; style=&#34;text-align: center&#34;&gt;
&lt;img src=&#34;sign_bit.png&#34; alt=&#34;Signed binary numbers&#34; width=&#34;300px&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;Signed binary numbers&lt;/p&gt;
&lt;/div&gt;
Consequently, the disadvantage of signed binary numbers is that there is 1 bit used to store the sign positive or negative while the remaning $n-1$ bits are assign to the range of digits from $-2^{n-1}$ to $2^{n-1}$. If we have 8 bits to represent a signed binary number, we have to use 1 bit for the **sign bit** and 7 bits for the **magnitude bits**:
&lt;div class=&#34;div-1&#34;&gt;
* Using Sign-Magnitude Representation:
$$-|2^{\left(8-1\right)}-1| \mbox{ to } 2^{\left(8-1\right)}-1 = -127 \mbox{ to } 127$$
* Using 2&#39;s Complement Representation:
$$-2^{\left(8-1\right)} \mbox{ to } 2^{\left(8-1\right)}-1 = -128 \mbox{ to } 127$$
&lt;/div&gt;
Thus, we can representing the numbers ranging from -128 to 127 using 2&#39;s Complement Representation. Probably now you are asking why there is one extra number being accounted when using 2&#39;s Complement Representation. The answer can be found in the Figure 4.
&lt;div class=&#34;figure&#34; style=&#34;text-align: center&#34;&gt;
&lt;img src=&#34;repre_scheme.png&#34; alt=&#34;Representation schemes of Sign-Magnitude Representation and 2&#39;s Complement Representation&#34; width=&#34;400px&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;Representation schemes of Sign-Magnitude Representation and 2&#39;s Complement Representation&lt;/p&gt;
&lt;/div&gt;
&lt;h1 id=&#34;examples&#34;&gt;Examples&lt;/h1&gt;
&lt;h2 id=&#34;unsigned-int&#34;&gt;Unsigned int&lt;/h2&gt;
&lt;p&gt;Supose we are interested in representing a sequence of number $x$ where $x \in \lbrace 0, 1, \ldots, 15\rbrace$. We can assign these numbers as unsigned numbers of 4 bits. Consequently, we have &lt;strong&gt;4 zero&lt;/strong&gt; bits associated to describe this numbers because our variable belongs to the interval $[0, 2^{4}‚àí1] \in \mathcal{N}_{0}$.&lt;/p&gt;
&lt;table class=&#34;table table-striped table-hover&#34; style=&#34;margin-left: auto; margin-right: auto;&#34;&gt;
&lt;caption&gt;Representation of numbers from 0 to 15 in 4 bits&lt;/caption&gt;
&lt;tbody&gt;
  &lt;tr&gt;
   &lt;td style=&#34;text-align:left;font-weight: bold;border-right:1px solid;&#34;&gt; bits &lt;/td&gt;
   &lt;td style=&#34;text-align:left;&#34;&gt; 0000 &lt;/td&gt;
   &lt;td style=&#34;text-align:left;&#34;&gt; 0001 &lt;/td&gt;
   &lt;td style=&#34;text-align:left;&#34;&gt; 0010 &lt;/td&gt;
   &lt;td style=&#34;text-align:left;&#34;&gt; 0011 &lt;/td&gt;
   &lt;td style=&#34;text-align:left;&#34;&gt; 0100 &lt;/td&gt;
   &lt;td style=&#34;text-align:left;&#34;&gt; 0101 &lt;/td&gt;
   &lt;td style=&#34;text-align:left;&#34;&gt; 0110 &lt;/td&gt;
   &lt;td style=&#34;text-align:left;&#34;&gt; 0111 &lt;/td&gt;
   &lt;td style=&#34;text-align:left;&#34;&gt; 1000 &lt;/td&gt;
   &lt;td style=&#34;text-align:left;&#34;&gt; 1001 &lt;/td&gt;
   &lt;td style=&#34;text-align:left;&#34;&gt; 1010 &lt;/td&gt;
   &lt;td style=&#34;text-align:left;&#34;&gt; 1011 &lt;/td&gt;
   &lt;td style=&#34;text-align:left;&#34;&gt; 1100 &lt;/td&gt;
   &lt;td style=&#34;text-align:left;&#34;&gt; 1101 &lt;/td&gt;
   &lt;td style=&#34;text-align:left;&#34;&gt; 1110 &lt;/td&gt;
   &lt;td style=&#34;text-align:left;&#34;&gt; 1111 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style=&#34;text-align:left;font-weight: bold;border-right:1px solid;&#34;&gt; x &lt;/td&gt;
   &lt;td style=&#34;text-align:left;&#34;&gt; 0 &lt;/td&gt;
   &lt;td style=&#34;text-align:left;&#34;&gt; 1 &lt;/td&gt;
   &lt;td style=&#34;text-align:left;&#34;&gt; 2 &lt;/td&gt;
   &lt;td style=&#34;text-align:left;&#34;&gt; 3 &lt;/td&gt;
   &lt;td style=&#34;text-align:left;&#34;&gt; 4 &lt;/td&gt;
   &lt;td style=&#34;text-align:left;&#34;&gt; 5 &lt;/td&gt;
   &lt;td style=&#34;text-align:left;&#34;&gt; 6 &lt;/td&gt;
   &lt;td style=&#34;text-align:left;&#34;&gt; 7 &lt;/td&gt;
   &lt;td style=&#34;text-align:left;&#34;&gt; 8 &lt;/td&gt;
   &lt;td style=&#34;text-align:left;&#34;&gt; 9 &lt;/td&gt;
   &lt;td style=&#34;text-align:left;&#34;&gt; 10 &lt;/td&gt;
   &lt;td style=&#34;text-align:left;&#34;&gt; 11 &lt;/td&gt;
   &lt;td style=&#34;text-align:left;&#34;&gt; 12 &lt;/td&gt;
   &lt;td style=&#34;text-align:left;&#34;&gt; 13 &lt;/td&gt;
   &lt;td style=&#34;text-align:left;&#34;&gt; 14 &lt;/td&gt;
   &lt;td style=&#34;text-align:left;&#34;&gt; 15 &lt;/td&gt;
  &lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h2 id=&#34;signed-int&#34;&gt;Signed int&lt;/h2&gt;
&lt;p&gt;Supose now we are interested in representing a sequence of number $y$ where $y \in \lbrace -7, -6, \ldots,6, 7\rbrace$. We have to assign them as signed numbers using 4 bits because 1 bit will be used for &lt;strong&gt;sign bit&lt;/strong&gt; and 3 bits for the &lt;strong&gt;magnitude bits&lt;/strong&gt; to describe $y \in \left[-|2^3-1|,2^3-1\right] \in \mathcal{Z}$.&lt;/p&gt;
&lt;table class=&#34;table table-striped table-hover&#34; style=&#34;margin-left: auto; margin-right: auto;&#34;&gt;
&lt;caption&gt;Sign-Magnitude Representation of numbers from -7 to 7 using 4 bits&lt;/caption&gt;
&lt;tbody&gt;
  &lt;tr&gt;
   &lt;td style=&#34;text-align:left;font-weight: bold;border-right:1px solid;&#34;&gt; bits &lt;/td&gt;
   &lt;td style=&#34;text-align:left;&#34;&gt; 0111 &lt;/td&gt;
   &lt;td style=&#34;text-align:left;&#34;&gt; 0110 &lt;/td&gt;
   &lt;td style=&#34;text-align:left;&#34;&gt; 0101 &lt;/td&gt;
   &lt;td style=&#34;text-align:left;&#34;&gt; 0100 &lt;/td&gt;
   &lt;td style=&#34;text-align:left;&#34;&gt; 0011 &lt;/td&gt;
   &lt;td style=&#34;text-align:left;&#34;&gt; 0010 &lt;/td&gt;
   &lt;td style=&#34;text-align:left;&#34;&gt; 0001 &lt;/td&gt;
   &lt;td style=&#34;text-align:left;&#34;&gt; 0000 &lt;/td&gt;
   &lt;td style=&#34;text-align:left;&#34;&gt; 1000 &lt;/td&gt;
   &lt;td style=&#34;text-align:left;&#34;&gt; 1001 &lt;/td&gt;
   &lt;td style=&#34;text-align:left;&#34;&gt; 1010 &lt;/td&gt;
   &lt;td style=&#34;text-align:left;&#34;&gt; 1011 &lt;/td&gt;
   &lt;td style=&#34;text-align:left;&#34;&gt; 1100 &lt;/td&gt;
   &lt;td style=&#34;text-align:left;&#34;&gt; 1101 &lt;/td&gt;
   &lt;td style=&#34;text-align:left;&#34;&gt; 1110 &lt;/td&gt;
   &lt;td style=&#34;text-align:left;&#34;&gt; 1111 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style=&#34;text-align:left;font-weight: bold;border-right:1px solid;&#34;&gt; y &lt;/td&gt;
   &lt;td style=&#34;text-align:left;&#34;&gt; 7 &lt;/td&gt;
   &lt;td style=&#34;text-align:left;&#34;&gt; 6 &lt;/td&gt;
   &lt;td style=&#34;text-align:left;&#34;&gt; 5 &lt;/td&gt;
   &lt;td style=&#34;text-align:left;&#34;&gt; 4 &lt;/td&gt;
   &lt;td style=&#34;text-align:left;&#34;&gt; 3 &lt;/td&gt;
   &lt;td style=&#34;text-align:left;&#34;&gt; 2 &lt;/td&gt;
   &lt;td style=&#34;text-align:left;&#34;&gt; 1 &lt;/td&gt;
   &lt;td style=&#34;text-align:left;&#34;&gt; 0 &lt;/td&gt;
   &lt;td style=&#34;text-align:left;&#34;&gt; -0 &lt;/td&gt;
   &lt;td style=&#34;text-align:left;&#34;&gt; -1 &lt;/td&gt;
   &lt;td style=&#34;text-align:left;&#34;&gt; -2 &lt;/td&gt;
   &lt;td style=&#34;text-align:left;&#34;&gt; -3 &lt;/td&gt;
   &lt;td style=&#34;text-align:left;&#34;&gt; -4 &lt;/td&gt;
   &lt;td style=&#34;text-align:left;&#34;&gt; -5 &lt;/td&gt;
   &lt;td style=&#34;text-align:left;&#34;&gt; -6 &lt;/td&gt;
   &lt;td style=&#34;text-align:left;&#34;&gt; -7 &lt;/td&gt;
  &lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;table class=&#34;table table-striped table-hover&#34; style=&#34;margin-left: auto; margin-right: auto;&#34;&gt;
&lt;caption&gt;2&#39;s Complement Representation of numbers from -8 to 7 using 4 bits&lt;/caption&gt;
&lt;tbody&gt;
  &lt;tr&gt;
   &lt;td style=&#34;text-align:left;font-weight: bold;border-right:1px solid;&#34;&gt; bits &lt;/td&gt;
   &lt;td style=&#34;text-align:left;&#34;&gt; 1000 &lt;/td&gt;
   &lt;td style=&#34;text-align:left;&#34;&gt; 1001 &lt;/td&gt;
   &lt;td style=&#34;text-align:left;&#34;&gt; 1010 &lt;/td&gt;
   &lt;td style=&#34;text-align:left;&#34;&gt; 1011 &lt;/td&gt;
   &lt;td style=&#34;text-align:left;&#34;&gt; 1100 &lt;/td&gt;
   &lt;td style=&#34;text-align:left;&#34;&gt; 1101 &lt;/td&gt;
   &lt;td style=&#34;text-align:left;&#34;&gt; 1110 &lt;/td&gt;
   &lt;td style=&#34;text-align:left;&#34;&gt; 1111 &lt;/td&gt;
   &lt;td style=&#34;text-align:left;&#34;&gt; 0000 &lt;/td&gt;
   &lt;td style=&#34;text-align:left;&#34;&gt; 0001 &lt;/td&gt;
   &lt;td style=&#34;text-align:left;&#34;&gt; 0010 &lt;/td&gt;
   &lt;td style=&#34;text-align:left;&#34;&gt; 0011 &lt;/td&gt;
   &lt;td style=&#34;text-align:left;&#34;&gt; 0100 &lt;/td&gt;
   &lt;td style=&#34;text-align:left;&#34;&gt; 0101 &lt;/td&gt;
   &lt;td style=&#34;text-align:left;&#34;&gt; 0110 &lt;/td&gt;
   &lt;td style=&#34;text-align:left;&#34;&gt; 0111 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style=&#34;text-align:left;font-weight: bold;border-right:1px solid;&#34;&gt; y &lt;/td&gt;
   &lt;td style=&#34;text-align:left;&#34;&gt; -8 &lt;/td&gt;
   &lt;td style=&#34;text-align:left;&#34;&gt; -7 &lt;/td&gt;
   &lt;td style=&#34;text-align:left;&#34;&gt; -6 &lt;/td&gt;
   &lt;td style=&#34;text-align:left;&#34;&gt; -5 &lt;/td&gt;
   &lt;td style=&#34;text-align:left;&#34;&gt; -4 &lt;/td&gt;
   &lt;td style=&#34;text-align:left;&#34;&gt; -3 &lt;/td&gt;
   &lt;td style=&#34;text-align:left;&#34;&gt; -2 &lt;/td&gt;
   &lt;td style=&#34;text-align:left;&#34;&gt; -1 &lt;/td&gt;
   &lt;td style=&#34;text-align:left;&#34;&gt; 0 &lt;/td&gt;
   &lt;td style=&#34;text-align:left;&#34;&gt; 1 &lt;/td&gt;
   &lt;td style=&#34;text-align:left;&#34;&gt; 2 &lt;/td&gt;
   &lt;td style=&#34;text-align:left;&#34;&gt; 3 &lt;/td&gt;
   &lt;td style=&#34;text-align:left;&#34;&gt; 4 &lt;/td&gt;
   &lt;td style=&#34;text-align:left;&#34;&gt; 5 &lt;/td&gt;
   &lt;td style=&#34;text-align:left;&#34;&gt; 6 &lt;/td&gt;
   &lt;td style=&#34;text-align:left;&#34;&gt; 7 &lt;/td&gt;
  &lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h1 id=&#34;references&#34;&gt;References&lt;/h1&gt;
&lt;p&gt;Barnett R.; O&amp;rsquo;Cull L.; Cox, S. Embedded C Programming and the Microship PIC. Delmar Learning, ed. 1, 2004.&lt;/p&gt;
&lt;p&gt;Cadenhead, R.; Liberty, J. Sams Teach Yoirself C++. Pearson Education, ed. 6, 2017.&lt;/p&gt;
&lt;p&gt;C Data Types - &lt;a href=&#34;https://en.wikipedia.org/wiki/C_data_types&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://en.wikipedia.org/wiki/C_data_types&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Did you find this page helpful? Consider sharing it üôå&lt;/strong&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>The seven steps of a programer</title>
      <link>https://prof-thiagooliveira.netlify.com/post/the-seven-steps-of-a-programer/</link>
      <pubDate>Wed, 16 Dec 2020 00:00:00 +0000</pubDate>
      <guid>https://prof-thiagooliveira.netlify.com/post/the-seven-steps-of-a-programer/</guid>
      <description>


&lt;div id=&#34;overview-of-the-seven-steps&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Overview of the Seven Steps&lt;/h1&gt;
&lt;p&gt;The seven steps proposed by Hilton et al.¬†(2019) present an intriguing strategy for initiating a new project involving programming. This approach is concisely summarized in Figure 1. In this discussion, we will elaborate on these steps, drawing upon the work of Hilton et al.¬†(2019).&lt;/p&gt;
&lt;div class=&#34;figure&#34; style=&#34;text-align: center&#34;&gt;&lt;span style=&#34;display:block;&#34; id=&#34;fig:unnamed-chunk-1&#34;&gt;&lt;/span&gt;
&lt;img src=&#34;seven_steps.png&#34; alt=&#34;The seven steps (modified from Hilton et al. (2019))&#34; width=&#34;500px&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;
Figure 1: The seven steps (modified from Hilton et al.¬†(2019))
&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;All steps are then described in the sections below.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;step-1---project-definition-using-simple-examples&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Step 1 - Project definition using simple examples&lt;/h1&gt;
&lt;p&gt;This step involves dedicating time to conceptualize the project and breaking it down into manageable tasks. Begin by manually sketching a diagram of the project, highlighting key topics, strategies for addressing challenges, and estimating the number of primary algorithms required for completion. This should also encompass the subdivision of the project into smaller tasks, their interconnections, and any sequential order for their execution, as depicted in Figure 2. An effective approach in this stage is crucial as it simplifies the subsequent steps.&lt;/p&gt;
&lt;div class=&#34;figure&#34; style=&#34;text-align: center&#34;&gt;&lt;span style=&#34;display:block;&#34; id=&#34;fig:unnamed-chunk-2&#34;&gt;&lt;/span&gt;
&lt;img src=&#34;main_project.png&#34; alt=&#34;Example of how divide the main project into small tasks&#34; width=&#34;500px&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;
Figure 2: Example of how divide the main project into small tasks
&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;example-1&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Example 1&lt;/h2&gt;
&lt;p&gt;Imagine we need to develop a &lt;code&gt;C++&lt;/code&gt; algorithm to calculate the total fat content (&lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt;) of a portion of ice cream. Assume this response variable is determined by the amounts of butyric fat (&lt;span class=&#34;math inline&#34;&gt;\(x_1\)&lt;/span&gt;) and vegetable fat (&lt;span class=&#34;math inline&#34;&gt;\(x_2\)&lt;/span&gt;). Let &lt;span class=&#34;math inline&#34;&gt;\(E[y]\)&lt;/span&gt; represent the expected value of &lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt;, defined as:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[E[y]=10-0.5x_1+0.6x_1^2-0.6x_2+0.2x_2^2+0.1x_1x_2\]&lt;/span&gt;
We can manually compute the total fat &lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt; for specific values of &lt;span class=&#34;math inline&#34;&gt;\(x_1\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(x_2\)&lt;/span&gt;. For instance, if &lt;span class=&#34;math inline&#34;&gt;\(x_1=2\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(x_2=1\)&lt;/span&gt;, then:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[y=10-0.5\times2+0.6\times 2^2-0.6\times 1+0.2 \times 1^2+0.1\times 2 \times 1 = 11.2.\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Now, let‚Äôs assume the secondary goal is to optimize the fat content in the ice cream formulation based on this model. This involves searching for the global minimum on the response surface. Consequently, we can break down our project into two tasks:&lt;/p&gt;
&lt;div class=&#34;div-2&#34;&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;Generalize the function for any &lt;span class=&#34;math inline&#34;&gt;\(x_1\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(x_2\)&lt;/span&gt;;&lt;/li&gt;
&lt;li&gt;Calculate the global (or absolute) minimum point;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;p&gt;If you encounter difficulties in these tasks, it‚Äôs often due to a gap in specific domain knowledge, such as a lack of expertise in mathematics:&lt;/p&gt;
&lt;div class=&#34;div-2&#34;&gt;
&lt;ul&gt;
&lt;li&gt;How could I calculate the global minimum?&lt;/li&gt;
&lt;li&gt;How can I use partial derivatives?&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;p&gt;Therefore, during this step, it is essential to identify all the necessary domain knowledge and address these gaps before proceeding to the next stage. Sometimes, this knowledge may stem from specialized areas such as computer science, sports, agriculture, statistics, or engineering.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;step-2---write-everything-you-did&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Step 2 - Write everything you did&lt;/h1&gt;
&lt;p&gt;In this phase, it is crucial to meticulously record every action undertaken to resolve the project‚Äôs challenges or tasks. Ensure that your notes are clear and detailed enough for others to replicate your solutions effortlessly. Be cautious not to overlook steps that might seem obvious, such as basic operations like multiplying &lt;span class=&#34;math inline&#34;&gt;\(x\)&lt;/span&gt; by &lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt;, or the sequence in which tasks are to be executed.&lt;/p&gt;
&lt;div id=&#34;example-2&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Example 2&lt;/h2&gt;
&lt;p&gt;Consider the task of calculating &lt;span class=&#34;math inline&#34;&gt;\(f(x, y) = x^y + 3x\)&lt;/span&gt; for &lt;span class=&#34;math inline&#34;&gt;\(x=2\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(y=4\)&lt;/span&gt;. Here‚Äôs how you could document the process in a detailed and comprehensible manner:&lt;/p&gt;
&lt;div class=&#34;div-2&#34;&gt;
&lt;ul&gt;
&lt;li&gt;Multiply 2 by 2 &lt;span class=&#34;math inline&#34;&gt;\(\rightarrow\)&lt;/span&gt; you get 4&lt;/li&gt;
&lt;li&gt;Multiply 4 by 2 &lt;span class=&#34;math inline&#34;&gt;\(\rightarrow\)&lt;/span&gt; you get 8&lt;/li&gt;
&lt;li&gt;Multiply 8 by 2 &lt;span class=&#34;math inline&#34;&gt;\(\rightarrow\)&lt;/span&gt; you get 16&lt;/li&gt;
&lt;li&gt;Sum 16 plus 3 multiplied by 2 &lt;span class=&#34;math inline&#34;&gt;\(\rightarrow\)&lt;/span&gt; you get 22&lt;/li&gt;
&lt;li&gt;22 is the answer.&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;p&gt;By following these explicit steps, anyone with basic mathematical skills should be able to reach the same result.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;step-3---generalize&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Step 3 - Generalize&lt;/h1&gt;
&lt;p&gt;The goal now is to transform the specific steps from earlier into a universal algorithm that applies to a broader range of cases, not just specific parameter values. Here are two common methods to achieve this generalization:&lt;/p&gt;
&lt;div class=&#34;div-2&#34;&gt;
&lt;ul&gt;
&lt;li&gt;Re-examine the details from Step 2, as the key to generalization often lies within its description.&lt;/li&gt;
&lt;li&gt;Identify repetitive patterns, particularly where the same step is executed multiple times.&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;p&gt;For instance, let‚Äôs generalize our Example 2 by adapting the steps from Step 2, replacing the specific occurrences of 2 with a variable &lt;span class=&#34;math inline&#34;&gt;\(x\)&lt;/span&gt;:&lt;/p&gt;
&lt;div class=&#34;div-2&#34;&gt;
&lt;ul&gt;
&lt;li&gt;Multiply 2 by &lt;span class=&#34;math inline&#34;&gt;\(x\)&lt;/span&gt; &lt;span class=&#34;math inline&#34;&gt;\(\rightarrow\)&lt;/span&gt; you get 4&lt;/li&gt;
&lt;li&gt;Multiply 4 by &lt;span class=&#34;math inline&#34;&gt;\(x\)&lt;/span&gt; &lt;span class=&#34;math inline&#34;&gt;\(\rightarrow\)&lt;/span&gt; you get 8&lt;/li&gt;
&lt;li&gt;Multiply 8 by &lt;span class=&#34;math inline&#34;&gt;\(x\)&lt;/span&gt; &lt;span class=&#34;math inline&#34;&gt;\(\rightarrow\)&lt;/span&gt; you get 16&lt;/li&gt;
&lt;li&gt;Sum 16 plus 3 multiplied by &lt;span class=&#34;math inline&#34;&gt;\(x\)&lt;/span&gt; &lt;span class=&#34;math inline&#34;&gt;\(\rightarrow\)&lt;/span&gt; you get 22&lt;/li&gt;
&lt;li&gt;22 is the answer.&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;p&gt;It is important to note that the initial multiplication should start with &lt;span class=&#34;math inline&#34;&gt;\(x \times x = x^2\)&lt;/span&gt;. Therefore, we multiply &lt;span class=&#34;math inline&#34;&gt;\(x\)&lt;/span&gt; by itself &lt;span class=&#34;math inline&#34;&gt;\(y-1\)&lt;/span&gt; times to obtain &lt;span class=&#34;math inline&#34;&gt;\(x^y\)&lt;/span&gt;. This leads us to the following generalized steps for any values of &lt;span class=&#34;math inline&#34;&gt;\(x\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt;:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;Algorithm sketch 1
  
start with x = 2 and y = 4
n[1] = x

Count up from i in 1 to y-1 
  n[i+1] = n[i] * x 

z = n[y] + 3 * x
z is  the answer&lt;/code&gt;&lt;/pre&gt;
&lt;div class=&#34;div-3&#34;&gt;
&lt;p&gt;This process is referred to as writing ‚Äòpseudo-code‚Äô as an algorithm design with no particular target language.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;step-4---test-your-algorithm&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Step 4 - Test Your Algorithm&lt;/h1&gt;
&lt;p&gt;Testing your algorithm is a crucial step to ensure the correctness of steps 1-3 before advancing to step 5. Here are some key actions and considerations during this stage:&lt;/p&gt;
&lt;div class=&#34;div-2&#34;&gt;
&lt;ul&gt;
&lt;li&gt;Test your algorithm with varying parameter values.&lt;/li&gt;
&lt;li&gt;Assess the algorithm‚Äôs behavior for positive, negative, or zero values.&lt;/li&gt;
&lt;li&gt;Determine if you have confined the parameter space, e.g., &lt;span class=&#34;math inline&#34;&gt;\(y \geq 0\)&lt;/span&gt;.&lt;/li&gt;
&lt;li&gt;Employ mathematical proofs to validate your approach.&lt;/li&gt;
&lt;li&gt;Recognize that there may be more than one correct solution to a programming problem.&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class=&#34;div-3&#34;&gt;
&lt;p&gt;Remember, the parameter space refers to the range of possible parameter values that define a specific mathematical or statistical model, typically within a subset of the finite-dimensional Euclidean space.&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;At times, the generalization in step 3 might be incomplete, leading to a revisit of steps 1-2. This oversight often occurs when not all potential cases are considered or when mathematical proofs are lacking.&lt;/p&gt;
&lt;p&gt;A notable example of an algorithmic error is seen in Example 2. What if &lt;span class=&#34;math inline&#34;&gt;\(y=0\)&lt;/span&gt; or &lt;span class=&#34;math inline&#34;&gt;\(y&amp;lt;0\)&lt;/span&gt;? Our algorithm incorrectly addresses these cases. For example, with &lt;span class=&#34;math inline&#34;&gt;\(x=2\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(y=0\)&lt;/span&gt;, the algorithm erroneously calculates &lt;span class=&#34;math inline&#34;&gt;\(2^0=2\)&lt;/span&gt; instead of the correct &lt;span class=&#34;math inline&#34;&gt;\(2^0=1\)&lt;/span&gt;. Also, for any &lt;span class=&#34;math inline&#34;&gt;\(y \leq 0\)&lt;/span&gt;, the algorithm erroneously tries to count from &lt;span class=&#34;math inline&#34;&gt;\(1\)&lt;/span&gt; to &lt;span class=&#34;math inline&#34;&gt;\(y-1 &amp;lt; 0\)&lt;/span&gt;, which is not applicable for natural numbers, leading to an error. Therefore, we must ensure &lt;span class=&#34;math inline&#34;&gt;\(|y| \in \mathcal{N}_{0}\)&lt;/span&gt;, where &lt;span class=&#34;math inline&#34;&gt;\(\mathcal{N}_{0}\)&lt;/span&gt; represents the set of natural numbers including zero. Consequently, we should aim to generalize our algorithm to accommodate a broader range of cases:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;Algorithm Sketch 2 

y must be an integer number.

Start with x = 2 and y = 4.

If y=0 {
  n[1] = 1;
  i=0;
} else {
  Count from i = 1 to |y|-1;
  If y &amp;lt; 0 {
    n[1] = 1/x;
    n[i+1] = n[i] * (1/x);
  } else {
    n[1] = x;
    n[i+1] = n[i] * x;
  }
}

z = n[i+1] + 3 * x;
z is the answer.&lt;/code&gt;&lt;/pre&gt;
&lt;div class=&#34;div-3&#34;&gt;
&lt;p&gt;Question: How can we improve this algorithm? Consider the case where &lt;span class=&#34;math inline&#34;&gt;\(x=y=0\)&lt;/span&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;When encountering problems with our algorithm at this stage, we have two options:&lt;/p&gt;
&lt;div class=&#34;div-2&#34;&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;Return to steps 1-3 to gather more information for broadening the algorithm‚Äôs applicability.&lt;/li&gt;
&lt;li&gt;Directly fix the algorithm in step 4 when the solution is known.&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;div id=&#34;example-3&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Example 3&lt;/h2&gt;
&lt;p&gt;The data in Figure 4 originates from an algorithm that accepts a single parameter, &lt;span class=&#34;math inline&#34;&gt;\(N\)&lt;/span&gt;, belonging to the set &lt;span class=&#34;math inline&#34;&gt;\(\mathcal{N}_{0}\)&lt;/span&gt;, where &lt;span class=&#34;math inline&#34;&gt;\(\mathcal{N}_{0} = \mathcal{N} \cup \{ 0 \}\)&lt;/span&gt; denotes the set of natural numbers including zero. This algorithm generates a sequence of output values corresponding to each specified value of &lt;span class=&#34;math inline&#34;&gt;\(N\)&lt;/span&gt;.&lt;/p&gt;
&lt;div class=&#34;figure&#34; style=&#34;text-align: center&#34;&gt;&lt;span style=&#34;display:block;&#34; id=&#34;fig:unnamed-chunk-3&#34;&gt;&lt;/span&gt;
&lt;img src=&#34;example3.png&#34; alt=&#34;Output of sequences of integers based on values of $N$ from 0 to 4&#34; width=&#34;400px&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;
Figure 3: Output of sequences of integers based on values of &lt;span class=&#34;math inline&#34;&gt;\(N\)&lt;/span&gt; from 0 to 4
&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;div-3&#34;&gt;
&lt;p&gt;Question: Can you deduce the algorithm that produced the numbers in this figure? Additionally, what would be the result for &lt;span class=&#34;math inline&#34;&gt;\(N=5\)&lt;/span&gt;?&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;references&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;References&lt;/h1&gt;
&lt;p&gt;[1] Hilton, AD; Lipp, GM; Rodger, SH, Translation from Problem to Code in Seven Steps, Comped 2019 Proceedings of the Acm Conference on Global Computing Education (2019), pp.¬†78-84.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;answers&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Answers&lt;/h1&gt;
&lt;div id=&#34;example-3-1&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Example 3&lt;/h2&gt;
&lt;pre&gt;&lt;code&gt;Algorithm Sketch 3

Set N as a non-negative integer (Natural number with zero).

Initialize N with a specific value n.

  Define the sequence parameters:
    Minimum Value = 4 * N
    Maximum Value = 9 * N + 6
    Sequence Increment = 3

  Set x[1] to the Minimum Value.
  
  Iteratively calculate the sequence:
    For each iteration i,
      if x[i-1] &amp;lt; Maximum Value,
        then x[i] = x[i-1] + Sequence Increment.
      else,
        break the loop.

  The sequence x represents the final answer.&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r code-input&#34;&gt;&lt;code&gt;# N = 6
N=5
seq &amp;lt;- seq(4*N, 9*N+6, 3)
cat(&amp;quot;The answer is&amp;quot;, seq)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## The answer is 20 23 26 29 32 35 38 41 44 47 50&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;citation&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Citation&lt;/h1&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;For attribution, please cite this work as:&lt;/li&gt;
&lt;/ol&gt;
&lt;div class=&#34;div-1&#34;&gt;
&lt;p&gt;Oliveira T.P. (2020, Dec.¬†16). The seven steps of a programer&lt;/p&gt;
&lt;/div&gt;
&lt;ol start=&#34;2&#34; style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;BibTeX citation&lt;/li&gt;
&lt;/ol&gt;
&lt;pre&gt;&lt;code&gt;@misc{oliveira2020seven,
  author = {Oliveira, Thiago},
  title = {The seven steps of a programer},
  url = {https://prof-thiagooliveira.netlify.app/post/the-seven-steps-of-a-programer/},
  year = {2020}
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;Did you find this page helpful? Consider sharing it üôå&lt;/strong&gt;&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
  </channel>
</rss>
